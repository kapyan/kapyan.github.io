<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[在CentOS7 安装selenium+chrome+chromedriver]]></title>
    <url>%2Fposts%2F2537485430.html</url>
    <content type="text"><![CDATA[安装Chrome浏览器 配置yum源 1234567cat &gt;/etc/yum.repos.d/google-chrome.repo&lt;&lt;EOF[google-chrome]name=google-chromebaseurl=http://dl.google.com/linux/chrome/rpm/stable/x86_64enabled=1gpgcheck=0EOF 安装google-chrome 12yum -y install google-chrome-stable --nogpgcheck google-chrome --version #查看版本 chromedriver下载地址根据google-chrome版本下载对应的chromedriver，解压至/usr/bin/目录下 1234567891011121314151617181920212223vim /usr/bin/xvfb-chrome #添加以下内容_kill_procs() &#123; kill -TERM $chrome wait $chrome kill -TERM $xvfb &#125; # Setup a trap to catch SIGTERM and relay it to child processes trap _kill_procs SIGTERM XVFB_WHD=$&#123;XVFB_WHD:-1280x720x16&#125; # Start Xvfb Xvfb :99 -ac -screen 0 $XVFB_WHD -nolisten tcp &amp; xvfb=$! export DISPLAY=:99 chrome --no-sandbox --disable-gpu$@ &amp; chrome=$! wait $chrome wait $xvfb 更改Chrome启动软连接 1234chmod +x /usr/bin/xvfb-chrome #添加执行权限ln -s /etc/alternatives/google-chrome /usr/bin/chrome rm -rf /usr/bin/google-chrome ln -s /usr/bin/xvfb-chrome /usr/bin/google-chrome 安装selenium 1pip3 install selenium 测试 新建Python脚本test.py,添加以下内容 12345678910from selenium import webdriveroptions = webdriver.ChromeOptions()options.add_argument('--headless')options.add_argument('--disable-gpu')options.add_argument('--no-sandbox')driver = webdriver.Chrome(executable_path="/usr/bin/chromedriver", chrome_options=options)driver.get("https://www.baidu.com")print(driver.page_source)driver.quit() 运行 1python3 test.py #无报错则正常]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack各服务组件及架构]]></title>
    <url>%2Fposts%2F2462062835.html</url>
    <content type="text"><![CDATA[openstack各组件说明 项目名称 描述 服务 Dashboard Horizon 提供了一个基于web的自服务门户，与openstack底层服务交互，如：启动实例、分配IP及配置访问控制 Compute Nova 在openstack环境中计算实例的生命周期管理。按需响应包括生成、调度、回收虚拟机等操作 Networking Neutron 确保为其他openstack服务提供网络连接即服务，如openstack计算。为用户提供api定义网络和使用。基于插件的架构支持众多的网络提供商和技术 存储 Object Storage Swift 通过一个restful,基于http的应用程序接口存储和任意检索的非结构化数据对象。它拥有高容错机制，基于数据复制和可扩展架构。它的实现像是一个文件服务器需要挂载目录。在此种方式下，它写入对象和文件到多个硬盘中，以确保数据是在集群内跨服务器的多份复制 Block storage Cinder 为运行实例而提供的持久性块存储。它的可插拔驱动架构功能有助于创建和管理块存储设备 共享服务 Identity service Keystone 为其他openstack服务提供认证和授权服务，为所有openstack服务提供一个端点目录 Image service Glance 存储和检索虚拟机磁盘镜像，openstack计算会实例部署时使用此服务 Telemetry Ceilometer 为openstack云的计费、基准、扩展性及统计等目的提供检测和计量 高层次服务 Orchestration Heat orchestration服务支持多样化的综合的云应用，通过调用openstack-native rest api和cloudformation-compatible query api，支持：term:`HOT &lt;Heat Orchestration Template (HOT)&gt;`格式模板或者AWS CloudFormation格式模板 table th:nth-of-type(1) { width: 15%; } table th:nth-of-type(2) { width: 15%; } table th:nth-of-type(3) { width: 70%; }]]></content>
      <categories>
        <category>虚拟化</category>
        <category>OpenStack</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack部署]]></title>
    <url>%2Fposts%2F1681399788.html</url>
    <content type="text"><![CDATA[通过packstack安装OpenStack 操作系统：Centos7+配置: 2+ vCPU 4G+ 内存 50G+ 磁盘 双网卡（单网卡也可） 非英文环境下设置 1234cat &gt;/etc/environment&lt;&lt;EOFLANG=en_US.utf-8LC_ALL=en_US.utf-8EOF 关闭防火墙、网络管理服务、selinux 12345systemctl stop firewalldsystemctl disable firewalldsystemctl stop NetworkManager.servicesystemctl disable NetworkManager.servicesetenforce 0 添加安装源为阿里云的OpenStack YUM源 1234567cat &gt;/etc/yum.repos.d/openstack-ocata.repo&lt;&lt;EOF[OpenStack-ocata]name=openstack-ocatabaseurl=http://mirrors.aliyun.com/centos/7.6.1810/cloud/x86_64/openstack-ocata/enabled=1gpgcheck=0EOF 添加kvm源 1234567cat &gt;/etc/yum.repos.d/kvm.repo&lt;&lt;EOF[KVM]name=KVMbaseurl=http://mirrors.aliyun.com/centos/7.6.1810/virt/x86_64/kvm-common/enabled=1gpgcheck=0EOF 安装epel源 1yum install epel-release -y 安装packstack工具 1yum -y install openstack-packstack 单机部署OpenStack 1packstack --allinone 安装过程大概一个小时左右，用户名、密码在执行安装命令的当前目录的keystonerc_admin中 登录dashboard 访问http://host_ip/dashboard]]></content>
      <categories>
        <category>虚拟化</category>
        <category>OpenStack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7下安装kettle]]></title>
    <url>%2Fposts%2F2220227672.html</url>
    <content type="text"><![CDATA[kettle简单介绍 Kettle是一种开源的 ETL 解决方案，书中介绍了如何使用PDI来实现数据的剖析、清洗、校验、抽取、转换、加载等各类常见的ETL类工作。除了ODS/DW类比较大型的应用外，Kettle实际还可以为中小企业提供灵活的数据抽取和数据处理的功能。Kettle除了支持各种关系型数据库、HBase、MongoDB这样的NoSQL数据源外，它还支持Excel、Access这类小型的数据源。并且通过插件扩展，Kettle 可以支持各类数据源。本书详细介绍了Kettle可以处理的数据源，而且详细介绍了如何使用Kettle抽取增量数据。Kettle的数据处理功能也很强大，除了选择、过滤、分组、连接、排序这些常用的功能外，Kettle 里的Java表达式、正则表达式、Java脚本、Java类等功能都非常灵活而强大，都非常适合于各种数据处理功能 在centos7下安装kettle kettle依赖java，在linux环境下需要安装webkitgtk。 1yum install java-1.8.0-openjdk -y 安装webkitgtk时提示包找不到，很多文章中说yum install epel-release后可以安装webkitgtk，但尝试并无效。根据以下方法亲测有效。 123wget http://mirrors.coreix.net/li.nux.ro/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpmrpm -ivh nux-dextop-release-0-5.el7.nux.noarch.rpmyum install -y webkitgtk nux-dextop-release-0-5.el7.nux.noarch.rpm下载运行spoon.sh是提示java包存在异常无法启动kettle，将spoon.sh中的 12345if [ $OS = "linux" ]; then (((("$_PENTAHO_JAVA" $OPT -jar "$STARTUP" -lib $LIBPATH "$&#123;1+$@&#125;" 2&gt;&amp;1; echo $? &gt;&amp;3 ) | grep -viE "Gtk-WARNING|GLib-GObject|GLib-CRITICAL|^$" &gt;&amp;4 ) 3&gt;&amp;1)| inputtoexitstatus ) 4&gt;&amp;1else "$_PENTAHO_JAVA" $OPT -jar "$STARTUP" -lib $LIBPATH "$&#123;1+$@&#125;"fi 修改为 12345if [ $OS = "linux" ]; then (((("$_PENTAHO_JAVA" $OPT -Dorg.eclipse.swt.internal.gtk.cairoGraphics=false -Dorg.eclipse.swt.browser.DefaultType=mozilla -jar "$STARTUP" -lib $LIBPATH "$&#123;1+$@&#125;" 2&gt;&amp;1; echo $? &gt;&amp;3 ) | grep -viE "Gtk-WARNING|GLib-GObject|GLib-CRITICAL|^$" &gt;&amp;4 ) 3&gt;&amp;1)| inputtoexitstatus ) 4&gt;&amp;1else "$_PENTAHO_JAVA" $OPT -jar "$STARTUP" -lib $LIBPATH "$&#123;1+$@&#125;"fi 再次运行spoon.sh正常启动。 数据库驱动下载 oracle驱动下载mysql驱动下载]]></content>
      <categories>
        <category>数据同步</category>
      </categories>
      <tags>
        <tag>kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle数据库常用操作]]></title>
    <url>%2Fposts%2F1523118387.html</url>
    <content type="text"><![CDATA[数据库登录 进入sqlplus命令提示符 1sqlplus /nolog #在cmd直接运行 以DBA身份连接 12sqlplus / as sysdba #在cmd直接运行connect / as sysdba #在sqlplus命令提示符下运行 普通用户登录 123sqlplus username/password #在cmd直接运行connect username/password #在sqlplus命令提示符下运行connect username/password@servername #在sqlplus命令提示符下运行 创建新用户 1create user username identified by password; #Oracle12中username前要加c## 创建表空间 1create tablespace tablespacename datafile 'D:\app\orcdata\data.dbf' szie 1024m; 将空间分配给用户 1alert user username defalut tablespace tablespacename; 为用户授权 1grant create session,create table,unlimited tablespace to username; Oralce监听状态 123lsnrctl status #监听状态查看lsnrctl start #监听状态启动lsnrctl stop #监听状态停止 启动Oracle实例 12sqlplus / as sysdba start up]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[minio常用操作]]></title>
    <url>%2Fposts%2F2398942176.html</url>
    <content type="text"><![CDATA[minio集群搭建 配置key 12export MINIO_ACCESS_KEY=&lt;ACCESS_KEY&gt;export MINIO_SECRET_KEY=&lt;SECRET_KEY&gt; 启动 12345678/usr/local/bin/minio server http://192.168.31.2/data1 http://192.168.31.2/data2 \ http://192.168.31.2/data3 http://192.168.31.2/data4 \ http://192.168.31.3/data1 http://192.168.31.3/data2 \ http://192.168.31.3/data3 http://192.168.31.3/data4 \ http://192.168.31.4/data1 http://192.168.31.4/data2 \ http://192.168.31.4/data3 http://192.168.31.4/data4 \ http://192.168.31.5/data1 http://192.168.31.5/data2 \ http://192.168.31.5/data3 http://192.168.31.5/data4 配置nginx支持LB 12345678910111213141516171819202122upstream minio &#123; server 192.168.31.2:9000 weight=10 max_fails=2 fail_timeout=30s; server 192.168.31.3:9000 weight=10 max_fails=2 fail_timeout=30s; server 192.168.31.4:9000 weight=10 max_fails=2 fail_timeout=30s; server 192.168.31.5:9000 weight=10 max_fails=2 fail_timeout=30s; &#125;server &#123; listen 9000; server_name localhost; charset utf-8; default_type text/html; location /&#123; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $remote_addr; client_body_buffer_size 10M; client_max_body_size 10G; proxy_buffers 1024 4k; proxy_read_timeout 300; proxy_next_upstream error timeout http_404; proxy_pass http://minio; &#125; &#125; minio启动脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243[Unit]Description=MinioDocumentation=https://docs.minio.ioWants=network-online.targetAfter=network-online.targetAssertFileIsExecutable=/usr/local/bin/minio[Service]WorkingDirectory=/usr/localUser=minio-userGroup=minio-userPermissionsStartOnly=trueEnvironmentFile=-/etc/default/minioExecStartPre=/bin/bash -c "[ -n \"$&#123;MINIO_VOLUMES&#125;\" ] || echo \"Variable MINIO_VOLUMES not set in /etc/defaults/minio\""ExecStart=/usr/local/bin/minio server $MINIO_OPTS $MINIO_VOLUMES# Let systemd restart this service only if it has ended with the clean exit code or signal.Restart=on-successStandardOutput=journalStandardError=inherit# Specifies the maximum file descriptor number that can be opened by this processLimitNOFILE=65536# Disable timeout logic and wait until process is stoppedTimeoutStopSec=0# SIGTERM signal is used to stop MinioKillSignal=SIGTERMSendSIGKILL=noSuccessExitStatus=0[Install]WantedBy=multi-user.target# Built for $&#123;project.name&#125;-$&#123;project.version&#125; ($&#123;project.name&#125; minio设置永久下载链接 添加minio host 1mc config host add minio http://192.168.1.10:9000 &lt;access Key&gt; &lt;secret Key&gt; S3v4 配置下载策略 12#将server端的base文件设置为开放管理，可以直接通url进行下载mc policy public minio/&lt;bucket&gt;]]></content>
      <categories>
        <category>文件存储</category>
      </categories>
      <tags>
        <tag>minio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（八）]]></title>
    <url>%2Fposts%2F812097678.html</url>
    <content type="text"><![CDATA[终端读取 标准输入 Go语言fmt包下有fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，可以在程序运行过程过程中获取用户输入。 1func Scan(a ...interface&#123;&#125;) (n int, err error) Scan从标准输入扫描文本，将成功读取的空白分隔的值保存进成功传递给本函数的参数。换行视为空白，返回成功扫描的条目个数和遇到的任何错误。如果读取的条目比提供的参数少，会返回一个错误报告原因 。 1func Scanf(format string, a ...interface&#123;&#125;) (n int, err error) Scanf从标准输入扫描文本，根据format参数指定的格式将成功读取的空白分隔的值保存进成功传递给本函数的参数。返回成功扫描的条目个数和遇到的任何错误。 1func Scanln(a ...interface&#123;&#125;) (n int, err error) Scanln类似Scan，但会在换行时才停止扫描。最后一个条目后必须有换行或者到大结束位置。 1234var firstname, lastname stringfmt.Scan(&amp;firstname, &amp;lastname)fmt.Scanf("%s , %s", &amp;firstname, &amp;lastname)fmt.Scanln(&amp;firstname, &amp;lastname) 获取命令行参数 os.Args os包提供一些函数和变量。变量os.Args是一个字符串slice。可以理解它是一个动态容量的顺序数组s,可以通过s[i]来访问单个元素，通过s[m：n]来访问一段连续子区间，数组长度用len(s)表示。在Go语言中，所有的索引使用半开区间，即包含第一个索引，不包含最后一个索引。os.Args的第一个元素是os.Args[0]，它是命令本身的名字；另外的元素是程序开始执行的参数。表达式s[m:n]表示一个从第m个到第n-1个元素的slice。 12345678910111213package mainimport ( "fmt" "os" "strconv")func main() &#123; for k, v := range os.Args &#123; fmt.Println("参数"+strconv.Itoa(k)+":", v) &#125;&#125; flag包 Go提供了一个flag包，支持基本的命令行标志解析。flag包相比单纯的通过os.Args切片分析命令行参数，提供了更强的能力，同时也是复杂的用法。命令行解析常用函数和方法： 1func Parse() 从os.Args[1:]中解析注册的flag。必须在所有flag都注册好而未访问其值时执行。未注册却使用flag -help时，会返回ErrHelp。 1func Int(name string, value int, usage string) *int Int用指定的名称、默认值、使用信息注册一个int类型flag。返回一个保存了该flag的值的指针。 1func Bool(name string, value bool, usage string) *bool Bool用指定的名称、默认值、使用信息注册一个bool类型flag。返回一个保存了该flag的值的指针。 1func String(name string, value string, usage string) *string String用指定的名称、默认值、使用信息注册一个string类型flag。返回一个保存了该flag的值的指针。 1func Args() []string 返回解析之后剩下的非flag参数。（不包括命令名） 1func (f *FlagSet) StringVar(p *string, name string, value string, usage string) StringVar用指定的名称、默认值、使用信息注册一个string类型flag，并将flag的值保存到p指向的变量。 123456789101112131415161718package mainimport ( "flag" "fmt")var i = flag.Int("i", 0, "int类型参数")var b = flag.Bool("b", false, "bool类型参数")var s = flag.String("s", "", "string类型参数")func main() &#123; flag.Parse() fmt.Println("-i:", *i) fmt.Println("-b:", *b) fmt.Println("-s:", *s) fmt.Println("其他参数：", flag.Args())&#125; 编译并运行，在窗口中输入： 12go build main.go ./main -i 100 -b -s string hi golang 运行结果： 1234-i: 100-b: true-s: string其他参数： [hi golang] 上述代码在 flag.Prase() 之前，定义了 i、b、s 三个接受参数的变量， i、b、s 是指针类型的变量。flag.String() 方法返回的是保存日后解析出来的对应参数的值的位置，是一个已经分配好的空间，我们可以用这个指针变量来接受这个位置。待程序重新进入main函数，执行flag.Parse()函数之后，这三个位置上就出现了我们命令行传入的参数（其实在程序初始化期就有默认值）。后续我们可以使用 i、b、*s 来访问具体的内容。]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（七）]]></title>
    <url>%2Fposts%2F3339487437.html</url>
    <content type="text"><![CDATA[Go语言反射 反射获取 反射介绍 反射可以在运行时动态获取变量的相关信息。Go语言中的reflect包实现了运行时反射，允许程序操作任意类型的对象。经典用法是静态类型interface{}保存一个值，通过调用TypeOF获取其动态类型信息，该函数返回一个Type类型值。调用ValueOf函数返回一个Value类型值，该值代表运行时的数据。Zero接受一个Type类型参数并返回一个代表该类型零值的Value类型值。反射获取常用函数和方法： 1func TypeOf(i interface&#123;&#125;) Type TypeOf返回接口中保存的值的类型，TypeOf(nil)会返回nil。 1func ValueOf(i interface&#123;&#125;) Value ValueOf返回一个初始化为i接口保管的具体值Value，ValueOf(nil)返回Value零值。 1func (t Type) ELem() Type 返回map类型的键的类型。如非映射类型将panic 1func (t Type) Field(i int) StructField 返回索引序列指定的嵌套字段的类型，等价于用索引中的每个值链式调用本方法，如非结构体将会panic 1func (tag StructTag) Get(key string) string Get方法返回标签字符串中键key对应的值。如果标签中没有该键，会返回””。如果标签不符合标准格式。Get的返回值是不确定的。 反射获取应用 反射获取基本类型 1234567891011121314151617package mainimport ( "fmt" "reflect")func main() &#123; var o string = "haha" //返回值的类型 t := reflect.TypeOf(o) fmt.Println("o type:", t) //返回具体值的Value v := reflect.ValueOf(o) fmt.Println("o value:", v)&#125; 反射获取结构体 12345678910111213141516171819package mainimport ( "fmt" "reflect")type Person struct &#123; Name string age int&#125;func main() &#123; o := Person&#123;"haha", 18&#125; t := reflect.TypeOf(o) fmt.Println("o type:", t) v := reflect.ValueOf(o) fmt.Println("o value:", v)&#125; 获取结构体 Tag 获取结构体元素单一Tag 1234567891011121314151617181920212223242526package mainimport ( "fmt" "reflect")type User struct &#123; Name string `json:"u_name"` age int `json:"u_age"`&#125;func getStructTag(i interface&#123;&#125;) &#123; t := reflect.TypeOf(i) tag := t.Elem().Field(0).Tag.Get("json") fmt.Printf("Name Tag:%s\n", tag) tag = t.Elem().Field(1).Tag.Get("json") fmt.Printf("Age Tag:%s\n", tag)&#125;func main() &#123; a := User &#123;"haha", 18&#125; getStructTag(&amp;a)&#125; 获取结构体元素多个Tag 123456789101112131415161718package mainimport ( "fmt" "reflect")func main() &#123; type User struct &#123; Name string `json:"user_name" xml:"UserName"` &#125; u := User&#123; Name: "haha", &#125; f := reflect.TypeOf(u).Field(0) fmt.Println(f.Tag.Get("json")) fmt.Println(f.Tag.Get("xml"))&#125; 循环获取 结构体Tag 123456789101112131415161718package mainimport ( "fmt" "reflect")func main() &#123; type User struct &#123; Name string `user name` Passwd string `user password` &#125; u := &amp;User&#123;"haha", "haha123"&#125; s := reflect.TypeOf(u).Elem() for i := 0; i &lt; s.NumField(); i++ &#123; fmt.Println(s.Field(i).Tag) &#125;&#125; 反射操作 反射操作常用函数和方法 1func (v Value) Elem() Value Elem返回v持有的接口保管的值的Value封装，或者v持有的指针指向的值的Value封装。如果v的Kind不是Interface会Ptr或panic；如果v持有的值为nil，会返回Value零值。 1func (v Value) SetInt(x int64) 设置v的持有值。如果v的kind不是Int、Int8、Int16、Int32、Int64之一或者v.CanSet()返回假，会panic。 1func (v Value) Int() int64 返回v持有的有符号整数（表示为int64），如果v的Kind不是Int、Int8、Int16、Int32、Int64会panic。 1func (v Value) Kind() Kind Kind返回v持有的值的分类，如果v是Value零值，返回值为Invalid。 1func (v Value) NumField() int 返回v持有的结构体类型值的字段数，如果v的Kind不是Struct会panic。 1func (v Value) Field(i int) Value 返回结构体的第i个字段（的Value封装）。如果v的Kind不是Struct或i出界会panic。 1func (v Value) SetString(x string) 设置v的持有值。如果v的Kind不是String或者v.CanSet()返回假，会panic。 1func (v Value) NumMethod() int 返回v持有值的方法集的方法数目。 1func (v Value) MethodByName(name string) Value 返回v的名为name的方法的已绑定（到v的持有值的）状态的函数形式的Value封装。返回值调用Call方法时不应包含接收者；返回值持有的函数总是使用v的持有者作为接收者（即第一个参数）。如果未找到该方法，会返回一个Value零值。 1func (v Value) Call(in []Value) []Value Call方法使用输入的参数in调用v持有的函数。例如，如果len(in) == 3，v.Call(in)代表调用v(in[0], in[1], in[2])（其中Value值表示其持有值）。如果v的Kind不是Func会panic。它返回函数所有输出结果的Value封装的切片。和go代码一样，每一个输入实参的持有值都必须可以直接赋值给函数对应输入参数的类型。如果v持有值是可变参数函数，Call方法会自行创建一个代表可变参数的切片，将对应可变参数的值都拷贝到里面。 1func (v Value) Type() Type 返回v持有的值的类型的Type表示。 反射操作应用 通过反射操作基本类型，来改变基本类型的值。 123456789101112131415package mainimport ( "fmt" "reflect")func main() &#123; var a int = 1 a = 100 val := reflect.ValueOf(&amp;a) val.Elem().SetInt(200) b := val.Elem().Int() fmt.Printf("a =&gt; %d , b =&gt; %d\n", a, b)&#125; 反射操作结构体及调用结构体方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( "fmt" "reflect")type School struct &#123; Name string Course string&#125;func (s School) Echo() &#123; fmt.Printf("name : %s , Course : %s \n", s.Name, s.Course)&#125;func main() &#123; o := School&#123; Name: "haha", Course: "Linux", &#125; val := reflect.ValueOf(&amp;o) kd := val.Kind() if kd != reflect.Ptr &amp;&amp; val.Elem().Kind() == reflect.Struct &#123; fmt.Println("expect struct") return &#125; //获取字段数量 fields := val.Elem().NumField() fmt.Printf("struct has %d field\n", fields) //获取字段的类型 for i := 0; i &lt; fields; i++ &#123; fmt.Printf("%d %v\n", i, val.Elem().Field(i).Kind()) &#125; // 操作结构体 val.Elem().Field(1).SetString("Golang") //获取方法数量 methods := val.NumMethod() fmt.Printf("struct has %d methods\n", methods) //反射调用的Echo方法 var params []reflect.Value val.Elem().Method(0).Call(params)&#125; 反射综合应用 定义一个结构体 给结构体赋值 用反射获取结构体的下标、结构体名称、类型、值 改变结构体值 12345678910111213141516171819202122232425package mainimport ( "fmt" "reflect")type Student struct &#123; Name string Age int&#125;func main() &#123; u := Student&#123;"haha", 18&#125; v := reflect.ValueOf(&amp;u).Elem() t := v.Type() for i := 0; i &lt; v.NumField(); i++ &#123; f := v.Field(i) fmt.Printf("构体的下标: %d: 名称: %s 类型: %s 值: %v\n", i, t.Field(i).Name, f.Type(), f.Interface()) &#125; v.Field(0).SetString("哈哈") v.Field(1).SetInt(100) fmt.Println("u is now", u)&#125; Go语言数据格式 json格式 JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。它基于 ECMAScript (欧洲计算机协会制定的js规范)的一个子集，采用完全独立于编程语言的文本格式来存储和表示数据。简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。Go语言对json的解析函数在encoding/json包里面，主要是编码和解码两个函数。 Marshal函数 1func Marshal(v interface&#123;&#125;) ([]byte,error) Marshal函数返回v的json编码。Marshal函数会递归的处理值。如果一个值实现了Marshaler接口切非nil指针，会调用其MarshalJSON方法来生成json编码。nil指针异常并不是严格必需的，但会模拟与UnmarshalJSON的行为类似的必需的异常。否则，Marshal函数使用下面的基于类型的默认编码格式： 布尔类型编码为json布尔类型。 浮点数、整数和Number类型的值编码为json数字类型。 字符串编码为json字符串。角括号”&lt;”和”&gt;”会转义为”\u003c”和”\u003e”以避免某些浏览器吧json输出错误理解为HTML。基于同样的原因，”&amp;”转义为”\u0026”。 数组和切片类型的值编码为json数组，但[]byte编码为base64编码字符串，nil切片编码为null。 结构体的值编码为json对象。每一个导出字段变成该对象的一个成员。除非字段的标签是“-” ，或字段是空值而其标签指定了omitempty选项。 空值是false、0、””、nil指针、nil接口、长度为0的数组、切片、映射。 对象默认键字符串是结构体的字段名，但可以在结构体字段的标签里指定。结构体标签值里的”json”键为键名，后跟可选的逗号和选项。 12345678// 字段被本包忽略Field int `json:"-"`// 字段在json里的键为"myName"Field int `json:"myName"`// 字段在json里的键为"myName"且如果字段为空值将在对象中省略掉Field int `json:"myName,omitempty"`// 字段在json里的键为"Field"（默认值），但如果字段为空值会跳过；注意前导的逗号Field int `json:",omitempty"` “string”选项标记一个字段在编码json时应编码为字符串。它只适用于字符串、浮点数、整数类型的字段。这个额外水平的编码选项有时候会用于和javascript程序交互： 1Int64String int64 `json:",string"` 如果键名是只含有unicode字符、数字、美元符号、百分号、连字符、下划线和斜杠的非空字符串，将使用它代替字段名。 匿名的结构体字段一般序列化为他们内部的导出字段就好像位于外层结构体中一样。如果一个匿名结构体字段的标签给其提供了键名，则会使用键名代替字段名，而不视为匿名。 Go结构体字段的可视性规则用于供json决定那个字段应该序列化或反序列化时是经过修正了的。如果同一层次有多个（匿名）字段且该层次是最小嵌套的（嵌套层次则使用默认go规则），会应用如下额外规则： json标签为”-“的匿名字段强行忽略，不作考虑； json标签提供了键名的匿名字段，视为非匿名字段； 其余字段中如果只有一个匿名字段，则使用该字段； 其余字段中如果有多个匿名字段，但压平后不会出现冲突，所有匿名字段压平； 其余字段中如果有多个匿名字段，但压平后出现冲突，全部忽略，不产生错误。 对匿名结构体字段的管理是从go1.1开始的，在之前的版本，匿名字段会直接忽略掉。映射类型的值编码为json对象。映射的键必须是字符串，对象的键直接使用映射的键。指针类型的值编码为其指向的值（的json编码）。nil指针编码为null。接口类型的值编码为接口内保持的具体类型的值（的json编码）。nil接口编码为null。通道、复数、函数类型的值不能编码进json。尝试编码它们会导致Marshal函数返回UnsupportedTypeError。 Json不能表示循环的数据结构，将一个循环的结构提供给Marshal函数会导致无休止的循环。 Unmarshal函数 1func Unamrshal(data []byte,v interface&#123;&#125;) error Unmarshal函数解析json编码的数据并将结果存入v指向的值。Unmarshal和Marshal做相反的操作，必要时申请映射、切片或指针，有如下的附加规则：要将json数据解码写入一个指针，Unmarshal函数首先处理json数据是json字面值null的情况。此时，函数将指针设为nil；否则，函数将json数据解码写入指针指向的值；如果指针本身是nil，函数会先申请一个值并使指针指向它。要将json数据解码写入一个结构体，函数会匹配输入对象的键和Marshal使用的键（结构体字段名或者它的标签指定的键名），优先选择精确的匹配，但也接受大小写不敏感的匹配。要将json数据解码写入一个接口类型值，函数会将数据解码为如下类型写入接口： 123456Bool 对应JSON布尔类型float64 对应JSON数字类型string 对应JSON字符串类型[]interface&#123;&#125; 对应JSON数组map[string]interface&#123;&#125; 对应JSON对象nil 对应JSON的null 如果一个JSON值不匹配给出的目标类型，或者如果一个json数字写入目标类型时溢出，Unmarshal函数会跳过该字段并尽量完成其余的解码操作。如果没有出现更加严重的错误，本函数会返回一个描述第一个此类错误的详细信息的UnmarshalTypeError。JSON的null值解码为go的接口、指针、切片时会将它们设为nil，因为null在json里一般表示“不存在”。解码json的null值到其他go类型时，不会造成任何改变，也不会产生错误。当解码字符串时，不合法的utf-8或utf-16代理（字符）对不视为错误，而是将非法字符替换为unicode字符U+FFFD。 值类型json转换 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport ( "encoding/json" "fmt")// int 类型 json转换func JsonInt() &#123; var arg = 100 data, err := json.Marshal(arg) if err != nil &#123; fmt.Printf("json.marshal failed, err : %v\n", err) return &#125; var reply int err = json.Unmarshal(data, &amp;reply) fmt.Printf("int 类型\nJSON序列化 string(data) =&gt; %s\nJSON反序列化 reply =&gt; %v\n", string(data), reply)&#125;// string 类型 json转换func JsonString() &#123; var arg = "haha" data, err := json.Marshal(arg) if err != nil &#123; fmt.Printf("json.marshal failed, err : %v\n", err) return &#125; var reply string err = json.Unmarshal(data, &amp;reply) fmt.Printf("string 类型\nJSON序列化 string(data) =&gt; %s\nJSON反序列化 reply =&gt; %v\n", string(data), reply)&#125;// array 类型 json转换func JsonArray() &#123; var arg = [2]string&#123;"haha", "Golang"&#125; data, err := json.Marshal(arg) if err != nil &#123; fmt.Printf("json.marshal failed, err : %v\n", err) return &#125; var reply [2]string err = json.Unmarshal(data, &amp;reply) fmt.Printf("array 类型\nJSON序列化 string(data) =&gt; %s\nJSON反序列化 reply =&gt; %v\n", string(data), reply)&#125;func main() &#123; JsonInt() JsonString() JsonArray()&#125; 指针类型json转换 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( "encoding/json" "fmt")// slice 类型 json转换func JsonSlice() &#123; var arg = []string&#123;"haha", "Linux", "Python", "Golang", "Java", "DBA"&#125; data, err := json.Marshal(arg) if err != nil &#123; fmt.Printf("json.marshal failed, err : %v\n", err) return &#125; var reply []string err = json.Unmarshal(data, &amp;reply) fmt.Printf("slice 类型\nJSON序列化 string(data) =&gt; %s\nJSON反序列化 reply =&gt; %v\n", string(data), reply)&#125;// map 类型 json转换func JsonMap() &#123; var arg = map[int]string&#123;1: "haha", 2: "Linux", 3: "Python", 4: "Golang", 5: "Java", 6: "DBA"&#125; data, err := json.Marshal(arg) if err != nil &#123; fmt.Printf("json.marshal failed, err : %v\n", err) return &#125; var reply map[int]string = make(map[int]string, 6) err = json.Unmarshal(data, &amp;reply) fmt.Printf("map 类型\nJSON序列化 string(data) =&gt; %s\nJSON反序列化 reply =&gt; %v\n", string(data), reply)&#125;func main() &#123; JsonSlice() JsonMap()&#125; 结构体json转换 12345678910111213141516171819202122232425262728293031323334package mainimport ( "encoding/json" "fmt")type School struct &#123; Name string `json:"name"` Age int `json:"-"` Courses []string&#125;// struct 类型 json转换func JsonStruct() &#123; var arg = School&#123; Name: "haha", Age: 100, Courses: []string&#123;"haha", "Linux", "Python", "Golang", "Java", "DBA"&#125;, &#125; data, err := json.Marshal(arg) if err != nil &#123; fmt.Printf("json.marshal failed, err : %v\n", err) return &#125; var reply School err = json.Unmarshal(data, &amp;reply) fmt.Printf("struct 类型\nJSON序列化 string(data) =&gt; %s\nJSON反序列化 reply =&gt; %v\n", string(data), reply)&#125;func main() &#123; JsonStruct()&#125; School 类型Name字段：JSON序列化、反序列化的时候，使用 name，而不是 Name。Age字段：json:”-“ JSON序列化、反序列化的时候忽略该字段。默认情况下会解析这个字段，因为它是大写字母开头的。Courses字段：因为它是大写字母开头的，JSON序列化、反序列化的时候默认解析这个字段。 xml格式 XML是可扩展标记语言（标准通用标记语言的子集）是一种简单的数据存储语言。使用一系列简单的标记描述数据，而这些标记可以用方便的方式建立，虽然可扩展标记语言占用的空间比二进制数据要占用更多的空间，但可扩展标记语言极其简单易于掌握和使用。Go语言中提供了处理XML的标准库 encoding/xml 包，该包实现了一个简单的XML 1.0 解析器（支持XML命名空间）。 Marshal函数 1func Marshal(v interface&#123;&#125;) ([]byte, error) Marshal函数返回v的XML编码。Marshal处理数组或者切片时会序列化每一个元素。Marshal处理指针时，会序列化其指向的值；如果指针为nil，则啥也不输出。Marshal处理接口时，会序列化其内包含的具体类型值，如果接口值为nil，也是不输出。Marshal处理其余类型数据时，会输出一或多个包含数据的XML元素。XML元素的名字按如下优先顺序获取： 如果数据是结构体，其XMLName字段的标签 类型为xml.Name的XMLName字段的值 数据是某结构体的字段，其标签 数据是某结构体的字段，其字段名 被序列化的类型的名字 一个结构体的XML元素包含该结构体所有导出字段序列化后的元素，有如下例外： XMLName字段，如上所述，会省略 具有标签”-“的字段会省略 具有标签”name,attr”的字段会成为该XML元素的名为name的属性 具有标签”,attr”的字段会成为该XML元素的名为字段名的属性 具有标签”,chardata”的字段会作为字符数据写入，而非XML元素 具有标签”,innerxml”的字段会原样写入，而不会经过正常的序列化过程 具有标签”,comment”的字段作为XML注释写入，而不经过正常的序列化过程，该字段内不能有”–”字符串 标签中包含”omitempty”选项的字段如果为空值会省略空值为false、0、nil指针、nil接口、长度为0的数组、切片、映射 匿名字段（其标签无效）会被处理为其字段是外层结构体的字段 如果一个字段的标签为”a&gt;b&gt;c”，则元素c将会嵌套进其上层元素a和b中。如果该字段相邻的字段标签指定了同样的上层元素，则会放在同一个XML元素里。 Unmarshal函数 1func Unmarshal(data []byte, v interface&#123;&#125;) error Unmarshal解析XML编码的数据并将结果存入v指向的值。v只能指向结构体、切片或者和字符串。良好格式化的数据如果不能存入v，会被丢弃。因为Unmarshal使用reflect包，它只能填写导出字段。本函数好似用大小写敏感的比较来匹配XML元素名和结构体的字段名/标签键名。Unmarshal函数使用如下规则将XML元素映射到结构体字段上。这些规则中，字段标签指的是结构体字段的标签键’xml’对应的值： 如果结构体字段的类型为字符串或者[]byte，且标签为”,innerxml”，Unmarshal函数直接将对应原始XML文本写入该字段，其余规则仍适用。 如果结构体字段类型为xml.Name且名为XMLName，Unmarshal会将元素名写入该字段 如果字段XMLName的标签的格式为”name”或”namespace-URL name”，XML元素必须有给定的名字（以及可选的名字空间），否则Unmarshal会返回错误。 如果XML元素的属性的名字匹配某个标签”,attr”为字段的字段名，或者匹配某个标签为”name,attr”的字段的标签名，Unmarshal会将该属性的值写入该字段。 如果XML元素包含字符数据，该数据会存入结构体中第一个具有标签”,chardata”的字段中，该字段可以是字符串类型或者[]byte类型。如果没有这样的字段，字符数据会丢弃。 如果XML元素包含注释，该数据会存入结构体中第一个具有标签”,comment”的字段中，该字段可以是字符串类型或者[]byte类型。如果没有这样的字段，字符数据会丢弃。 如果XML元素包含一个子元素，其名称匹配格式为”a”或”a&gt;b&gt;c”的标签的前缀，反序列化会深入XML结构中寻找具有指定名称的元素，并将最后端的元素映射到该标签所在的结构体字段。以”&gt;”开始的标签等价于以字段名开始并紧跟着”&gt;” 的标签。 如果XML元素包含一个子元素，其名称匹配某个结构体类型字段的XMLName字段的标签名，且该结构体字段本身没有显式指定标签名，Unmarshal会将该元素映射到该字段。 如果XML元素的包含一个子元素，其名称匹配够格结构体字段的字段名，且该字段没有任何模式选项（”,attr”、”,chardata”等），Unmarshal会将该元素映射到该字段。 如果XML元素包含的某个子元素不匹配以上任一条，而存在某个字段其标签为”,any”，Unmarshal会将该元素映射到该字段。 匿名字段被处理为其字段好像位于外层结构体中一样。 标签为”-“的结构体字段永不会被反序列化填写。 Unmarshal函数将XML元素写入string或[]byte时，会将该元素的字符数据串联起来作为值，目标[]byte不能是nil。Unmarshal函数将属性写入string或[]byte时，会将属性的值以字符串/切片形式写入。Unmarshal函数将XML元素写入切片时，会将切片扩展并将XML元素的子元素映射入新建的值里。Unmarshal函数将XML元素/属性写入bool值时，会将对应的字符串转化为布尔值。Unmarshal函数将XML元素/属性写入整数或浮点数类型时，会将对应的字符串解释为十进制数字。不会检查溢出。Unmarshal函数将XML元素写入xml.Name类型时，会记录元素的名称。Unmarshal函数将XML元素写入指针时，会申请一个新值并将XML元素映射入该值。 xml转换应用 123456789101112131415161718192021222324252627282930313233package mainimport ( "encoding/xml" "fmt")type School struct &#123; Name string `xml:"name"` Age int `xml:"-"` Courses []string&#125;func XmlStruct() &#123; var arg = School&#123; Name: "haha", Age: 100, Courses: []string&#123;"haha", "Linux", "Python", "Golang", "Java", "DBA"&#125;, &#125; data, err := xml.Marshal(arg) if err != nil &#123; fmt.Printf("xml.marshal failed, err : %v\n", err) return &#125; var reply School err = xml.Unmarshal(data, &amp;reply) fmt.Printf("struct 类型\nXML序列化 string(data) =&gt; %s\nXML反序列化 reply =&gt; %v\n", string(data), reply)&#125;func main() &#123; XmlStruct()&#125;]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（六）]]></title>
    <url>%2Fposts%2F353173330.html</url>
    <content type="text"><![CDATA[Go语言接口 接口定义 Go语言中的接口很特别，而且提供了难以置信的一系列灵活性或抽象性。它们指定一个特定类型的值和指针表现为特定的方式。从语言角度看，接口是一种类型，它指定一个方法集，所有方法为接口类型就被认为是该接口。interface是一种类型，默认是一个指针。interface类型可以定义一组方法，但是这些不需要实现。并且interface不能包含任何变量。 1234567891011121314//定义一个空接口，空接口interface&#123;&#125;没有任何方法签名，也就意味着任何类型都实现了空接口。var i interface&#123;&#125;//定义一个接口，并赋值var name interface&#123;&#125; = "haha"//使用interface定义一组方法，方法签名的集合type I interface &#123; method1() //无参数、无返回值 method2(i int) //单参数、无返回值 method3(x,y int) //多参数、无返回值 method4() (i int) // 无参数、单返回值 method5(x, y int) (z int, err error) //多参数、多返回值&#125; 类型断言 Go语言类型断言语法为 value,ok := em.(T)如果确保em是同类型的时候可以直接使用value,ok := em.(T)，一般用于switch语句中。 em：代表要判断的变量T：代表被判断的类型value：代表返回值ok：代表是否为该类型注意：要判断的变量必须为interface类型才可以进行类型断言。 用switch做批量类型判断，不支持fallthrough。 12345678910111213141516171819202122232425262728package mainimport "fmt"type User struct &#123; id int name string&#125;func (self *User) String() string &#123; return fmt.Sprintf("%d, %s", self.id, self.name)&#125;func main() &#123; var i interface&#123;&#125; = &amp;User&#123;18, "haha"&#125; switch v := i.(type) &#123; case nil: fmt.Println("nil") case fmt.Stringer: fmt.Println(v) case func() string: fmt.Println(v()) case *User: fmt.Printf("%d, %s\n", v.id, v.name) default: fmt.Println("unknown") &#125;&#125; 接口规则 接口是一个或多个方法签名的集合。任何类型的方法集中只要拥有该接口对应的全部方法签名。就表示它“实现”了该接口，无须在该类型上显式声明实现了哪个接口。对应方法，是指有相同名称、参数列表（不包括参数名）以及返回值，该类型也可以有其他方法。 接口赋值 对象赋值给接口时，会发生拷贝，而接口内部存储的是指向这个复制品的指针，既无法修改复制品的状态，也无法获取指针。 1234567891011121314151617package mainimport "fmt"type User struct &#123; id int name string&#125;func main()&#123; u := User&#123;18,"haha"&#125; var i interface&#123;&#125; = u u.id =20 u.name = "Golang" fmt.Printf("u : %v\n",u) fmt.Printf("i.(User) : %v\n",i.(User))&#125; 接口转型返回临时对象，只有使用指针才能修改其状态。 123456789101112131415161718package mainimport "fmt"type User struct &#123; id int name string &#125;func main() &#123; u := User&#123;18,"haha"&#125; var vi,pi interface&#123;&#125; = u,&amp;u //vi.(User).name = "Golang" pi.(*User).name = "Golang" fmt.Printf("vi.(User) : %v\n",vi.(User)) fmt.Printf("pi.(*User) : %v\n",pi.(*User))&#125; 空接口 只有当接口存储的类型和对象都为nil时，接口才等于nil。 123456789101112131415package mainimport "fmt"func main() &#123; var i interface&#123;&#125; fmt.Printf("i =&gt; %v\n",i) fmt.Printf("(i == nil) =&gt; %v\n",i == nil) var p *int =nil //i指向p，指向的对象是个nil，但是存在类型不是nil，是个指针 i = p fmt.Printf("i =&gt; %v\n",i) fmt.Printf("(i == nil =&gt; %v\n)",i == nil)&#125; 接口实现 接口只有方法声明，没有数据字段，没有实现，也不要显示的实现。只要一个变量，含有接口类型中的所有方法，那么这个变量就实现了这个接口。 123456789101112131415161718192021222324252627package mainimport "fmt"type Info interface &#123; GetAge() int GetName() string&#125;type User struct &#123; name string age int&#125;func (u User) GetAge() int &#123; return u.age&#125;func (u User) GetName() string &#123; return u.name&#125;func main()&#123; var user Info = User&#123;"haha",18&#125; age := user.GetAge() name := user.GetName() fmt.Println(age,name)&#125; 如果一个变量含有了多个interface类型的方法，那么这个变量就实现了多个接口。如果一个变量只含有了一个interface的部分方法，那么这个变量就没有实现这个接口。 接口应用 接口嵌套 接口可以匿名嵌入其他接口，或嵌入到结构中。如果一个interface1作为interface2的一个嵌入字段，那么interface2隐式的包含了interface1里面的方法。 12345678910111213141516171819202122232425262728293031323334353637package mainimport "fmt"type Info interface &#123; Age Name&#125;type Age interface &#123; GetAge() int&#125;type Name interface &#123; GetName() string&#125;type User struct &#123; name string age int &#125;func (u User) GetAge() int &#123; return u.age&#125;func (u User) GetName() string &#123; return u.name&#125;func main() &#123; user := User&#123;"haha",18&#125; var u Info u = user age := u.GetAge() name := u.GetName() fmt.Println(age,name)&#125; 匿名接口可用作变量类型，或结构成员。 12345678910111213141516171819202122package mainimport "fmt"type Info struct &#123; u interface &#123; GetUser() string &#125;&#125;type User struct &#123; id int name string&#125;func (self *User) GetUser() string &#123; return fmt.Sprintf("user %d,%ds",self.id,self.name)&#125;func main() &#123; t := Info&#123;&amp;User&#123;18,"haha"&#125;&#125; fmt.Println(t.u.GetUser())&#125; 接口检查 超集接口对象可转换为子集接口，反之出错。 123456789101112131415161718192021222324252627282930package mainimport "fmt"type Stringer interface &#123; String() string&#125;type Printer interface &#123; String() string Print()&#125;type User struct &#123; id int name string&#125;func (self *User) String() string &#123; return fmt.Sprintf("%d,%v",self.id, self.name)&#125;func (self *User) Print() &#123; fmt.Println(self.String())&#125;func main() &#123; var o Printer = &amp;User&#123;18,"haha"&#125; var s Stringer = o fmt.Println(s.String())&#125; 接口技巧 让编译器检查，以确保某个类型实现接口。 123456789101112131415package mainimport "fmt"type Data struct &#123; id int name string&#125;func (self *Data) String() string &#123; return fmt.Sprintf("%d,%s",self.id,self.name)&#125;func main() &#123; var _ fmt.Stringer = (*Data)(nil)&#125; 某些时候，让函数直接“实现”接口能省不少事。 12345678910111213package maintype Tester interface &#123; Do()&#125;type FuncDo func()func (self FuncDo) Do() &#123;self() &#125;func main() &#123; var t Tester = FuncDo(func() &#123;println("Hello,world")&#125;) t.Do()&#125; 并发编程 并发介绍 Golang从语言层面就对并发提供了支持，而goroutine是Go语言并发设计的核心。Go语言的并发机制运用起来非常舒适，在启动并发的方式上直接添加了语言级的关键字就可以实现，和其他编程语言相比更加轻量。 进程&amp;线程 进程是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。 线程是进程的一个执行实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。 一个进程可以创建和撤销多个线程，同一个进程中的多个线程之间可以并发执行。 并发&amp;并行 多线程程序在一个核的cpu上运行，就是并发。 多线程程序在多个核的cpu上运行，就是并行。 并发不是并行：并发主要由切换时间片来实现“同时”运行，并行则是直接利用多核实现多线程的运行，Go程序可以设置使用核数，以发挥多核计算机的能力。 协程&amp;线程 协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的。线程：一个线程上可以跑多个协程，协程是轻量级的线程。 Goroutine介绍 goroutine只是由官方实现的超级“线程池”。每个实例4~5KB的栈内存占用和由于实现机制而大幅减少的创建和销毁开销是Go语言高并发的根本原因。goroutine奉行通过通信来共享内存，而不是共享内存来通信。只需在函数调用语句前添加go关键字，就可创建并发执行单元。开发人员无需了解任何执行细节，调度器会自动将其安排到合适的系统线程上执行。goroutine是一种非常轻量级的实现，可在单个进程里执行成千上万的并发任务。事实上，入口函数main就以goroutine运行。另有与之配套的channel类型，用以实现“以通讯来共享内存”的CSP模式。 编写第一个Goroutine 123456789101112package mainimport ("fmt" "time")func main() &#123; go func()&#123; fmt.Println("hello world") &#125;() time.Sleep(1 * time.Second)&#125; 进入main函数开启一个goroutine运行匿名函数体内容，主线程执行等待1秒。goroutine执行完毕回到主线程，主线程的sleep完成结束程序。（注意：若去掉time.Sleep(1 * time.Second)代码，进入main函数开启一个goroutine，没等goroutine运行匿名函数函数体内容，主线程已经完成结束程序） Chan应用 channel是CSP模式的具体实现，用于多个goroutine通讯。其内部实现了同步，确保并发安全。channel是先进先出，线程安全的，多个goroutine同时访问，不需要加锁。 chan阻塞 我们定义的管道intChan容量是5，开启goroutine写入10条数据，在写满5条数据时会阻塞，而read()每秒会从intChan中读取一条，然后write()再会写一条数据。 1234567891011121314151617181920212223242526272829package mainimport ( "fmt" "time")func write(ch chan int) &#123; for i :=0; i &lt; 10; i++ &#123; ch &lt;- i fmt.Println("write data :",i) &#125;&#125;func read(ch chan int) &#123; for &#123; i := &lt;-ch fmt.Println("read data:",i) time.Sleep(time.Second) &#125;&#125;func main() &#123; intChan := make(chan int,5) go write(intChan) go read(intChan) time.Sleep(10 * time.Second)&#125; 同步模式 默认为同步，需要发送和接收配对，否则会被阻塞，直到另一方准备好后被唤醒。 123456789101112131415161718192021222324package mainimport "fmt"func main() &#123; data := make(chan string) //数据交换队列 exit := make(chan bool) //退出通知 go func() &#123; for d := range data &#123; //从队列迭代接收数据，直到close fmt.Println(d) &#125; fmt.Println("received over.") exit &lt;- true //发出退出通知 &#125;() data &lt;- "haha" data &lt;- "linux" data &lt;- "golang" data &lt;- "python" close(data) //关闭队列 fmt.Println("send over.") &lt;-exit //等待退出通知&#125; 异步模式 异步方式通过判断缓冲区来决定是否阻塞。如果缓冲区已满，发送被阻塞；缓冲区为空，接收被阻塞。通常情况下，异步channel可减少排队阻塞，具备更高的效率。但应该考虑使用指针规避大对象拷贝，将多个元素打包，减少缓冲区大小。 12345678910111213141516171819202122232425262728package mainimport ( "fmt")func main() &#123; data := make(chan string, 3) // 缓冲区可以存储 3 个元素 exit := make(chan bool) data &lt;- "haha" // 在缓冲区未满前，不会阻塞。 data &lt;- "Linux" data &lt;- "Golang" go func() &#123; for d := range data &#123; // 在缓冲区未空前，不会阻塞。 fmt.Println(d) &#125; exit &lt;- true &#125;() data &lt;- "Java" // 如果缓冲区已满，阻塞。 data &lt;- "DBA" close(data) &lt;-exit&#125; chan选择 如果需要同时处理多个channel，可使用select语句。它随机选择一个可用channel做收发操作，或执行default case。用select实现超时控制 1234567891011121314151617181920212223242526package mainimport ( "fmt" "time")func main() &#123; exit := make(chan bool) intChan := make(chan int,2) strChan := make(chan string,2) go func() &#123; select &#123; case vi := &lt;-intChan: fmt.Println(vi) case vs := &lt;-strChan: fmt.Println(vs) case &lt;- time.After(time.Second * 3): fmt.Println("timeout.") &#125; exit &lt;- true &#125;() // intChan &lt;- 100 //注释掉，引发timeout // strChan &lt;- "haha" &lt;-exit&#125; 注意：在循环中使用select default case需要小心，避免形成洪水。 简单工厂模式 用简单工厂模式打包并发任务和channel 123456789101112131415161718192021package mainimport ( "fmt" "math/rand" "time")func NewTest() chan int &#123; c := make(chan int) rand.Seed(time.Now().UnixNano()) go func() &#123; time.Sleep(time.Second) c &lt;- rand.Int() &#125;() return c&#125;func main() &#123; t := NewTest() fmt.Println(&lt;-t) // 等待 goroutine 结束返回。&#125; WaitGroup WaitGroup能够一直等到所有的goroutine执行完成，并且阻塞主线程的执行，直到所有的goroutine执行完成。WaitGroup总共有三个方法：Add(delta int),Done(),Wait()。 Add：添加或减少等待goroutine的数量；Done：相当于Add(-1);Wait:执行阻塞，直到所有的WaitGroup数量变成0。 WaitGroup用于线程同步，WaitGroup等待一组线程集合完成，才会继续向下执行。主线程（goroutine）调用Add来设置等待的线程（goroutine）数量。然后每个线程（goroutine）运行，并在完成后调用Done。同时，Wait用来阻塞，直到所有线程（goroutine）完成才会向下执行。 12345678910111213141516171819202122232425package mainimport ( "fmt" "sync" "time")func main() &#123; var wg sync.WaitGroup for i := 0; i &lt; 5; i++ &#123; wg.Add(1) go func(n int) &#123; //defer wg.Done() defer wg.Add(-1) EchoNum(n) &#125;(i) &#125; wg.Wait()&#125;func EchoNum(i int) &#123; time.Sleep(time.Second) fmt.Println(i)&#125; 程序中将每次循环的数量 sleep 1 秒钟后输出。如果程序不使用WaitGroup，将不会输出结果。因为goroutine还没执行完，主线程已经执行完毕（注掉的 defer wg.Done() 和 defer wg.Add(-1) 作用一样）。 WaitGroup陷阱 add数量小于done数量导致WaitGroup为负数 add数量大于done数量造成deadlock 跳过add和done操作，直接执行wait WaitGroup拷贝传值问题 123456789101112131415161718package mainimport ( "fmt" "sync")func main() &#123; wg := sync.WaitGroup&#123;&#125; for i := 0; i &lt; 5; i++ &#123; wg.Add(1) go func(wg sync.WaitGroup, i int) &#123; fmt.Printf("i=&gt;%d\n", i) wg.Done() &#125;(wg, i) &#125; wg.Wait()&#125; 运行错误： 1fatal error: all goroutines are asleep - deadlock! wg 给拷贝传递到了 goroutine 中，导致只有 Add 操作，其实 Done操作是在 wg 的副本执行的，因此 Wait 就死锁了。正确代码： 123456789101112131415161718192021package mainimport ( "fmt" "sync")func main() &#123; wg := new(sync.WaitGroup) // wg := &amp;sync.WaitGroup&#123;&#125; for i := 0; i &lt; 5; i++ &#123; wg.Add(1) go func(wg *sync.WaitGroup, i int) &#123; fmt.Printf("i=&gt;%d\n", i) wg.Done() &#125;(wg, i) &#125; wg.Wait()&#125; runtime runtime包提供Go语言运行时的系统交互操作，例如控制goroutine的功能。调度器不能保证多个goroutine执行次序，且进程退出时不会等待他们结束。默认情况下，进程启动后仅允许一个系统线程服务于goroutine。可使用环境变量或标准库函数runtime.GOMAXPROCS修改，让调度器用于多个线程实现多核并行，而不仅仅是并发。runtime包常用方法 1const GOOS string = theGoos GOOS是可执行程序的目标操作系统（将要在该操作系统的机器上执行）：darwin、freebsd、linux等。 1func Gosched() Gosched使当前goroutine放弃处理器，以让其他goroutine运行。它不会挂起当前go程，因此当前goroutine未来会恢复执行。 1func NumCPU() int NumCPU返回本地机器的逻辑CPU个数 1func GOROOT() string GOROOT返回go的根目录。如果存在GOROOT环境变量，返回该变量的值；否则，返回创建go时的根目录。 1func GOMAXPROCS(n int) int GOMAXPROCS设置可同时执行的最大CPU数，并返回先前的设置。 若 n &lt; 1，它就不会更改当前设置。本地机器的逻辑CPU数可通过 NumCPU 查询。本函数在调度程序优化后会去掉。 1func Goexit() Goexit终止调用它的goroutine。其他goroutine不会受影响。Goexit会在终止该goroutine前执行所有defer的函数。在程序的main goroutine调用本函数，会终结该goroutine，而不会让main返回。因为main函数没有返回，程序会继续执行其它goroutine。如果所有其他goroutine都退出了，程序就会崩溃。 1func NumGoroutine() int NumGoroutine返回当前存在的Goroutine数。]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（五）]]></title>
    <url>%2Fposts%2F1879225483.html</url>
    <content type="text"><![CDATA[Go语言流程控制 if条件语句 条件语句需要开发者通过指定一个或多个条件，并通过测试条件是否为true来决定是否执行指定语句，并在条件为false的情况下执行另外的语句。 if 语句 if语句由一个布尔表达式后紧跟一个或多个语句组成。if 在布尔表达式为 true 时，其后紧跟的语句块执行，如果为 false 则不执行。 12345678910111213141516171819202122232425262728293031//直接判断bool类型b := trueif b &#123; fmt.Println("b := true")&#125;//表达式中判断bool类型var str stringif str == "" &#123; fmt.Println(`str == ""`)&#125;//通过&amp;&amp;逻辑与、||逻辑或、！逻辑非，判断bool类型a := 10b := 20if a &gt; 0 &amp;&amp; a &lt; b &#123; fmt.Println("a &gt; 0 &amp;&amp; a &lt; b")&#125;if a &lt; 10 || b == 20 &#123; fmt.Println("a &lt; 10 || b == 20")&#125;if !(a == b) &#123; fmt.Println("!(a == b)")&#125;//表达式中先变量后判断bool类型if age ：= 18;age == 18 &#123; fmt.Println("age == 18")&#125; if…else语句 if语句后可以使用可选的else语句，else语句中的表达式在布尔表达式为false时执行。 12345678i := 10if i &lt; 10 &#123; fmt.Println("i&lt;10")&#125; else if i == 10 &#123; fmt.Println("i=10")&#125; else &#123; fmt.Println("i&gt;10")&#125; if嵌套语句 可以在if或else if语句中嵌入一个或多个if或else if 语句。 1234567name := "haha"age := 18if name == "haha" &#123; if age == 18 &#123; fmt.Println("haha") &#125;&#125; switch条件语句 switch语句用于基于不同条件执行不同动作。每一个case分支都是唯一的，所有case分支的参数必须是相同的类型，语句执行的过程从上至下，直到找到匹配项，匹配项后面也不需要再加上break，默认自动终止。 switch语句 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//直接判断var i = 0 switch i &#123; case 0: case 1: fmt.Println(1) case 2: fmt.Println(2) default: fmt.Println("default")&#125;//带初始化语句names := []string&#123;"Linux", "Golang", "Jav"Python"&#125;switch name := names[0]; name &#123;case "Golang": fmt.Println("Golang")case "Java": fmt.Println("Java")case "Python": fmt.Println("Python")default: fmt.Println("haha")&#125;//一个case多个可能符合条件的值var i = 1switch i &#123; case 0,1: fmt.Println("0 or 1") case 2: fmt.Println("2") default: fmt.Println("default")&#125;//省略条件表达式应用var i = 10switch &#123; case i &gt;=0 &amp;&amp; i &lt; 10: fmt.Println("i &gt; 0 and i &lt; 10") case i &gt;=10 &amp;&amp; i &lt; 20: fmt.Println("i &gt;10 and i &lt; 20") default: fmt.Println("default")&#125;/*fallthrough应用Go语言switch语句的每个case最后默认带有break,成功后不会自动向下执行其他case，而是跳出整个switch。可以使用fallthrough语句强制执行后面的case代码。*/var i = 0switch i &#123; case 0: fmt.Println("fallthrough") fallthrough case 1: fmt.Println(1) //此行代码被强制执行 case 2: fmt.Println(2) default: fmt.Println("defalut")&#125; select语句 select是Go中的一个控制结构，类似于通信的switch语句。每个case必须是一个通信操作，要么是发送要么是接收。select随机执行一个可运行的case。如果没有case可运行，它将阻塞，直到有case可运行。一个默认的子句应该总是可运行的。语法如下： 123456789select &#123; case communication clause : statement(s); case communication clause : statement(s); /* 你可以定义任意数量的 case */ default : /* 可选 */ statement(s);&#125; 每个case都必须是一个通信 所有channels表达式都被会求值 所有被发送的表达式都被求值 如果任意某个通信可以进行，他就执行，其它被忽略 如果有多个case都可以运行，select会随机公平地选出一个执行。其它不会被执行。否则：如果有default子句，则执行该语句；如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值。 12345678910111213141516171819202122package mainimport "fmt"func main() &#123; var c1, c2, c3 chan int var i1, i2 int select &#123; case i1 = &lt;-c1: fmt.Printf("received ", i1, " from c1\n") case c2 &lt;- i2: fmt.Printf("sent ", i2, " to c2\n") case i3, ok := (&lt;-c3): // same as: i3, ok := &lt;-c3 if ok &#123; fmt.Printf("received ", i3, " from c3\n") &#125; else &#123; fmt.Printf("c3 is closed\n") &#125; default: fmt.Printf("no communication\n") &#125; &#125; for循环语句 for循环是一个循环控制结构，可以执行指定次数的循环。三种循环方式： 常见的for循环，支持初始化语句 12for init; condition; post &#123; &#125; init:一般为赋值表达式，给控制变量赋初值；condition：关系表达式或逻辑表达式，循环控制条件；post：一般为复制表达式，给控制变量增量或减量。for语句执行过程如下：① 先对表达式init赋初值② 判别赋值表达式init是否满足给定condition条件，若其值为真，满足循环条件则执行循环体内语句，然后执行post，进入第二次循环，再判别condition；否则判断condition值为假，不满足条件就终止for循环，执行循环体外语句。 关系表达式或逻辑表达式控制循环 1234567891011for condition &#123; &#125;//例如i := 0for i &lt; 5 &#123; i++&#125;for i == 5 &#123; fmt.Println(i) break&#125; 无限循环 1234567for &#123;&#125;for true &#123;&#125; range循环语句 Go语言中range关键字用于for循环中迭代数组（array）、切片（slice）、通道（channel）或者集合（map）的元素。在数组和切片中它返回元素的索引和索引对应的值，在集合中返回key-value对应的key值。 字符串遍历 1234var str string = "linux系统"for k,v := range str &#123; fmt.Println(k,string(v))&#125; for range英文字符串，key值按照+1顺序递增 for range包含中文字的字符串，英文字符key值按照+1顺序递增，中文字符key值按照+3顺序递增 数组遍历 for range数组程序会复制对象，key、value都是从复制品中取出 12345678910arr := [5]int&#123;1, 2, 3, 4, 5&#125;for k, v := range arr &#123; if k == 0 &#123; arr[0], arr[1] = 1000, 1000 fmt.Println("修改原数组：", arr) // 使用复制品中取出的 value 修改原数组 arr[k] = v + 100&#125;fmt.Println(arr) 多维数组遍历 12345678var arr [2][3]int = [2][3]int&#123;&#123;1, 2, 3&#125;, &#123;2, 4, 6&#125;&#125;for k1, v1 := range arr &#123; for k2, v2 := range v1 &#123; fmt.Printf("%d*%d=%d ", k1+1, k2+1, v2) &#125; fmt.Printf("\n")&#125; 数组遍历值拷贝行为会造成性能问题，建议数组遍历使用饮用型slice，或数组指针。 12345678910arr := [5]int&#123;1, 2, 3, 4, 5&#125;arrP := &amp;arrfor k, _ := range arrP &#123; if k == 0 &#123; arrP[0], arrP[1] = 1000, 1000 fmt.Println("修改原数组：", arr) &#125; arrP[k] += 100&#125;fmt.Println(arr) slice遍历 将所需数据copy到较小的slice，以便释放底层数组内存 12345arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;slice := arr[:]for key, value := range slice &#123; fmt.Printf("key: %v , value : %v\n", key,value)&#125; map遍历 map遍历不能保证迭代返回次序，通常是随机结果，具体和版本实现有关。 12345678910m := map[int]string&#123; 1: "Linux", 2: "Golang", 3: "Python", 4: "Java", 5: "DBA",&#125;for k, v := range m &#123; fmt.Printf("%d =&gt; %s \n", k, v)&#125; channel遍历 123456789var ch chan intch = make(chan int,10)for i :=0;i &lt; 10; i++ &#123; ch &lt;- i&#125;close(ch)for v := range ch &#123; fmt.Println(v)&#125; 注意：如果没有close()，因为存入管道10个数字，然后无限取数据，再取出来第10个数据，再次range管道，会dead lock。### 循环控制语句循环控制语句可以控制循环体内语句的执行过程。Go语言支持goto、break、continue三种循环控制语句，三个语句都可以配合标签（label）使用，标签名区分大小写，定义后不使用会造成编译错误。#### goto语句Go语言支持在函数内goto跳转，goto语句可以无条件地转移到过程中指定的行，通常与条件语句配合使用。可用来实现条件转移、构成循环、跳出循环体等功能。 12345678910111213141516171819202122232425262728293031323334//先定义标签后定义goto语句package mainimport "fmt"func main()&#123; var i int = 10GO: for i &lt; 20 &#123; if i == 15 &#123;//跳过迭代 i = i + 1 goto GO &#125; fmt .Printf("i的值为：%d\n",i) i++ &#125;&#125;//先定义goto语句后定义标签package mainimport "fmt"func main() &#123; var i int for &#123; fmt.Println(i) i++ if i &gt; 2 &#123; goto haha &#125; &#125;haha: fmt.Println("golang")&#125; 注意：goto语句与标签之间不能有变量声明，否则编译错误。 break语句 break语句中断当前for循环，并开始执行循环之后的语句 break语句中断当前for range循环，并开始执行循环之后的语句 break语句在执行一条case后跳出switch循环 break语句在执行一条case后跳出select循环 break label语句跳出多层嵌套循环，break标签除了可以跳出for循环，还可以跳出select、switch循环（注意：label要写在循环的开始而不是结束的地方，和goto语句不一样） continue语句 continue语句在for循环和for range循环中用于跳过当前循环的剩余语句，然后继续进行下一轮循环。 continue label语句可在多级嵌套循环中跳出。 Go语言函数 函数定义 Go语言函数特点 关键字func用来声明一个函数名； 函数可以有一个或多个参数，每个参数后面带有类型，通过逗号“,”分隔； 函数可以返回多个值； 返回值可以使用声明变量，如果不想声明也可以直接使用返回值的类型； 如果只有一个返回值且不声明返回值变量，那么可以省略包括返回值的括号； 如果没有返回值，可以直接省略最后的返回信息； 如果有返回值，必须在函数的外层添加return语句，否则会引发编译错误； 函数也是一种类型，一个函数可以赋值给变量，可作为参数传递； 函数不支持嵌套，一个包不能有两个名字一样的函数。不支持重载，不支持默认参数 1234567891011121314151617181920212223242526272829//定义一个无参数、无返回值的函数func funcName() &#123;&#125;//定义一个参数、无返回值的函数func Print(st string) &#123; println(str)&#125;//定义多个参数的函数，一个返回值的函数func sum(x,y int) int &#123; return x + y&#125;//定义一个多返回值的函数func haha(str string) (ret string,err error) &#123; if str == "go" &#123; return "OK",nil &#125; return "",errors.New("error")&#125;//返回值只有类型，无变量声明函数func haha(str string) (string,error) &#123; if str == "go" &#123; return "OK",nil &#125; return "",errors.New("error")&#125; 函数类型 1234567891011//定义一个五参数、无返回值的函数类型type funcType func()//定义一个参数，无返回值的函数类型type funcType func(string)//定义多个参数的函数，一个返回值的函数类型type funcType func(x,y int) init//定义一个多返回值的函数类型type funcType func(string) (string,error) 函数参数 实际参数简称“实参”。在调用有参数时，函数名后面括号中的参数称为“实际参数”，实参可以是常量、变量或表达式。自定义函数中的“形参”全称为“形式参数”，由于它不是实际存在变量，所以又称虚拟变量。实参和形参可以重名。形参的作用域是整个函数体，就像定义在函数体内的局部变量。 参数传递 值传递：指在调用函数时将实际参数复制一份到传递函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 1234567891011121314151617package mainimport ( "fmt")func main() &#123; var x int = 1 var y int = 2 // 值传递 z := sum(x, y) fmt.Println(z)&#125;func sum(x, y int) int &#123; return x + y&#125; 引用传递：是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行修改，将影响到实际参数。 123456789101112131415161718192021package mainimport ( "fmt")func swap(x, y *string) &#123; var temp string temp = *x *x = *y *y = temp&#125;func main() &#123; var course1, course2 string = "Python", "Golang" swap(&amp;course1, &amp;course2) fmt.Println(course1, course2)&#125; 固定类型可变参数：就是函数的参数不是固定的，后面的类型是固定的。 1234567891011121314package mainimport "fmt"func variable(name string, course ...string) &#123; fmt.Println("可变参数的长度:", len(course)) for _, val := range course &#123; fmt.Println(name, val) &#125;&#125;func main() &#123; variable(linux", "golang", "python", "java")&#125; 任意类型的不定参数：就是函数的参数和每个参数的类型都不是固定的。形参用interface{}传递任意类型数据。 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( "fmt")type Person struct &#123; name string&#125;func variable(values ...interface&#123;&#125;) &#123; for _, val := range values &#123; switch v := val.(type) &#123; case int: fmt.Println("val type is int ", v) case float64: fmt.Println("val type is float ", v) case string: fmt.Println("val type is string ", v) case bool: fmt.Println("val type is bool ", v) case Person: fmt.Println("val type is Person ", v.name) case *Person: fmt.Println("val type is *Person ", v.name) default: fmt.Println("val type is unknow ", v) &#125; &#125;&#125;func main() &#123; temp_int := 1 temp_float := 5.6 temp_string := "hello" temp_bool := true temp_person1 := &amp;Person&#123;name: "jack"&#125; temp_person2 := Person&#123;name: "rose"&#125; var temp_float32 float32 = 6.6 variable(temp_int, temp_float, temp_string, temp_bool, temp_person1, temp_person2, temp_float32)&#125; 函数类型参数：就是函数类型赋值给变量，作为参数传递应用。 12345678910111213141516171819package mainimport "fmt"// 定义函数类型type myfunc func(string, string)func addperfix(perfix, name string) &#123; fmt.Println(perfix, name)&#125;// 第二个参数用匿名函数当参数func sayhello(name string, f myfunc) &#123; f("hello", name)&#125;func main() &#123; sayhello("haha", addperfix)&#125; 注意： Go语言函数中的参数不支持默认值。 无论是值传递，还是引用传递，传递给函数的都是变量的副本，不过，值传递是值的拷贝。引用传递是地址的拷贝，一般来说，地址拷贝更为高效。而值拷贝取决于拷贝的对象大小，对象越大，则性能越低。 map、slice、chan、指针、interface默认以引用的方式传递。 函数的可变参数只能有一个，且必须是最后一个。 在参数赋值时可以不用一个个赋值，可以直接传递一个数组或者切片，特别注意的在参数后加上“…”即可。 函数返回值 返回值定义 返回值通过使用返回语句返回。可以返回任意类型。返回语句会立即中止函数的运行，并且将控制权交回调用该函数的代码行。Go语言函数可以有零个或多个返回值，可以返回多个不同类型的结果。当函数有返回值时return语句必须要写，否则编译器会报错。Go语言在定义函数返回值可以被命名，命名返回值的作用域是整个函数体，就像定义在函数体内的局部变量。在return语句中，无需显示的返回这些值，Go会自动将其返回。 巧用return 无返回值函数，在内部任何程序执行片段return，直接会跳出该函数，return下面的程序片段都不会再执行。 123456789101112131415package mainimport "fmt"func test() &#123; for i := 10; i &lt; 100;i++ &#123; fmt.Printf("%v\n",i) if i == 11 &#123; return &#125; &#125;&#125;func main() &#123; test()&#125; 有返回值函数，在内部任何程序执行片段使用return，它下面的程序片段都不会再执行，但是程序结尾必须以return结束，否则程序报错。 1234567891011121314151617pacakage mainimport "fmt"func test() int &#123; i := 0 for i = 10 ;i &lt; 100; i++&#123; fmt.Printf("%v\n",i) if i == 11 &#123; return i &#125; &#125; return i&#125;func main() &#123; _ = test()&#125; 匿名函数 匿名函数是指不需要定义函数名的一种函数实现方式。1958年LISP首先采用匿名函数。在Go里面，函数可以像普通变量一样被传递或使用，Go语言支持随时在代码里定义匿名函数。匿名函数由一个不带函数名的函数声明和函数体组成。匿名函数的优越性在于可以直接使用函数内的变量，不必声明。 匿名函数定义 12345678910111213141516171819202122//先声明一个函数类型的变量，然后定义一个匿名函数package mainimport "fmt"func main() &#123; var sum func(int,int) int sum = func(x,y int) int &#123; return x + y &#125; fmt.Println(sum(1,2))&#125;//使用更简略的“:=”方式定义一个匿名函数package mainimport "fmt"func main() &#123; product := func(x,y int) int &#123; return x * y &#125; fmt.Println(product(3,3))&#125; 匿名函数应用 123456789101112131415161718192021//匿名函数的变量为函数地址package mainimport "fmt"func main() &#123; sum := func(x,y int) int &#123; return x + y &#125; fmt.Printf("sum -&gt; %v sum(1,3) =%v\n",sum,sum(1,3))&#125;//直接创建匿名函数执行并返回结果package mainimport "fmt"func main() &#123; product := func(x,y int) int &#123; return x * y &#125;(3,3) fmt.Printf("product = % d\n",product)&#125; 递归函数 递归，就是在运行的过程中调用自己。一个函数调用自己，就叫做递归函数。构成递归需具备的条件： 子问题须与原始问题为同样的是事，且更为简单。 不能无限制地调用本身，须有个出口，化简为非递归状况处理。 Go编程语言支持递归，即函数调用函数本身。在使用递归时，需要谨慎确定函数的退出条件，否则会造成无限循环。递归函数可以解决许多数学问题如计算给定数字阶乘、产生斐波那契数列等。 延迟调用 defer是Go语言提供的关键字，用来调度一个函数（被延期的函数），使其在执行defer的函数即将返回之前才运行被延期执行的函数，它的参数（包括接受者）在defer执行的时候被求值，而不是在调用执行的时候 。也就是说被延期执行的函数的参数是按照正常顺序被求值的。defer常用来释放资源，如果有多个defer表达式，调用顺序类似于栈，越后面的defer表达式越先被调用。defer函数调用的执行时机是外层函数设置返回值后，并在即将返回之前。 defer应用 当defer被声明时，参数被实时解析 12345678910111213package mainimport "fmt"func test() (str string) &#123; str = "haha" defer fmt.Printf("defer : %s\n",str) str = "哈哈" return&#125;func main() &#123; test()&#125; deferz执行顺序为先进后出 123456789101112package mainimport "fmt"func test() &#123; for i := 1; i&lt; 4; i++ &#123; defer fmt.Printf("defer%d\n",i) &#125; &#125;func main() &#123; test()&#125; defer可以读取有名返回值 123456789101112package mainimport "fmt"func test() (i int) &#123; defer func() &#123; i += 100&#125;() return 1&#125;func main() &#123; ret := test() fmt.Println(ret)&#125; 需要明确的是defer代码块的作用域仍然在函数之内。defer的作用域仍然在test()函数之内，因此可以读取test()函数内的变量。 Go语言方法 方法定义 在Go语言中有一个概念和函数极其相似叫做方法。Go语言的方法其实是作用在接收者（receiver）上的一个函数，接收者是某种非内置类型的变量。因此，方法是一种特殊类型的函数。接收者类型可以是（几乎）任何类型，不仅仅是结构体类型，任何类型都可以有方法，甚至可以是函数类型，可以是int、bool、string或数组的别名类型。但是接收者不能是接口类型。方法的声明和普通函数的声明类似，只是在函数名称前面多了一个参数，这个参数把这个方法绑定到这个参数对应的类型上。方法定义首先声明一个自定义类型Test 1type Test struct&#123;&#125; 方法参数receiver类型可以是Test或*Test。类型Test不能是接口或指针。 123456789101112131415161718192021222324//定义一个无参数、无返回值的方法func (t Test) method() &#123;&#125;//定义一个单参数、无返回值的方法func (t Test) method(i int) &#123;&#125;//定义一个多参数、无返回值的方法func (t Test) method(x, y int) &#123;&#125;//定义一个无参数、单返回值的方法func (t Test) method() (i int) &#123; return&#125;//定义一个多参数、多返回值的方法func (t Test) method(x, y int) (z int, err error) &#123; return&#125; 方法和函数的关系 方法是特殊的函数，定义在某一特定的类型上，通过类型的实例来进行调用，这个实例被叫接收者。接受者必须有一个显式的名字，这个名字必须在方法中被使用。接受者类型必须在和方法同样的包中被声明。 注意：Go语言不允许为简单的内置类型添加方法 方法与函数的区别 对于普通函数，接收者为值类型时，不能将指针类型的数据直接传递，反之亦然。 对于方法（如struct的方法），接收者为值类型时，可以直接用指针类型的变量调用方法，反之亦然。 方法规则 根据调用者不同，方法分为两种表现形式：方法（method value）、方法表达式（method expression）。两者都可像普通函数那样赋值和传参，区别在于方法（method value）绑定了实例，而方法表达式（method expression）必须显式传参。 直接调用 直接调用，类型T和*T上的方法集是互相继承的。 1234567891011121314151617181920212223242526package mainimport "fmt"type T struct &#123; int&#125;func (t T) testT()&#123; fmt.Println("接收者为T")&#125;func (t *T) testP() &#123; fmt.Println("接收者为*T")&#125;func main() &#123; t1 := T&#123;1&#125; fmt.Printf("t1 is :%v\n",t1) t1.testT() t1.testP() t2 := &amp;t1 fmt.Printf("t2 is : %v\n", t2) t2.testT() t2.testP()&#125; 直接调用，类型S包含匿名字段*T或T,则S和*S方法包含T和*T上的方法集是互相继承的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( "fmt")type ST struct &#123; T&#125;type SP struct &#123; *T&#125;type T struct &#123; int&#125;func (t T) testT() &#123; fmt.Println("类型 S 包含匿名字段 *T 或 T ，则 S 和 *S 方法集包含 T 方法")&#125;func (t *T) testP() &#123; fmt.Println("类型 S 包含匿名字段 *T 或 T ，则 S 和 *S 方法集包含 *T 方法")&#125;func main() &#123; st1 := ST&#123;T&#123;1&#125;&#125; st2 := &amp;st1 fmt.Printf("st1 is : %v\n", st1) st1.testT() st1.testP() fmt.Printf("st2 is : %v\n", st2) st2.testT() st2.testP() sp1 := SP&#123;&amp;T&#123;1&#125;&#125; sp2 := &amp;sp1 fmt.Printf("sp1 is : %v\n", sp1) sp1.testT() sp1.testP() fmt.Printf("sp2 is : %v\n", sp2) sp2.testT() sp2.testP()&#125; 隐式传递调用 接收者隐式传递，类型T和*上的方法是相互继承的。 1234567891011121314151617181920212223242526package mainimport "fmt"type T struct &#123; string&#125;func (t T) testT() &#123; fmt.Println("接收者为T")&#125;func (t *T) testP() &#123; fmt.Println("接收者为*T")&#125;func main() &#123; t := T&#123;"haha"&#125; methodValue1 := t.testT methodValue1() methodValue2 := (&amp;t).testT methodValue2() methodValue3 := t.testP methodValue3() methodValue4 := (&amp;t).testP methodValue4() &#125; 接收者隐式传递，类型S包含匿名字段*T或T,则S和*S方法集包含T和*T上的方法集是互相继承的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( "fmt")type ST struct &#123; T&#125;type SP struct &#123; *T&#125;type T struct &#123; string&#125;func (t T) testT() &#123; fmt.Println("类型 S 包含匿名字段 *T 或 T ，则 S 和 *S 方法集包含 T 方法")&#125;func (t *T) testP() &#123; fmt.Println("类型 S 包含匿名字段 *T 或 T ，则 S 和 *S 方法集包含 *T 方法")&#125;func main() &#123; st1 := ST&#123;T&#123;"hahha"&#125;&#125; methodValue1 := st1.testT methodValue1() methodValue2 := (&amp;st1).testT methodValue2() methodValue3 := st1.testP methodValue3() methodValue4 := (&amp;st1).testP methodValue4() sp1 := SP&#123;&amp;T&#123;"oldboy"&#125;&#125; methodValue5 := sp1.testT methodValue5() methodValue6 := (&amp;sp1).testT methodValue6() methodValue7 := sp1.testP methodValue7() methodValue8 := (&amp;sp1).testP methodValue8()&#125; 显示传递调用 接收者显示传值，类型T的可调用方法集包含接收者为T所有方法，不包含接收者为*T的方法。类型*T的可调用方法集包含接收者为*T或者T的所有方法集。 12345678910111213141516171819202122232425262728293031package mainimport ( "fmt")type T struct &#123; string&#125;func (t T) testT() &#123; fmt.Println("接受者为 T ")&#125;func (t *T) testP() &#123; fmt.Println("接受者为 *T ")&#125;func main() &#123; t := T&#123;"haha"&#125; expression1 := T.testT expression1(t) expression2 := (*T).testT expression2(&amp;t) // expression3 := T.testP // expression3(t) expression4 := (*T).testP expression4(&amp;t)&#125; 接收者显示传值，类型S包含匿名字段*T,则S和*S方法集包含T和*T上的方法集是互相继承的。类型 S 包含匿名字段 T ，类型 S 的可调用方法集包含接受者为 T 的所有方法，不包含接受者为 *T 的方法。类型 *S 的可调用方法集包含接受者为 *T 或 T 的所有方法集。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( "fmt")type ST struct &#123; T&#125;type SP struct &#123; *T&#125;type T struct &#123; string&#125;func (t T) testT() &#123; fmt.Println("类型 S 包含匿名字段 *T 或 T ，则 S 和 *S 方法集包含 T 方法")&#125;func (t *T) testP() &#123; fmt.Println("类型 S 包含匿名字段 *T 或 T ，则 S 和 *S 方法集包含 *T 方法")&#125;func main() &#123; st1 := ST&#123;T&#123;"haha"&#125;&#125; expression1 := ST.testT expression1(st1) expression2 := (*ST).testT expression2(&amp;st1) // expression3 := ST.testP // expression3(st1) expression4 := (*ST).testP expression4(&amp;st1) sp1 := SP&#123;&amp;T&#123;"haha"&#125;&#125; expression5 := SP.testT expression5(sp1) expression6 := (*SP).testT expression6(&amp;sp1) expression7 := SP.testP expression7(sp1) expression8 := (*SP).testP expression8(&amp;sp1)&#125; 方法应用 匿名字段 Go语言支持只提供类型，而不写字段名的方式，也就是匿名字段，也称为嵌入字段。当匿名字段是一个struct的时候，那么这个struct所拥有的全部字段都被隐式地引入了当前定义的这个struct。Go语言匿名字段可以像字段成员那样访问匿名字段方法，编译器负责查找。 123456789101112131415161718192021package mainimport "fmt"type Student struct &#123; id int name string&#125;type Course struct &#123; Student&#125;func (self *Student) ToString() string &#123; return fmt.Sprintf("Student: %p, %v", self, self)&#125;func main() &#123; c := Course&#123;Student&#123;1,"haha"&#125;&#125; fmt.Printf("Course: %p\n",&amp;c) fmt.Println(c.ToString()) &#125; Go语言不像其它面向对象语言一样可以写个类，然后在类里面写一堆方法，但其实Go语言的方法很巧妙的实现了这种效果：我们只需要在普通函数前面加个接收者（receiver，写在函数名前面的括号里面），这样编译器就知道这个函数（方法）属于哪个struct了。 继承复用 Go语言中没有继承，但是可以依靠组合来模拟继承和多态。通过匿名字段，可获得和继承类似的复用能力。依据编译器查找次序，只需在外层定义同名方法，就可以实现。 1234567891011121314151617181920212223242526package mainimport "fmt"type Student struct &#123; id int name string&#125;type Course struct &#123; Student title string&#125;func (self *Student) ToString() string &#123; return fmt.Sprintf("Student:%p,%v",self,self)&#125;func (self *Course) ToString() string &#123; return fmt.Sprintf("Course: %p, %v", self, self)&#125;func main() &#123; c := Course&#123;Student&#123;1, "haha"&#125;, "Golang"&#125; fmt.Println(c.ToString()) fmt.Println(c.Student.ToString())&#125; 自定义EEROR 错误是可以用字符串描述自己的任何东西。可以由预定义的内建接口类型error，和其返回字符串的方法Error构成。 123type error interface &#123; Error() string&#125; 当用fmt包的多种不同的打印函数输出一个error时，会自动调用该方法。 12345678910111213141516171819202122232425262728293031323334353637383940package mainimport ( "fmt" "os" "time")type PathError struct &#123; path string op string createTime string message string&#125;func (p *PathError) Error() string &#123; return fmt.Sprintf("path=%s \nop=%s \ncreateTime=%s \nmessage=%s", p.path, p.op, p.createTime, p.message)&#125;func Open(filename string) error &#123; file, err := os.Open(filename) if err != nil &#123; return &amp;PathError&#123; path: filename, op: "read", message: err.Error(), createTime: fmt.Sprintf("%v", time.Now()), &#125; &#125; defer file.Close() return nil&#125;func main() &#123; err := Open("/test/test.go") switch v := err.(type) &#123; case *PathError: fmt.Println("get path error,", v) default: &#125;&#125;]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（四）]]></title>
    <url>%2Fposts%2F530346444.html</url>
    <content type="text"><![CDATA[Go语言切片 Go语言切片是对数组的抽象。数组的长度不可改变，在特定场景中不太使用，Go提供了一种灵活，功能强悍的内置类型切片（“动态数组”），与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片容量增大。（slice并不是数组或数组指针，它通过内部指针和相关属性引用数组片段，以实现变长方案） 切片定义 123456789101112131415161718192021222324252627282930313233343536373839//声明一个切片var slice []int //切片定义并初始化var slice0 []int = []int&#123;1,2,3&#125;var slice1 = []int&#123;1,2,3&#125;//通过make来创建切片var slice0 []int = make([]int,10)var slice1 = make([]int,10)var slice2 = make([]int,10,10)//通过:=语法来定义切片slice0 := []int&#123;&#125;slice1 := make([]int, 10)slice2 := make([]int, 10, 10)//通过操作数组来创建切片var array = [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;var slice0 []int = array[2:8]var slice1 []int = array[0:6] //可以简写为 var slice []int = array[:end]var slice2 []int = array[5:10] //可以简写为 var slice[]int = array[start:]var slice3 []int = array[0:len(array)] //可以简写为var slice []int = array[:]var slice4 = array[:len(array)-1] //去掉切片的最后一个元素//通过两个冒号创建切片，slice[x:y:z]切片实体[x:y],切片长度len=y-x,切片容量cap=z-xpackage mainimport ( "fmt")func main() &#123; slice := []int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; slice1 := slice[6:8] fmt.Printf("slice1 : %v , len : %d , cap : %d\n", slice1, len(slice1), cap(slice1)) slice2 := slice[2:6:8] fmt.Printf("slice2 : %v , len : %d , cap : %d\n", slice2, len(slice2), cap(slice2))&#125; 切片操作 切片长度，可以由len()函数获取切片长度。切片容量，可以由cap()函数获取切片最长可以达到多少。如果slice == nil，那么len、cap结果都等于0。切片追加，使用append()函数向slice尾部添加数据，返回新的slice 12345678910111213141516171819202122package mainimport ( "fmt")func main() &#123; var a = []int&#123;1, 2, 3&#125; // 一次 append 一个值 b := append(a, 4) // 一次 append 多个值 c := append(b, 5, 6, 7) // 一次 append 一个切片 var d = []int&#123;8, 9, 10&#125; e := append(c, d...) fmt.Println(a, b, c, d, e)&#125; 切片拷贝，使用copy()函数copy在两个slice间复制数据，复制长度以len小的为准。两个slice可指向同一底层数组，允许元素区间重叠。 slice中cap重新分配规律 123456789101112131415package mainimport . "fmt" func main()&#123; s := make([]int,0,1) c := cap(s) for i :=0;i &lt; 50;i++ &#123; s = append(s,i) if n := cap(s); n &gt; c&#123; Printf("cap:%d -&gt; %d\n",c,n ) c = n &#125; &#125; &#125; 运行结果: 123456cap:1 -&gt; 2cap:2 -&gt; 4cap:4 -&gt; 8cap:8 -&gt; 16cap:16 -&gt; 32cap:32 -&gt; 64 Go语言容器 Map是一种无序的键值对的集合。Map最重要的一点是通过key来快速检索数据，key类似于索引，指向数据的值。Map是一种集合，所以可以像迭代数组和切片那样迭代它。不过，Map是无序的，我们无法决定它的返回顺序，这是因为Map是使用hash表来实现的。键必须是支持相等运算符（“==”、“！=”）类型，如number、string、pointer、array、struct和对应的interface，值可以是任意类型，没有限制。 定义Map 1234567891011121314//声明一个Mapvar m map[int]string //Map定义并初始化var m1 map[int]string = map[int]string&#123;0:"Linux",1:"Golang"&#125;var m2 = map[int]string&#123;0:"Linux",1:"Golang"&#125;//通过make来创建Mapvar m1 map[int]string = make(map[int]string,10)var m2 = make(map[int]string,10)//通过:=语法来定义Mapm1 := map[int]string&#123;&#125;m2 := make(map[int]string,10) Map操作 12345678910111213141516171819m := map[string]string&#123;"key0": "Linux", "key1": "Python"&#125;//插入操作m["key2"] = "golang"//更新操作m["key1"] = "php"//查找操作val,ok := m["key0"]if ok &#123; fmt.Printf("查找操作：key0 =&gt; %v\n", val)&#125;//删除操作delete(m,"key1")//求长度len := len(m) 注意：不可以在map上使用cap()方法 Go语言管道 Channel概念 Channel是Go中的一个核心类型，可以把它看成一个管道。Channel是引用类型，操作符是箭头 &lt;-。Channel是CSP模式的具体实现，用于多个goroutine通讯。其内部实现了同步，确保并发安全。Channel是线程安全的，先进先出，多个goroutine同时访问，不需要加锁，channel是有类型的，一个整数的channel只能存放整数。 Channel定义 1234567891011121314151617181920212223242526//channel声明var ch chan int //声明int类型的chanvar ch chan string //声明string类型的chanvar ch chan map[int]string //声明map类型的chan//使用make定义，无缓冲channelvar ch1 chan int = make(chan int)var ch2 chan = make(chan int)ch3 := make(chan int)//使用make定义，有缓冲channelvar ch1 chan int = make(chan int, 10)var ch2 = make(chan int, 10)ch3 := make(chan int, 10)//只读channelvar ch1 &lt;-chan intvar ch2 &lt;-chan int = make(&lt;-chan int,10)var ch3 = make(&lt;-chan int, 10)ch4 := make(&lt;-chan int, 10)//只写channelvar ch1 chan&lt;- intvar ch2 chan&lt;- int = make(chan&lt;- int,10)var ch3 = make(chan&lt;- int,10)ch4 := make(chan&lt;- int,10) Channel特点 无缓冲的与有缓冲channel有着重大差别，那就是一个是同步的，一个是非同步的。 无缓冲chan：ch1:=make(chan int)有缓冲chan：ch2:=make(chan int,1)无缓冲： ch1&lt;-1不仅仅是向c1通道放1，而是一直要等到有别的协程&lt;-ch1接收了这个参数，ch1&lt;-1才会继续下去，要不然就一直阻塞着。有缓冲：ch2&lt;-1则不会阻塞，因为缓大小是1（其实是缓冲大小为0,），只有当放第二个值的时候，第一个还没被接收，才会阻塞。 缓冲区是内部属性，并非类型构成要素。普通channel可以隐式转为只读channel或只写channel。 123456789package mainvar ch = make(chan int, 3)var send chan&lt;- int = chvar recv &lt;-chan int = chfunc main() &#123;&#125; 注意：只读channel或只写channel不能转为普通channel Channel操作 12345678910111213141516171819202122232425262728//使用内置函数len()返回未被读取的缓冲元素数量，使用内置函数cap()返回缓冲区大小ch2 := make(chan int, 3)len(ch1), cap(ch1)//channel写入、读取操作：ch := make(chan int,1)//写入chanch &lt;- 99//读取chanvalue,ok := &lt;-chif ok &#123; fmt.Printf("读取chan:%v\n",value)&#125;//channel关闭操作使用内置函数close()进行关闭chan/*chan关闭之后，for range遍历chan中已经存在的元素后结束没有使用for range的写法需要使用，val,ok := &lt;-ch进行判断chan是否关闭,注意:*/close(ch)for &#123; val,ok := &lt;-ch if ok == false&#123; fmt.Println("chan is closed") break &#125; fmt.Println(val)&#125; Go语言指针 指针（Pointer）是编程语言中的一个对象，利用地址，它的值直接指向（points to）存在的电脑存储器中另一个地方的值。由于通过地址能找到所需的变量单元，可以说，地址指向该变量单元。因此，将地址形象化的称为“指针”。意思是通过它能找到以它为地址的内存单元。一个指针变量指向了一个值的内存地址。Go语言支持指针类型*T，指针的指针**T，以及包含包名前缀的*package.T。 指针声明 在指针类型变量前面加上*（取值符）来获取指针所指向的内容。在值类型变量前面加上&amp;（取地址符）来获取该变量的指针。 12345678910111213141516171819var ip *int //声明一个int值的指针变量var sp *string //声明一个string值的指针变量//通过:=语法来定义指针var str string = "hello"sp := &amp;strvar p **int //声明一个int值的指针的指针变量var t *time.Time //声明一个time.Time值的指针变量//打印变量在内存中的地址：package mainimport "fmt"func main()&#123; var str string = "hello" fmt.Printf("变量的地址:%x\n",&amp;str)&#125; 空指针 当一个指针被定义后没有分配到任何变量时，它的值为nil。nil指针也被称为空指针。nil在概念上和其他语言的null、None、nil、NULL一样，都代替零值或空值。定义的不同类型的零值不能用于比较运算。 指针类型转换 Go语言是不允许两个指针类型进行转换的。unsafe.Pointer类型用于表示任意类型的指针。有4个特殊的只能用于Pointer类型的操作。 在任意类型的指针可以转换为一个Pointer类型值。 一个Pointer类型值可以转换为任意类型的指针。 一个uintptr类型值可以转换为一个Pointer类型值。 一个Pointer类型值可以转换为一个uintptr类型值。 因此，Pointer类型允许程序绕过类型系统读写任意内存。使用它时必须谨慎。 123456789101112131415package main import ( "fmt" "unsafe")func main()&#123; var i uint = 10 var p2 *int p1 := &amp;i p2 = (*int)(unsafe.Pointer(p1)) fmt.Println(*p2)&#125; Go语言结构体 Go语言中数组可以存储同一类型的数据，但在结构体中为不同项定义不同的数据类型。结构体是由一系列具有相同类型或不同类型的数据构成的数据集合。 struct特点 用来定义复杂数据结构 struct里面可以包含一个或多个字段（属性） struct类型可以定义方法，注意和函数的区分 struct类型是值类型 struct类型可以嵌套 结构体是用户单独定义的类型，不能和其他类型进行强制转换 Go中的struct没有构造函数，一般可以使用工厂模式来解决这个问题 可以为struct中的每个字段，写上一个tag。这个tag可以通过反射的机制获取到，最常用的场景就是json序列化和反序列化 访问结构体成员，用“.”来连接，格式为：“结构体.成员名” struct定义 可以用tpye在全局或函数内定义新类型 12345678910111213141516171819//定义一个新的数据类型，结构体中只有一个成员type bigint int64type smallint int8/*新类型不是原类型的别名，除拥有相同数据存储结构外，它们之间没有任何关系，不会持有原类型任何信息。除非目标类型是未命名类型，否则必须显式转换。*///定义一个新的数据类型，结构体中有多个成员type study struct &#123; linux string python string golang string&#125;//定义一个新的数据类型，指向结构体的指针type linux stringtype study struct &#123; *linux&#125; 不能同时嵌入某一类型和其指针类型，因为它们名字相同。 1234567891011package maintype linux stringtype study struct &#123; *linux linux&#125;func main()&#123;&#125; 编译错误： 1.\test.go:6:2: duplicate field linux struct初始化 有序初始化：结构体中的多个成员的值，必须一一对应。无序初始化：结构体中的多个成员的值，无须一一对应，可初始化部分值。 12345678910type study struct &#123; Linux string Python string Golang string&#125;// 有序初始化var ordered = study&#123;"linux", "python", "golang"&#125;// 无序初始化var disordered = study&#123;Golang: "golang"&#125; 结构体初始化方法有以下几种： 1234567891011121314151617181920package mainimport "fmt"type study struct &#123; int string&#125;var one studyfunc mian()&#123; two ：= new(study) //同var two *study = new(study) three := study&#123;1,"three"&#125; four ：= study&#123;&#125; five := &amp;study&#123;&#125; six := &amp;study&#123;2,"six"&#125; //同var six *study = &amp;study&#123;2,"six"&#125; fmt.Println(one,two,three,four,five,six)&#125; one three four返回study类型变量；two five six返回“*study”类型变量；若无初始化值，则默认为零值。 匿名字段 定义一个struct，定义的时候字段名与其类型一一对应，实际上Go语言支持只提供类型，而不写字段名的方式，也就是匿名字段，或称为嵌入字段。当匿名字段是一个struct的时候，这个struct所拥有的全部字段都被隐式地引入了当前定义的这个struct。 12345678910111213141516171819202122232425262728package mainimport "fmt"type Person struct &#123; name string age int addr string&#125;type Employee struct &#123; Person //匿名字段 salary int int //用内置类型作为匿名字段 addr string //类似于重载&#125;func main() &#123; em1 := Employee&#123; Person&#123;"haha", 18, "北京"&#125;, 10, 100, "首都", &#125; fmt.Println(em1) var em2 Person = em1.Person fmt.Println(em2)&#125; struct与tag应用 声明struct结构的时候，在属性的右侧用小米点`括起来的内容叫标签（Tag），在转换成其其它数据格式的时候，会使用其中特定的字段作为键值。如转成json格式： 1234567891011121314151617181920212223242526package main import ( "encoding/json" "fmt")type User struct &#123; UserId int UserName string&#125; type UserTag struct &#123; UserId int `json:"user_id" bson:"user_id"` UserName string `json:"user_name" bson:"user_name"`&#125;func main()&#123; user := &amp;User&#123;UserId:1,UserName:"haha"&#125; json_user, _:= json.Marshal(user) fmt.Printf("struct User echo : %v\n",string(json_user)) user_tag := &amp;UserTag&#123;UserId:1,UserName:"haha"&#125; json_user_tag, _:= json.Marshal(user_tag) fmt.Printf("struct UserTag echo : %v\n",string(json_user_tag))&#125; 运行结果： 12struct User echo : &#123;"UserId":1,"UserName":"haha"&#125;struct UserTag echo : &#123;"user_id":1,"user_name":"haha"&#125; 标签是struct类型的组成部分 Go语言常见语法错误 开大括号不能放在单独一行。 12345678910//错误代码func main()&#123;&#125;//正确代码func main()&#123;&#125; 存在未使用的变量。如果有未使用的局部变量，代码将编译失败。如果给未使用的变量分配了一个新的值，代码还是会编译失败。需要在某个地方使用这个变量，才能让编译器愉快的编译。 未使用的Imports。如果引入了一个包，而没有使用其中的任何函数、接口、结构体或者变量的话，代码将会编译失败。如果真的需要引入的包，可以添加一个“_”下划线标记符，来作为这个包的名字，从而避免编译失败。下划线标记符用于引入，但不使用。 “:=”简式声明仅可以在函数内部使用。 使用简式声明重复声明变量。不能在一个单独的声明中重复声明一个变量，但在多变量中这是允许的，其中至少要有一个新的声明变量。重复变量需要在相同的代码块内，否则将得到一个隐藏变量。 123456789101112131415//错误代码package mainfunc main()&#123; one := 0 one := 1&#125;//正确代码package mainfunc main()&#123; one :=0 one,two := 1,2 one,two = two,one&#125; Go语言命名区分大小写 Go语言中分号分行。如果想将多行代码写在同一行，使用”;”分隔 Go语言中无效的分号。不可以写两个及两个以上连续的分号。 偶然的变量隐藏。短式变量声明的语法如此的方便，容易让人把它当成一个正常的分配操作。如果在一个新的代码块中犯了这个错误，将不会出现编译错误，但应用将不会做期望的事情。 12345678910111213package mainimport "fmt"func main()&#123; x := 1 fmt.Println(x) //1 &#123; fmt.Println(x) //1 x :=2 fmt.Println(x) //2 &#125; fmt.Println(x) //1&#125; 这是一个非常常见的陷阱，但又很难发现。可以使用vet命令来发现一些这样的问题。默认情况下，vet不会执行这样的检查，需要设置-shadow参数：命令：go tool vet -shadow your_file.go 不使用显式类型，无法使用“nil”来初始化变量。nil标志符用于表示interface、函数、maps、slices和channels的“零值”。如果不指定变量的类型，编译器将无法编译代码，因为它猜不出具体的类型。 使用“nil” Slices and Maps。在一个nil的slice中添加元素是没有问题的，但对一个map做同样的事将会生成一个运行时的panic。 Map的容量。map只有len操作，没有cap操作。 字符串不会为nil。]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（三）]]></title>
    <url>%2Fposts%2F2830198955.html</url>
    <content type="text"><![CDATA[Go语言fmt包 格式化输出函数 1func Print(a ...interface&#123;&#125;) (n int, err error) Print采用默认格式将其参数格式化并写入标准输出。如果两个相邻的参数都不是字符串，会在它们的输出之间添加空格，返回写入的字节数和遇到的任何错误。 1func Printf(format string,a ...interface&#123;&#125;) (n int,err error) Printf根据format参数生成格式化的字符串并写入标准输出，返回写入的字节数和遇到的任何错误。 1func Println(a ...interface&#123;&#125;) (n int,err error) Println采用默认格式将其参数格式化并写入标准输出。总是会在相邻参数的输出之间添加空格并在输出结束后添加换行符，返回写入的字节数和遇到的任何错误。 常用的格式化 Go语言的标准输出流在打印到屏幕时有些参数跟别的语言（比如C#和Java）不同。 普通占位符 占位符 说明 举例 %v 以默认的方式打印变量的值 fmt.Printf(“%v”,site) %+v 在打印结构体时，会添加字段名 fmt.Printf(“%+v”, site) %#v 在打印结构体时，会添加字段名和包名 fmt.Printf(“%#v”, site) %T 打印变量的类型 fmt.Printf(“%T”, site) %% 字面上的百分号，并非值的占位符 fmt.Printf(“%%”) 布尔占位符 占位符 说明 举例 %t 打印true或fasle fmt.Printf(“%t”,true) 整数占位符 占位符 说明 举例 %b 表示为二进制 fmt.Printf(“%b”,100) %c 该值对应的Unicode码值 fmt.Printf(“%c”,0x4E2D) %d 表示为十进制 fmt.Printf(“%d”,0x12) %o 表示为八进制 fmt.Printf(“%d”, 10) %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 fmt.Printf(“%q”, 0x4E2D) %x 十六进制表示，字母形式为小写 a-f fmt.Printf(“%x”, 13) %X 十六进制表示，字母形式为大写 A-F fmt.Printf(“%x”, 13) %U 表示为Unicode格式：U+1234，等价于”U+%04X” fmt.Printf(“%U”, 0x4E2D) 浮点数和复数的组成部分（实部和虚部） 占位符 说明 举例 %e (=%.6e) 6位小数点科学计数法，例如 -1234.456e+78 fmt.Printf(“%e”, 10.2) %E 科学计数法，如-1234.456E+78 fmt.Printf(“%e”, 10.2) %f (=%.6f) 6位小数点有小数点而无指数，例如 123.456 fmt.Printf(“%f”, 10.2) %g 根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0）输出 fmt.Printf(“%g”, 10.20) %G 根据情况选择 %E 或 %f 以产生更紧凑的（无末尾的0）输出 fmt.Printf(“%G”, 10.20+2i) 字符串与字节切片 占位符 说明 举例 %s 输出字符串表示（string类型或[]byte） fmt.Printf(“%s”, []byte(“haha”)) %10s 输出字符串最小宽度为10(右对齐) fmt.Printf(“%10s”, “haha”) %-10s 输出字符串最小宽度为10(左对齐) fmt.Printf(“%-10s”, “haha”) %.5s 输出字符串最大宽度为5 fmt.Printf(“%.5s”, “haha”) %5.10s 输出字符串最小宽度为5，最大宽度为10 fmt.Printf(“%5.10s”, “haha”) %-5.10s 输出字符串最小宽度为5，最大宽度为10(左对齐) fmt.Printf(“%-5.10s”, “haha”) %5.3s 输出字符串宽度为5,如果原字符串宽度大于3,则截断 fmt.Printf(“%5.3s”, “haha”) %010s 如果宽度小于10，就会在字符串前面补零 fmt.Printf(“%010s”, “haha”) %q 双引号围绕的字符串，由Go语法安全地转义 fmt.Printf(“%q”, “haha”) %x 十六进制，小写字母，每字节两个字符 fmt.Printf(“%x”, “haha”) %X 十六进制，大写字母，每字节两个字符 fmt.Printf(“%X”, “haha”) 指针 占位符 说明 举例 %p 十六进制表示，前缀0x fmt.Printf(“%p”,&amp;site) %#p 不带前缀0x fmt.Printf(“%#p”,&amp;site) Go语言字符串 Go语言的字符串是一个用UTF-8编码的变宽字符序列，它的每一个字符都用一个或多个字节表示。在Go语言中，没有字符类型，字符类型是rune类型，rune是int32的别称。可用[]byte()获取字节，使用[]rune()获取字符，可对中文进行转换。 定义字符串 123str := "Go语言字符串\n不能跨行赋值" //双引号，用来创建可解析的字符串字面量（支持转义，但不能用来引用多行）str := `Go原生原格式字符串 可以跨行` //反引号，用来创建原生的字符串字面量，这些字符串可能由多行组成（不支持任何转义序列），原生的字符串字面量多用于书写多行消息、HTML以及正则表达式 注意:单引号不能用于定义字符串，单引号用于定义Go语言的一个特殊类型rune，类似其他语言的byte但又不完全一样，是指码点字面量（Unicode code point），不做任何转义的原始内容。 连接字符串 1str := "hello" + "world" golang里字符串都是不可变的，每次运算都会产生一个新的字符串，所以会产生很多临时无用的字符串，不仅没有用，还会给gc带来额外的负担，所以性能比较差。(注意：连接跨行字符串时，”+”必须在上一行末尾，否则导致编译错误) 1str := fmt.Sprintf("%s,%s","hello","world") 内部使用[]byte实现，不像直接运算符这种会产生很多临时的字符串，但是内部逻辑比较复杂，有很多额外的判断，还用到了interface，所以性能也不是很好。 1str := strings.Join([]string&#123;"hello","world"&#125;,",") join会先根据字符串数组的内容，计算出一个拼接之后的长度，然后申请对应大小的内存，一个一个字符串填入，在已有一个数组的情况下，这种效率会很高，但是本来没有，去构造这个数据的代价也不小。 123456import "bytes"var buffer bytes.Bufferbuffer.WriteString("hello")buffer.WriteString(",")buffer.WriteString("world")str := buffer.String() 这个比较理想,可以当成可变字符使用，对内存的增长也有优化。 总结： 在已有字符串数组的场合，使用strings.Join()能有比较好的性能； 在一些性能要求比较高的场合，尽量使用buffer.WriteString() 以获得更好的性能； “+” 运算符在较少字符串连接的场景下性能最好，而且代码更简短清晰，可读性更好； 如果需要拼接的不仅仅是字符串，还有数字之类的其他需求的话，可以考虑 fmt.Sprintf()。 字符串长度 1.将字符串转换为[]rune后调用len函数进行统计 1234567891011package mainimport ( "fmt")func main() &#123; str := "hello world" length := len([]rune(str)) fmt.Println(length)&#125; 在golang中，如果字符串出现中文字符不能直接调用len函数来统计字符串字符长度，这是因为在Go中，字符串是以UTF-8为格式进行存储的，在字符串上调用len函数，取得的是字符串包含的byte的个数。 2.使用bytes.Count()统计 123456789101112package mainimport ( "bytes" "fmt")func main() &#123; str := "hello world" length := bytes.Count([]byte(str), nil) - 1 fmt.Println(length)&#125; 计算字节切片sep在字节切片s中非重叠显示的个数，如果 sep 为 nil，则返回 s 中的字符个数 + 1。 3.使用strings.Count()统计 123456789101112package mainimport ( "fmt" "strings")func main() &#123; str := "hello world" length := strings.Count(str, "") - 1 fmt.Println(length)&#125; 判断字符sep在字符串s中出现的次数，没有找到则返回-1，如果为空字符串(“”)则返回字符串的长度+1。 4.使用 utf8.RuneCountInString() 统计 123456789101112package mainimport ( "fmt" "unicode/utf8")func main() &#123; str := "hello world" length := utf8.RuneCountInString(str) fmt.Println(length)&#125; 返回 s 字符串长度，可以正常解析中文，一个中文被当做一个字符。 字符串操作 使用索引号“[]”返回子串。返回的字符串依然指向原字节数组，仅修改了指针和长度属性。 123456789101112package mainimport ( "fmt")func main() &#123; str := "hello, world" s1 := str[0:5] s2 := str[7:13] fmt.Println(s1, s2)&#125; 运行结果 1hello world 修改字符串，可先将其转换成 []rune 或 []byte，完成后再转换为string。无论哪种转换，都会重新分配内存，并复制字节数组。 123456789101112131415package mainimport "fmt"func main() &#123; str1 := "hello world" s1 := []byte(str1) s1[0] = 'H' fmt.Println(string(s1)) str2 := "鸟宿池边树，僧推月下门。" s2 := []rune(str2) s2[7] = '敲' fmt.Println(string(s2))&#125; 运行结果 12Hello world鸟宿池边树，僧敲月下门。 Go语言string包 strings包实现了用于操作字符的简单函数。 查找操作 判断给定字符串s中是否包含子串substr,找到返回true, 找不到返回false。 12345678910package mainimport ( "fmt" "strings")func main() &#123;fmt.Println("包含子串返回：", strings.Contains("hello world", "hello"))&#125; 在字符串s中查找sep所在的位置,返回位置值,找不到返回-1 123456789101112package mainimport ( "fmt" "strings")func main() &#123; fmt.Println("存在返回第一个匹配字符的位置：", strings.Index("hello", "o")) fmt.Println("不存在返回：", strings.Index("hello", "world")) fmt.Println("中文字符串存在返回：", strings.Index("呜呼哈哈", "哈哈"))&#125; 运行结果： 123存在返回第一个匹配字符的位置： 4不存在返回： -1中文字符串存在返回： 6 统计给定子串sep的出现次数, sep为空时, 返回字符串的长度 + 1 1234567891011package mainimport ( "fmt" "strings")func main() &#123; fmt.Println("子字符串出现次数：", strings.Count("hello ooo", "o")) fmt.Println("子字符串为空时, 返回：", strings.Count("hello", ""))&#125; 运行结果： 12子字符串出现次数： 4子字符串为空时, 返回： 6 重复操作 重复s字符串count次，最后返回新生成的重复的字符串 123456789package mainimport ( "fmt" "strings")func main()&#123; fmt.Println(strings.Repeat("嘀嗒",4),"时针它不停在转动")&#125; 运行结果： 1嘀嗒嘀嗒嘀嗒嘀嗒 时针它不停在转动 替换操作 在s字符串中，把old字符串替换为new字符串，n表示替换的次数，如果n&lt;0会替换所有old子串。 1234567891011package mainimport ( "fmt" "strings")func main() &#123; fmt.Println(strings.Replace("luck luck luck", "k", "ky", 2)) fmt.Println(strings.Replace("luck luck luck", "k", "ky", -1))&#125; 运行结果： 12lucky lucky lucklucky lucky lucky 删除操作 删除在s字符串的头部和尾部中由cutset指定的字符，并返回删除后的字符串 12345678910package mainimport ( "fmt" "strings")func main() &#123; fmt.Println(strings.Trim(" hello ", " "))&#125; 运行结果： 1hello 大小写转换 12345678//给定字符串转换为英文标题的首字母大写的格式（不能正确处理unicode标点）func Title(s string) string//返回将所有字母都转为对应的小写版本的拷贝func ToLower(s string) string//返回将所有字母都转为对应的大写版本的拷贝func ToUpper(s string) string 字符串前后缀 12345//判断字符串是否包含前缀prefix，大小写敏感func HasPrefix(s,prefix string) bool//判断s是否有后缀字符串suffix，大小写敏感func HasSuffix(s,suffix string) bool 字符串分割 用去掉s中出现的sep的方式进行分割，会分割到结尾，并返回生成的所有片段组成的切片（每一个sep都会进行一次切割，即使两个sep相邻，也会进行两次切割）。如果sep为空字符，Split会将s切分成每一个unicode码值一个字符串。 1func Split(s,sep string) []string 返回将字符串按照空白（Unicode.IsSpace确定，可以是一个到多个连续的空白字符）分割的多个字符串。如果字符串全部是空白或者空字符串的话，会返回空切片。 1func Fields(s string) []string Go语言数组 数组是具有相同唯一类型的一组已编号且长度固定的数据项序列，这种类型可以是任意的原始类型，如：整形、字符串或自定义类型。在go中数组是固定长度的数据类型，它包含相同类型的连续的元素，这些元素可以是内建类型，像数字和字符串，也可以是结构类型，元素可以通过唯一的索引值访问，从0开始。数组是很有价值的数据结构，因为它的内存分配是连续的，内存连续意味着可以让它在CPU缓存中待更久，所以迭代数组和移动元素都会非常迅速。 数组定义 1.通过指定数据类型和元素个数（数组长度）来声明数组。 12var array [5]int //声明一个长度为5的整数数组var array [5]int = [5]int&#123;1,2,3,4,5&#125; //声明一个长度为5的整数数组并初始化 2.一种快速创建和初始化数组的方法是使用数组字面值。数组字面值允许我们声明我们需要的元素个数并指定数据类型。 1array := [5]string&#123;"Linux", "Python", "Java", "Golang", "DBA"&#125; //声明一个长度为5的字符串数组并初始化每个元素 3.如果把长度写成…，go编译器将会根据元素来推导出长度 1array := [...]int&#123;1,2,3,4,5&#125; //通过初始化值的个数来推导出数组容量 4.如果知道想要数组的长度，但是希望对指定位置元素初始化。 1arry := [5]int&#123;1:1,3:3&#125; //声明一个长度为5的整数数组，为索引为1和3的位置指定元素初始化，剩余元素为该元素类型的默认值 注意:当一个数组被声明时，它里面包含的每个元素都会被初始化为该元素类型的默认值。一旦数组被声明了，那么它的数据类型和长度都不能再被改变。如果需要更多的元素，那么只能创建一个想要长度的新的数组，然后把原有数组的元素拷贝过去。 数组操作 使用内置函数len()和cap()返回数组长度和数组容量。 12345678package mainimport "fmt"func main()&#123; array := [2]int&#123;&#125; fmt.Printf("数组长度：%d，数组容量：%d\n", len(array), cap(array))&#125; 运行结果: 1数组长度：2，数组容量：2 使用[]操作符来访问数组元素： 123//改变索引为2的元素的值：array := [5]int&#123;1,2,3,4,5&#125;array[2] = 100 注意：数组可以通过下标进行访问，数组下标是从0开始，最后一个元素下标是：len(array)-1。如果下标在数组合法范围之外，则触发访问越界。数组赋值操作，一个数组可以被赋值给任意相同类型的数组： 123var arr1 [5]stringarr2 := [5]string&#123;"Linux", "Python", "Java", "Golang", "DBA"&#125;arr1 = arr2 注意：数组的类型同时包括数组的长度和可以被存储的元素类型，数组类型完全相同才可以互相赋值。 多维数组 数组总是一维的，但是可以组合成多维的。多维数组通常用于有父子关系的数据或者是坐标系数据： 1234var array [3][6]int //声明一个二维数组array := [4][2]int&#123;&#123;10, 11&#125;, &#123;20, 21&#125;, &#123;30, 31&#125;, &#123;40, 41&#125;&#125; //使用数组字面值声明并初始化array := [4][2]int&#123;1: &#123;20, 21&#125;, 3: &#123;40, 41&#125;&#125; //指定外部数组索引位置初始化array := [4][2]int&#123;1: &#123;1, 2&#125;, 3: &#123;1: 41&#125;&#125; //同时指定内外部数组索引位置初始化 使用内置函数len()和cap返回多维数组长度和多维数组容量。 12345678package mainimport "fmt"func main() &#123; array := [3][6]int&#123;&#125; fmt.Printf("数组长度：%d，数组容量：%d\n", len(array), cap(array))&#125; 运行结果： 1数组长度：3，数组容量：3 Go语言类型转换 类型转换用于将一种数据类型的变量转换为另一种类型的变量。Go语言类型转换基本格式如下：表达式T(v)将值v转换为类型T。 Go语言各种类型转换及函数的高级用法：strconv包实现了基本数据类型和其字符串表示的相互转换。 字符串转字节 123456789101112package mainimport ( "fmt" "reflect")func main() &#123; var str string = "hello" result := []byte(str) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 32位整型转字节 1234567891011121314151617package mainimport ( "bytes" "encoding/binary" "fmt" "reflect")func main() &#123; var x int32 x = 100 bytesBuffer := bytes.NewBuffer([]byte&#123;&#125;) binary.Write(bytesBuffer, binary.BigEndian, x) result := bytesBuffer.Bytes() fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 字节转字符串 123456789101112package mainimport ( "fmt" "reflect")func main() &#123; var b []byte = []byte&#123;111, 108, 100, 98, 111, 121&#125; result := string(b) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 整型转字符串 1234567891011121314package mainimport ( "fmt" "reflect" "strconv")func main() &#123; var x int x = 100 result := strconv.Itoa(x) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; FormatInt 将 int 型整数 i 转换为字符串形式base：进位制（2 进制到 36 进制） 大于 10 进制的数，返回值使用小写字母 ‘a’ 到 ‘z’ 1func FormatInt(i int64, base int) string Itoa 相当于 FormatInt(i, 10) 64位整形转字符串 1234567891011121314package mainimport ( "fmt" "reflect" "strconv")func main() &#123; var i int64 i = 0x100 result := strconv.FormatInt(i, 10) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 布尔值转字符串 1234567891011121314package mainimport ( "fmt" "reflect" "strconv")func main() &#123; t := strconv.FormatBool(true) f := strconv.FormatBool(false) fmt.Printf("t is %v , t type is %v\n", t, reflect.TypeOf(t)) fmt.Printf("f is %v , f type is %v\n", f, reflect.TypeOf(f))&#125; 浮点数转字符串 1234567891011121314151617181920212223242526strconv.FormatFloat(f,fmt,prec,bitSize)f：要转换的浮点数 fmt：格式标记（b、e、E、,f、g、G） prec：精度（数字部分的长度，不包括指数部分） bitSize：指定浮点类型（32:float32、64:float64）格式标记： ‘b’ (-ddddp±ddd，二进制指数) ‘e’ (-d.dddde±dd，十进制指数) ‘E’ (-d.ddddE±dd，十进制指数) ‘f’ (-ddd.dddd，没有指数) ‘g’ (‘e’:大指数，’f’:其它情况) ‘G’ (‘E’:大指数，’f’:其它情况)package mainimport ( "fmt" "reflect" "strconv")func main() &#123; f := 100.12345678901234567890123456789 result := strconv.FormatFloat(f, 'e', 30, 32) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; int转int64 123456789101112package mainimport ( "fmt" "reflect")func main() &#123; var x int = 100 result := int64(x) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 字符串转整形 1234567891011121314package mainimport ( "fmt" "reflect" "strconv")func main() &#123; var str string str = "100" result, _ := strconv.Atoi(str) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 字节转32位整形 12345678910111213141516package mainimport ( "bytes" "encoding/binary" "fmt" "reflect")func main() &#123; b := []byte&#123;0x00, 0x00, 0x03, 0xe8&#125; bytesBuffer := bytes.NewBuffer(b) var result int32 binary.Read(bytesBuffer, binary.BigEndian, &amp;result) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result)) float32转float64 123456789101112package mainimport ( "fmt" "reflect")func main() &#123; var x float32 = 100 result := float64(x) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 整型转浮点型 123456789101112package mainimport ( "fmt" "reflect")func main() &#123; var x int = 100 result := float32(x) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 字符串转浮点数 1234567891011121314151617181920strconv.ParseFloat(str,bitSize)str：要转换的字符串bitSize：指定浮点类型（32:float32、64:float64）如果 str 是合法的格式，而且接近一个浮点值，则返回浮点数的四舍五入值（依据 IEEE754 的四舍五入标准）如果 str 不是合法的格式，则返回“语法错误”如果转换结果超出 bitSize 范围，则返回“超出范围”package mainimport ( "fmt" "reflect" "strconv")func main() &#123; var str string = "0.12345678901234567890" result, _ := strconv.ParseFloat(str, 32) fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 字符串转布尔值 12345678910111213141516ParseBool 将字符串转换为布尔值 它接受真值：1, t, T, TRUE, true, True 它接受假值：0, f, F, FALSE, false, False. 其它任何值都返回一个错误package mainimport ( "fmt" "reflect" "strconv")func main() &#123; result, _ := strconv.ParseBool("1") fmt.Printf("result is %v , result type is %v\n", result, reflect.TypeOf(result))&#125; 注意：Go语言不能将其他类型当bool值使用]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（二）]]></title>
    <url>%2Fposts%2F3853503483.html</url>
    <content type="text"><![CDATA[Go语言变量 变量来源于数学，是计算机语言中能储存计算结果或能标识值抽象概念。变量可以通过变量名访问。Go语言是静态类型语言，不能在运行期间改变变量类型。使用关键字var定义变量，自动初始化为零值。如果提供初始化值，可省略变量类型，由编译器自动推断。Go语言中变量可以在三个地方声明： 函数外定义的变量称为全局变量：在函数体外声明，可以在整个包甚至外部包（被导出后）使用 函数内定义的变量称为局部变量：在函数体内部声明，作用域只在函数体内，参数和返回值变量也是局部变量 函数定义中的变量称为形式参数：会作为函数的局部变量来使用 变量声明 1234567891011121314151617181920212223242526272829303132333435var name string //指定变量类型，声明后若不赋值，使用默认值var age = 18 //根据值自行判定变量类型var class string = "linux" //变量声明并赋值//一次声明多个变量var Mon,Tues,Wed,Thur,Fri,Sat,Sun, intvar ( Monday int Tuesday int Wednesday int Thursday int Friday int Saturday int Sunday int )//短变量声明，在函数内部，可以使用更简略的":="方式定义变量。":="简洁赋值语句在明确类型的地方可以用于替代var定义,":="结构不能在函数外使用package mainfunc main()&#123; name := "haha" age,class :=18,"linux" _, _, _ = name,age,class&#125;//形式参数package mainfunc main() &#123;&#125;func sum(a,b int) (c init)&#123; c = a + b return&#125; 变量优先级 Go语言程序中全局变量与局部变量名称可以相同，但是函数内的局部变量会被优先使用。多变量赋值时，先计算所有相关值，然后再从左到右依次赋值。 12345678package mainimport "fmt"func main()&#123; data, i := [4]string&#123;"course", "Python", "Linux", "Golang"&#125;, 0 i, data[i] = 2,"haha" fmt.Printf("i：%v，data：%v\n", i, data)&#125; 输出结果: 1i:2,data:[haha Python Linux Golang] Go语言常量 常量是一个简单值的标识符，在程序运行时，永远是只读，不能修改。使用const关键字定义常量。常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。 常量定义 123456789101112131415161718const name string = "haha" //显式类型定义const age = 18 //隐式类型定义，一个未指定类型的常量由上下文来决定其类型//一次性定义多个常量const Mon, Tues, Wed, Thur, Fri, Sat, Sun = 1, 2, 3, 4, 5, 6, 7const ( name = "haha" age = 18)//常量可以用len(),cap()，unsafe.Sizeof()函数计算表达式的值。常量表达式中，函数必须是内置函数，否则编译不通过const ( a = "abc" b = len(a) c = unsafe.Sizeof(b)) 常量技巧 未使用的局部常量不会引发编译错误。在常量组中，如不提供类型和初始化值，那么视作与上一个常量相同。 特殊常量 特殊常量，iota,可以认为是一个可以被编译器修改的常量。在每一个const关键字出现时，被重置为0，然后在下一个const出现之前，每出现一次iota，其所代表的数字会自动增加1。 关键字iota定义常量组中从0开始按行计数的自增枚举值。实例如下： 12345678910111213141516171819package mainimport ( "fmt")const ( Sunday = iota Monday Tuesday Wednesday Thursday Friday Saturday)func main() &#123; fmt.Println(Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)&#125; 运行结果： 10 1 2 3 4 5 6 在同一常量组中，可以提供多个iota，他们各自增长。实例如下： 1234567891011121314package mainimport ( "fmt")const ( A1,B1 = iota,iota &lt;&lt;10 A2,B2)func main() &#123; fmt.Println(A1,B1,A2,B2)&#125; 运行结果： 10 0 1 1024 如果iota自增被打断，须显式恢复。实例如下： 12345678910111213141516171819package mainimport ( "fmt")const ( Sun = iota Mon Tues Wed = "Wednesday" Thur Fri = iota Sat)func main() &#123; fmt.Println(Sun, Mon, Tues, Wed, Thur, Fri, Sat)&#125; 运行结果： 10 1 2 Wednesday Wednesday 5 6 Go语言包和文件 工作空间 Go语言工作空间：编译工具对源码目录有严格要求，每个工作空间（workspace）必须由bin、pkg、src三个目录组成。 src:项目源码目录，里面每一个子目录，就是一个包，包内是Go语言的源码文件。pkg：Go语言编译的.a中间文件存放目录，可自动生成。bin：Go语言编译可执行文件存放目录，可自动生成。 包结构 包是结构化代码的一种方式：每个程序都由包的概念组成，可以使用自身的包或者从其他包中导入内容。如同其他一些编程语言中的类库或命名空间的概念，每个Go文件都属于且仅属于一个包。一个包可以由许多以.go为扩展名的源文件组成，因此文件名和包名一般来说都不是相同的。包声明“package + 包名”，必须在源文件中非注释的第一行指明这个文件属于哪个包。如：package main。package main表示一个可独立执行的程序，每个Go应用程序都包含一个名为main的包。同一个包（package）下面，可以有非常多的不同文件，只要每个文件的头部都有相同name就可以。文件夹名称和可以和这个package名称不一致。 标准库 在Go的安装文件里包含了一些可以直接使用的包，即标准库。Go语言标准库包，覆盖了几乎所有的基础库，提供了丰富广泛的功能特性。标准库的内容还可能继续增加，可以通过在线查阅库API或使用godoc（包含在Go发布包中）来获取最新信息及全面了解每个包所具备的功能。 第三方库 通过“go get + 完整包名”保存下载第三方库。在执行go get命令之前，确保配置了环境变量GOPATH，并且安装了git。 导出包 在Go语言中根据首字母的大小写来确定可以访问的权限。如果首字母大写，则可以被其他的包访问；如果首字母小写，则只能在本包中使用。该规则适用于全局变量、全局常量、类型、结构字段、函数、方法等。可以简单的理解成，首字母大写是公有的，首字母小写是私有的。在导入包之后，只能访问包所导出的名字，任何未导出的名字是不能被包外的代码访问的。 导入包 使用包成员前，必须先用import关键字导入，但不能形成导入循环。import用法： 123456import "fmt" //导入系统包import "./test" //相对路径导入包，导入同一目录下test包中的内容import "test/app" //绝对路径导入包，导入gopath/sr/tset/app包中的内容import f "fmt" //导入包并启用别名为fimport . "fmt" //将fmt启用别名"."，这样就可以直接使用其内容，而不用在添加fmt，如fmt.Println可以直接写成Printlnimport _ "fmt" //表示不使用该包，而是只是使用该包的init函数，并不显示的使用该包的其他内容。这种形式的import，当import时就执行了fmt包中的init函数，而不能够使用该包的其他函数 注意:未使用的导入包，会被编译器视为错误（不包括”import _“）。 编码格式 Go语言源码文件编码格式必须是UTF-8格式，否则会导致编译器出错。 结束语句 在Go程序中，一行代表一个语句结束。每个语句不需要像其他语言一样以分号“;”结尾，因为这些工作都将由Go编译器自动完成。如果打算将多个语句写在同一行，他们则必须使用“;”人为区分。 代码注释 注释不会被编译，每一个包应该有相关注释。Go语言代码注释支持 “//“、”/**/“ 两种注释方式，不能嵌套。单行注释是最常见的注释形式，你可以在任何地方使用以 // 开头的单行注释。多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾。 Go程序启动执行顺序 按顺序导入所有被main包引用的其他包，然后在每个包中执行如下流程：如果该包又导入了其他的包，则从第一步开始递归执行，但是每个包只会被导入一次。然后以相反的顺序在每个包中初始化常量和变量，如果该包含后init函数的话，则调用该函数。在完成这一切之后，main也执行同样的过程，最后调用main函数开始执行程序。]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记（一）]]></title>
    <url>%2Fposts%2F3585681187.html</url>
    <content type="text"><![CDATA[Go语言简介 Go语言是谷歌2009发布的第二款开源编程语言。Go语言专门针对多处理器系统应用程序的编程进行了优化，使用Go编译的程序可以媲美C或C++代码的速度，而且更加安全、支持并行进程。 Go语言主要特征 可直接编译成机器码，不依赖其他库，glibc的版本有一定要求，部署就是扔一个文件上去就完成了。 静态类型语言，但是有动态语言的感觉，静态类型的语言就是可以在编译的时候检查出来隐藏的大多数问题，动态语言的感觉就是有很多的包可以使用，写起来的效率很高。 语言层面支持并发，这个就是Go语言最大的特色，可以充分的利用多核，很容易的使用并发。 内置runtime，支持垃圾回收，这属于动态语言的特性之一吧，虽然目前来说GC不算完美，但是足以应付我们所能遇到的大多数情况，特别是Go1.1之后的GC。 简单易学，Go语言的作者都有C的基因，那么Go自然而然就有了C的基因，那么Go关键字是25个，但是表达能力很强大，几乎支持大多数你在其他语言见过的特性：继承、重载、对象等。 丰富的标准库，Go目前已经内置了大量的库，特别是网络库非常强大。 内置强大的工具，Go语言里面内置了很多工具链，最好的应该是gofmt工具，自动化格式化代码，能够让团队review变得如此的简单，代码格式一模一样，想不一样都很困难。 跨平台编译，如果你写的Go代码不包含cgo，那么就可以做到window系统编译linux的应用，如何做到的呢？Go引用了plan9的代码，这就是不依赖系统的信息。 内嵌C语言支持，前面说了作者是C语言的作者，所以Go语言里面也可以直接包含C语言代码，利用现有的丰富的C语言库。 Go语言标准命令解释 123456789101112go env #用于打印GO语言的环境信息go run #命令可以编译并运行命令源码文件go get #可以根据要求和实际情况从互联网下载或更新指定的代码包及其依赖包，并对他们进行编译和安装go build #用于编译指定的源码文件或代码包以及它们的依赖包go install #用于编译并安装指定的代码包及它们的依赖包go clean #命令会删除掉执行其他命令时产生的一些文件和目录go doc #命令可以打印附于Go语言程序实体上的文档，我们可以通过把程序实体的标识符作为该命令的参数来达到查看其文档的目的go test #命令用于对Go语言编写的程序进行测试go list #命令的作用是列出指定的代码包的信息go fix #会把指定代码包的所有Go语言源码文件中的旧版本代码修正为新版本的代码go vet #是一个用于检查Go语言源码中静态错误的简单工具go tool pprof #交互式的访问概要文件的内容 Go关键字及用途 关键字 用途 var 用于变量声明 const 用于常量声明 type 用于类型声明 func 用于声明函数和方法 package 用于声明包文件 import 用于导入其他package return 用于从函数返回 defer 延迟调用，在函数退出之前执行 go 创建一个协程 select 用于选择不同类型的通讯 interface 用于定义接口 struct 用于定义数据类型 break、case、continue、for、fallthrough、else、if、switch、goto、default 用于流程控制 chan 用于声明chan类型数据 map 用于声明map类型数据 range 用于遍历array、slice、map、channel数据类型 Go语言保留字 Go语言有37个保留字： 作用域 保留字 Constants(常量) true false iota nil Types（类型） int int8 int16 int 32 int64uint uint8 uint16 uint32 uint64 uintptrfloat32 float64 complex128 complex64bool byte rune string error Functions(方法) make len cap new append copy close deletecomplex real imagpanic recover Go语言命名规范 Go语言的包（package）、变量、常量、自定义类型、函数、方法的命名方式遵循以下规则： 首字符可以是任意的Unicode字符或者下划线 剩余字符可以是Unicode字符、下划线、数字 字符长度不限 不要使用Go语言的关键字和保留字命名 Go语言内置类型和函数 内置类型 类型 长度（字节） 默认值 说明 bool 1 false bool类型代表逻辑值，有true（真）和false（假）两种取值 byte 1 0 是int8的别名 rune 4 0 是int32的别名，代表Unicode代码点 int,uint 4或8（和系统有关） 0 int有符号整数、uint无符号整数 int8,uint8 1 0 int8:-128~127uint8:0~255byte是uint8的别名 int16,uint16 2 0 int16：-32768~32767uint16:0~65535 int32,uint32 4 0 int32:-2147483648~2147483647uint32:0~4294967295rune是int32的别名 int64,unint64 8 0 int64:-9223372036854775808~9223372036854775807uint64:0~18446744073709551615 float32 4 0 单精度浮点型 float64 8 0 双精度浮点型 complex64 8 (0+0i) 复数类型 complex128 16 (0+0i) 复数类型 uintptr 4或8（和系统有关） 0 指针类型存储指针的uint32或uint64整数 array 默认值要根据其数据类型确定var a[4]int,其默认值为[0 0 0 0] 值类型 struct 默认值要根据其数据类型来确定 值类型 string “” UTF-8字符串 slice nil 引用类型 map nil 引用类型 channel nil 引用类型 interface nil 接口类型 function nil 函数类型 error nil 错误类型 内置函数 Go语言拥有一些不需要进行导入操作就可以使用的内置函数。它们有时可以针对不同类型进行操作，例如：len、cap、和append，或必须用于系统级的操作，例如：panic。因此，它们需要直接获得编译器的支持。 函数 说明 append 用来追加元素到slice中，返回修改后的slice close 主要用来关闭channel delete 从map中删除key对应的value panic 停止常规的goroutine（panic和recover：用来做错误处理） recover 允许程序定义goroutine的panic动作 imag 返回complex的实部（complex、real imag:用于创建和操作复数） real 返回complex的虚部 make 用来分配内存，返回Type本身（只能应用于slice、map、channel） new 用来分配内存，主要用来分配值类型，比如int，struct。返回指向Type的指针 cap 用于求最大容量，比如array、slice、channel，返回最大容量 len 用于求长度，比如string、array、slice、map、channel，返回长度 print,println 底层打印函数，在部署环境中建议使用fmt包 内置接口error 只要实现了Error()函数，返回值为String,就实现了error接口 1234type error interface &#123; Error() String&#125; Go语言特殊函数 main函数 Go语言程序的默认入口函数（主函数）：func main()函数体用{}一对括号包裹。只能应用于package main 123func main()&#123; //函数体&#125; init函数 go语言中init函数用于包package的初始化，该函数是go语言的一个重要特性。init函数有以下的特证： init函数是用于程序执行前做包的初始化函数，比如初始化包里的变量等。 每个包可以拥有多个init函数。 包的每个源文件也可以拥有多个init函数 同一个包中多个init函数的执行顺序go语言没有明确定义（说明） 不同包的init函数按照包导入的依赖关系决定该初始化函数的执行顺序 init函数不能被其他函数调用，而是在main函数执行之前，自动被调用 init函数和main函数的异同 相同点：两个函数在定义时不能有任何的参数和返回值，且Go程序自动调用。不同点:init函数可以应用于任意包中，且可以重复定义多个。main函数只能用于main包中，且只能定义一个。 两个函数的执行顺序对同一个go文件的init()调用顺序是从上到下的。对铜鼓一个package中不同文件是按文件名字符串比较“从小到大”顺序调用各文件中的init()函数。对于不同的package，如果不互相依赖的话，按照main包中“先import的后调用”的顺序调用其包中的init(),如果package存在依赖，则先调用最早被依赖的package中的init(),最后调用main函数。如果init函数中使用了println()或者print()，会发现在执行过程中这两函数不会按照想象中的顺序执行。这两个函数官方只推荐在测试环境中使用，对于正式环境不要使用。 Go语言运算符 运算符用于在程序运行时执行数学或逻辑运算。Go语言内置的运算符有：算术运算符、关系运算符、逻辑运算符、位运算符、赋值运算符、其他运算符。 算术运算符 运算符 描述 + 加 - 减 * 乘 / 除 % 求余 ++ 自增 – 自减 关系运算符 运算符 描述 == 检查两个值是否相等，如果相等返回 True 否则返回 False != 检查两个值是否不相等，如果不相等返回 True 否则返回 False &gt; 检查左边值是否大于右边值，如果是返回 True 否则返回 False &lt; 检查左边值是否小于右边值，如果是返回 True 否则返回 False &gt;= 检查左边值是否大于等于右边值，如果是返回 True 否则返回 False &lt;= 检查左边值是否小于等于右边值，如果是返回 True 否则返回 False 逻辑运算符 运算符 描述 &amp;&amp; 逻辑 AND 运算符。 如果两边的操作数都是 True，则条件 True，否则为 False &#124;&#124; 逻辑 OR 运算符。 如果两边的操作数有一个 True，则条件 True，否则为 False ! 逻辑 NOT 运算符。 如果条件为 True，则逻辑 NOT 条件 False，否则为 True 位运算符 运算符 描述 &amp; 按位与运算符“&amp;”是双目运算符。其功能是参与运算的两数各对应的二进位相与 &#124;&#124; 按位或运算符“&#124;”是双目运算符。其功能是参与运算的两数各对应的二进位相或 ^ 按位异或运算符“^”是双目运算符。其功能是参与运算的两数各对应的二进位相异或，当两数对应的二进位相异时，结果为1 &lt;&lt; 左移运算符“&lt;&lt;”是双目运算符。左移n位就是乘以2的n次方。 其功能把“&lt;&lt;”左边的运算数的各二进位全部左移若干位，由“&lt;&lt;”右边的数指定移动的位数，高位丢弃，低位补0 &gt;&gt; 右移运算符“&gt;&gt;”是双目运算符。右移n位就是除以2的n次方。 其功能是把“&gt;&gt;”左边的运算数的各二进位全部右移若干位，”&gt;&gt;”右边的数指定移动的位数。 赋值运算符 运算符 描述 = 简单的赋值运算符，将一个表达式的值赋给一个左值 += 相加后再赋值 -= 相减后再赋值 *= 相乘后再赋值 /= 相除后再赋值 %= 求余后再赋值 &lt;&lt;= 左移后赋值 &gt;&gt;= 右移后赋值 &amp;= 按位与后赋值 ^= 按位异或后赋值 &#124;= 按位或后赋值 其他运算符 运算符 描述 &amp; 取地址符，返回变量存储地址 * 取值符，返回指针的变量 运算符优先级 有些运算符拥有较高的优先级，二元运算符的运算方向均是从左至右。下表列出了所有运算符以及他们的优先级，由上至下代表优先级由高到低： 优先级 运算符 7 ^ ! 6 * / % &lt;&lt; &gt;&gt; &amp; &amp;^ 5 + - &#124; ^ 4 == != &lt; &lt;= &gt;= &gt; 3 &lt;- 2 &amp;&amp; 1 &#124;&#124; 特殊标识符 “_”是特殊标识符，又称占位符（空标识符号），用来忽略结果。 特殊标识符应用在import中在go语言里，import的作用是导入其他package。特殊标识符（如：import _ test/golang）的作用：当导入一个包时，该包下的文件里所有init()函数都会被执行，然而，有些时候我们并不需要把整个包都导入进来，仅仅是希望它执行init()函数而已。这个时候就可以使用import _ 引用包。即使用（import _ 引用包）只是引用该包，仅仅是为了调用init()函数，所以无法通过包名来调用包中的其他函数。 特殊标识符应用在代码中 1234567891011package mainfunc main()&#123; str, _ := test() _ = str&#125;func test() (str string,err erro)&#123; str = "hello" err = nil; return&#125; 占位符，意思是那个位置本应该赋值给某个值，但是不需要这个值。所以就把该赋值给站位符，意思是丢掉不要，这样编译器可以更好的优化，任何类型的单个值都可以丢给占位符。第一个占位符：这种情况是忽略函数返回值，函数返回两个结果，而只想要一个结果。第二个站位符：这种情况是忽略未使用的局部变量，如果声明的局部变量，不使用，编译器是会报错。 table th:nth-of-type(1) { width: 15%; } table th:nth-of-type(2) { width: 15%; } table th:nth-of-type(3) { width: 20%; } table th:nth-of-type(4) { width: 50%; }]]></content>
      <categories>
        <category>Go语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis主从复制和集群]]></title>
    <url>%2Fposts%2F655286048.html</url>
    <content type="text"><![CDATA[Redis主从复制 redis复制特性 使用异步复制 一个主服务器可以有多个从服务器 从服务也可以有自己的从服务器 复制功能不会阻塞主服务器 可以通过复制功能来让主服务器免于执行持久化操作，由从服务器去执行持久化操作即可 关闭主服务器持久化时，复制功能的数据安全 当配置Redis复制功能时，强烈建议打开主服务器的持久化功能。否则，由于延迟等问题，部署的服务应该要避免自动拉起。 为了帮助理解主服务器关闭持久化时自动拉起的危险性，参考一下会导致主从服务器数据全部丢失的例子： 假设节点A为主服务器，并且关闭了持久化，并且节点B和节点C从节点A复制数据 节点A崩溃，然后由自动拉起服务重启了节点A。由于节点A的持久化被关闭了，所以重启之后没有任何数据 节点B和节点C将从节点A复制数据，但是A的数据是空的，于是就把自身保存的数据副本删除 在关闭主服务器的持久化，并同时开启自动拉起进程的情况下，即便使用Sentinel来实现Redis的高可用性，也是非常危险的。因为主服务器可能拉起得非常快，以至于Sentinel在配置的心跳时间间隔内没有检测到主服务器已被重启，然后还是会执行上面的数据丢失流程。 无论何时，数据安全都是极其重要的，所以应该禁止主服务器关闭持久化的同时自动拉起。 主从复制原理 redis主从同步有两种方式（或者说两个阶段）：全同步和部分同步。 主从刚刚连接的时候，进行全同步；全同步结束后，进行部分同步。当然，如果有需要，slave在任何时候都可以发起全同步。 redis策略是，无论如何，首先会尝试进行部分同步，如不成功，要求从机进行全同步，并启动BGSAVE，BGSAVE结束后，传输RDB文件；如果成功，允许从机进行部分同步，并传输积压空间中的数据。 下图总结了主从同步机制： 主从复制过程： 从服务器向主服务器发送SYNC命令 接收到SYNC命令的主服务器会调用BGSAVE命令，创建一个RDB文件，并使用缓冲区记录接下来执行的所有命令 当主服务器执行完BGSAVE命令时，它会向从服务器发送RDB文件，而从服务器则会接收并载入这个文件 主服务器将缓冲区存储的所有写命令发送给从服务器执行 命令的传播在主从服务器完成同步之后，主服务器每执行一个写命令，他都会将被执行的写命令发送给从服务器执行，这个操作被称为“命令传播”（command propagate）。 命令传播是一个持续的过程：只要复制仍在继续，命令传播就会一直进行，使得主从服务器的状态可以一直保持一致。 复制中的SYNC与PSYNC 在Redis2.8版本之前，断线之后重连的从服务器总要执行一次完整重同步（full resynchronization）操作。 从Redis2.8开始，Redis使用PSYNC命令代替SYNC命令。PSYNC比起SYNC的最大改进在于PSYNC实现了部分重同步（partial resync）特性：在主从服务器断线并且重新连接的时候，只要条件允许，PSYNC可以让主服务器只向从服务器同步断线期间缺失的数据，而不用重新向从服务器同步整个数据库。 复制的一致性问题 在读写分离环境下，客户端向主服务器发送写命令SET n 1086，主服务器在执行这个写命令之后，向客户端返回回复，并将这个写命令传播给从服务器。接到回复的客户端继续向从服务器发送读命令GET n，并且因为网络状态的原因，客户端的GET命令比主服务器传播的SET命令更快到达了从服务器。因为从服务器键n的值还未被更新，所以客户端在从服务器读取到的将是一个错误（过期）的n值。 复制安全性提升 主服务器只在有至少N个从服务器的情况下，才执行写操作。从Redis2.8开始，为了保证数据的安全性，可以通过配置，让主服务器只在至少有N个当前已连接从服务器的情况下，才执行写命令。不过，因为Redis使用异步复制，所以主服务器发送的写数据并不一定会被从服务器接收到，因此，数据丢失的可能性仍然存在。通过以下两个参数保证数据的安全： 12min-slaves-to-write &lt;number of slaves&gt; # 从服务器个数min-slaves-max-lag &lt;number of seconds&gt; # 从服务器网络延迟（秒） 参数说明:如果至少有min-slaves-to-write个从服务器，并且这些服务器的延迟值都少于min-slaves-max-lag秒，主服务器就会执行客户端的写操作。这个特性看作CAP理论中的C的条件放宽版本: 尽管不能保证写操的持久性，但起码丢失数据的窗口会被严格限制在指定的秒数中。如果条件达不到min-slaves-to-write和min-slaves-max-lag所指定的条件，那么写操作就不会被执行，主服务器会向请求执行写操作的客户端返回一个错误。 Redis主从复制实践 启动多个Redis实例： 123redis-server /6380/redis.confredis-server /6381/redis.confredis-server /6382/redis.conf 配置文件示例： 12345678910111213bind 127.0.0.1port 6380pidfile /var/run/redi_6380.pidloglevel noticelogfile "/var/log/redis_6380.log"dbfilename dump.rdbdir /usr/local/redis/6380/appendonly noappendfilename "appendonly.aof"appendfsync everysecslowlog-log-slower-than 10000slowlog-max-len 128protected-mode no 复制环境说明： 主节点：6380 从节点：6381、6382 开启主从（在6381、6382实例中执行） 12redis-cli -p 6381/6382SLAVEOF 127.0.0.1 6380 Redis主从复制管理 主从复制状态监控：info replication主从切换：slaveof no one(在从库执行，将从库设为主库) Redis HA实践（Redis Sentinel） Redis-Sentinel是Redis官方推荐的高可用性（HA）解决方案，当用Redis做Master-salve的高可用方案时，假如master宕机了，Redis本身（包括它的很多客户端）都没有实现自动进行主备切换，而Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。 Sentinel是一个监视器，它可以根据被监视实例的身份和状态来判断应该执行何种动作。 Redis Sentinel功能 监控（Monitoring）：Sentinel会不断地检查主服务器和从服务器是否运作正常。提醒（Notification）：当被监控的某个Redis服务器出现问题时，Sentinel可以通过API向管理员或其他应用程序发送通知。自动故障迁移（Automatic failover）：当一个主服务器不能正常工作时，Sentinel会开始一次自动故障迁移操作，它会将失效主服务器的其中一个从服务器升级为新的主服务器，并让失效主服务器的其他从服务器改为复制新的主服务器；当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址，使得集群可以使用新主服务器代替失效服务器。 服务器连接 发现并连接主服务器:Sentinel通过用户给定的配置文件来发现主服务器。 Sentinel会与被监视的主服务器创建两个网络连接： 命令连接：用于向主服务器发送命令。 订阅连接：用于订阅指定的频道，从而发现监视同一主服务器的其他Sentinel。 发现并连接从服务器：Sentinel通过向主服务器发送INFO命令来自动获得所有从服务器的地址。跟主服务器一样，Sentinel会与每个被发现的从服务器创建命令连接和订阅连接。 发现其他Sentinel：Sentinel会通过命令连接向被监视的主从服务器发送“HELLO”信息，该消息包含Sentinel的IP、端口、ID等内容，以此来向其他Sentinel宣告自己的存在。与此同时Sentinel会通过订阅连接接收其他Sentinel的“HELLO”信息，以此来发现监视同一个主服务器的其他Sentinel。 sentinel1通过发送HELLO信息来让sentinel2和sentinel3发现自己，其他两个sentinel也会进行类似的操作。 多个Sentinel之间的连接：Sentinel之间只会互相创建命令连接，用于通信。因为已经有主从服务器作为发送和接收HELLO信息的中介，所以Sentinel之间不会创建订阅连接。 Redis的Sentinel中关于下线（down）有两个不同的概念：主观下线（Subjectively Down，简称SDOWN）指的是单个Sentinel实例对服务器做出的下线判断。客观下线（Objectively Down，简称ODOWN）指的是多个Sentinel实例在对同一个服务器做出SDOWN判断，并且通过SENTINEL is-master-down -by-addr命令互相交流之后，得出的服务器下线判断。（一个Sentinel可以通过向另一个Sentinel发送SENTINEL is-master-down-by-addr命令来询问对方是否认为给定的服务器已下线。） 如果一个服务器没有在master-down-after-milliseconds选项所指定的时间内，对向它发送PING命令的Sentinel返回一个有效回复（valid reply），那么Sentinel就会将这个服务器标记为主观下线。 故障转移FAILOVER 一次故障转移操作由以下步骤组成： 发现主服务器已进入客观下线状态； 基于Raft leader election协议，进行投票选举； 如果当选失败，那么在设定的故障迁移超时时间的两倍之后，重新尝试当选。如果当选成功，那么执行以下步骤； 选出一个从服务器，并将它升级为主服务器； 向被选中的从服务器发送SLAVEOF NO ONE命令，让它转变为主服务器； 通过发布与订阅功能，将更新后的配置传播给所有其他Sentinel，其他Sentinel对他们自己的配置进行更新； 向已下线主服务器的从服务器发送SLAVEOF命令，让它们去复制新的主服务器； 当所有从服务器都已经开始复制新的主服务器时，leader Sentinel终止这次故障迁移操作。 配置sentinel 创建程序目录 1234cd /applicationmkdir 26380cp /usr/local/redis/src/redis-sentinel ./26380/cd 26380 编辑配置文件 1234567vim sentinel.conf# 写入以下配置port 26380dir "/tmp"sentinel monitor mymaster 127.0.0.1 6370 2sentinel down-after-milliseconds mymaster 60000sentinel config-epoch mymaster 0 启动sentinel 1./redis-sentinel ./sentinel.conf 配置文件说明： 123456789101112# 指定监控mastersentinel monitor mymaster 127.0.0.1 6370 2# 2表示多少个sentinel同意# 安全信息sentinel auth-pass mymaster root# 超过15000毫秒后认为主机宕机sentinel down-after-milliseconds mymaster 15000# 当主从切换多久后认为主从切换失败sentinel failover-timeout mymaster 900000# 这两个配置后面的数量主从机需要一样，epoch为master的版本sentinel leader-epoch mymaster 1sentinel config-epoch mymaster 1 Sentinel命令操作 命令 描述 PING 返回PONG SENTINEL masters 列出所有被监视的主服务器 SENTINEL slaves 列出指定master的所有slave及它们的状态 SENTINEL get-master-addr-by-name 返回给定名字的服务器的IP地址和端口号 SENTINEL reset 重置所有名字和给定模式pattern相匹配的主服务器 SENTINEL failover 当主服务器失效时，在不询问其他Sentinel意见的情况下，强制开始一次自动故障迁移 Sentinel发布与订阅信息 客户端可以将Sentinel看作是一个只提供了订阅功能的Redis服务器：不可以使用PUBLISH命令向这个服务器发送信息，但可以用SUBSCRIBE命令或PSUBSCRIBE命令，通过订阅给定的频道来获取相应的事件提醒。一个频道能够接受和这个频道的名字相同的事件。比如：名为 + sdown的频道就可以接受所有实例进入主观下线（SDOWN）状态的事件。通过执行PSUBSCRIBE * 命令可以接收所有事件信息。以下列出的是客户端可以通过订阅来获得的频道和信息的格式：第一个英文单词是频道 / 事件的名字，其余的是数据的格式 注意：当格式中包含instance details字样时，表示频道所返回的信息中包含了以下用于识别目标实例的内容： 12&lt;instance-type&gt;&lt;name&gt;&lt;ip&gt;&lt;port&gt;@&lt;master-name&gt;&lt;master-ip&gt;&lt;master-port &gt;@字符之后的内容用于指定主服务器，这些内容是可选的，它们仅在@字符之前的内容指定的实例不是主服务器时使用。 Redis cluster(集群) Redis集群 Redis集群是一个可以在多个Redis节点之间进行数据共享的设施（installation）。Redis集群不支持那些需要同时处理多个键的Redis命令，因为执行这些命令需要在多个Redis节点之间移动数据，并且在高负载的情况下，这些命令将降低Redis集群的性能，并导致不可预测的行为。Redis集群通过分区（partition）来提供一定程度的可用性（availability）：即使集群中一部分节点失效或者无法进行通讯，集群也可以继续处理命令请求。将数据自动切分（split）到多个节点的能力。当集群中的一部分节点失效或者无法进行通讯时，仍然可以继续处理命令请求的能力。 Redis集群数据共享 Redis集群使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现：一个Redis集群包含16384个哈希槽（hash slot），数据库中的每个键都属于这16384个哈希槽的其中一个，集群使用公式CRC16（key）% 16384来计算键key属于哪个槽，其中CRC16（key）语句用于计算键key的CRC校验和。 节点A负责处理0号至5500号哈希槽节点B负责处理5501号至11000号哈希槽节点C负责处理11001号至16384号哈希槽 槽的计算公式： CRC16(key) % 16383 集群运行机制 所有的redis节点彼此互联（PING-PONG机制），内部使用二进制协议优化传输速度和带宽。节点的fail是通过集群中超过半数的master节点检测失效时才失效。客户端与redis节点直连，不需要中间proxy层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。把所有的物理节点映射到[0-16383]slot上，cluster负责维护nodeslotkey 为了使得集群在一部分节点下线或者无法与集群的大多数（majority）节点进行通讯的情况下，仍然可以正常运作，Redis集群对节点使用了主从复制功能：集群中的每个节点都有1个至N个复制品（replication），其中一个复制品为主节点（master），而其余的N - 1个复制品为从节点（slave）。 在之前列举的节点A、B、C的例子中，如果节点B下线了，那么集群将无法正常运行，因为集群找不到节点来处理5501号至11000号的哈希槽。假如在创建集群的时候（或者至少在节点B下线之前），我们为主节点B添加了从节点B1，那么当主节点B下线的时候，集群就会将B1设置为新的主节点，并让它代替下线的主节点B, 继续处理5501号至11000号的哈希槽，这样集群就不会因为主节点B的下线而无法正常运作了。不过，如果节点B和B1都下线的话，Redis集群还是会停止工作。 集群的复制特性重用了SLAVEOF命令代码，所以集群节点的复制行为和SLAVEOF命令的复制行为完全相同。 集群的故障转移 在集群里面，节点会对其他节点进行下线检测。 当一个主节点下线时，集群里面的其它主节点会负责对下线主节点进行故障转移。 换句话说，集群的节点集成了下线检测和故障转移等类似Sentinel的功能。 因为Sentinel是一个独立运行的监控程序，而集群的下线检测和故障转移等功能是集成在节点里面的，它们的运行模式非常地不同，所以尽管这两者功能很相似，但集群的实现没有重用Sentinel的代码。 在集群里执行命令的两种情况： 命令发送到了正确的节点：命令要处理的键所在的槽正好是由接收命令的节点负责，那么该节点执行命令，就像单机Redis服务器一样。 槽位说明：7000：槽0~5000 7001：槽5001~10000 7002：槽10001~16383键date位于2022槽，该槽由节点7000负责，命令会直接执行。 命令发送到了错误的节点：接收到命令的节点并非处理键所在槽的节点，那么节点将向客户端返回一个转向（redirection）错误，告知客户端应该到哪个节点去执行这个命令，客户端会根据错误提示的信息，重新向正确的节点发送命令。 键date位于2022槽，该槽点由7000负责，但错误发送到了7001节点，7001向客户返回转向错误。客户端根据转向错误的指引，转向到节点7000，并重新发送命令。 关于转向错误 在集群中的节点会互相告知对方，自己负责处理哪些槽点。集群中的每个节点都会记录16384个槽分别由哪个节点负责，从而形成一个“槽表”（slot table）。节点在接收到命令请求时，会通过槽表检查键所在的槽是否由本节点处理： 如果是，那么节点直接执行命令 如果不是，那么节点就从槽表里面提取出正确节点的地址信息，然后返回转向错误。 配置集群 12345yum install centos-release-scl-rh # 会在/etc/yum.repos.d/目录下多出一个CentOS-SCLo-scl-rh.repo源yum install rh-ruby23 -yscl enable rh-ruby23 bash # 必须执行ruby -v # 查看ruby版本gem install redis-v4.1.0 # redis-trib 工具执行需要安装redis gem才能执行 配置文件Redis集群由多个运行在集群模式（cluster mode）下的Redis实例组成，实例的集群模式需要通过配置来开启，开启集群模式的实例将可以使用集群特有的功能和命令。以下是一个包含了最少选项的集群配置文件示例： 12345port 7000cluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000appendonly yes 创建程序目录 12cd /application/redismkdir 7000 7001 7002 7003 7004 7005 拷贝应用 123for i in 0 1 2 3 4 5do cp /usr/local/redis/bin/redis-server ./700$idone 创建配置文件 123456789for i in 7000 7001 7002 7003 7004 7005doecho "port $icluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000appendonly yesdaemonize yes"&gt;$i/redis.confdone 启动redis集群 123456for i in 7000 7001 7002 7003 7004 7005do cd $i ./redis-server ./redis.conf &amp; cd ../done 创建集群 12cd /usr/local/redis/src/./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 给定redis-trib.rb程序的命令是create，表示创建一个新的集群。选项–replicas 1 表示集群中的每个主节点创建一个从节点。 集群管理 写数据，查看集群状态 123redis-cli -c -p 7000 #-c连接集群结点时使用，此选项可防止moved和ask异常set foo barget foo 重新分片实践 12cd /usr/local/redis/src/./redis-trib.rb reshard 127.0.0.1:7000 集群状态 1redis-cli -p 7000 cluster nodes | grep master 故障转移 1redis-cli -p 7002 debug segfault 查看状态 1redis-cli -p 7000 cluster info | grep master 增加新的节点 1./redis-trib.rb add-node 127.0.0.1:7006 127.0.0.1:7000 删除一个节点 1redis-trib del-node ip:port '&lt;node-id&gt;' 删除master节点之前首先使用reshard移除master的全部slot，然后再删除当前节点添加一个从节点 1./redis-trib.rb add-node--slave --master-id $[nodeid] 127.0.0.1:7008 127.0.0.1:7000 状态说明 1234[root@localhost ~]#redis-cli -p 7000 cluster nodes | grep master35b7fac5750c997412dc6826802bfb78d5b81abf 127.0.0.1: 7001@17001 master - 0 1548925480000 2 connected 5461 - 109223c3106bd8740706bebe2341e90d08554ab2bcd52 127.0.0.1: 7000@17000 myself, master - 0 1548925480000 1 connected 0 - 5460e190049acbd61ecb16e82cca3d6aa06dd0927305 127.0.0.1: 7002@17002 master - 0 1548925481046 3 connected 10923 - 16383 集群最近一次向节点发送PING命令之后，过去了多长时间还没接到回复。节点最近一次返回PONG回复的时间。节点的配置节点（configuration epoch）。本节点的网络连接情况：例如connected。节点目前包含的槽：例如127.0.0.1: 7001目前包含号码为 5461 - 10922的哈希槽。 使用redis-py-cluster模块操作redis集群 1pip install --default-timeout=100 redis-py-cluster #安装redis-py-cluster扩展 python连接redis代码： 1234567891011121314151617#!/usr/bin/env python# -*- coding: utf-8 -*-from rediscluster import StrictRedisClusterredis_nodes = [&#123;'host': '127.0.0.1', 'port': 7000&#125;, &#123;'host': '127.0.0.1', 'port': 7001&#125;, &#123;'host': '127.0.0.1', 'port': 7002&#125;, &#123;'host': '127.0.0.1', 'port': 7003&#125;, &#123;'host': '127.0.0.1', 'port': 7004&#125;, &#123;'host': '127.0.0.1', 'port': 7005&#125; ]try: redisconn = StrictRedisCluster(startup_nodes=redis_nodes) redisconn.set('name', 'admin') print("name is: ", redisconn.get('name'))except Exception: print("Connect Error!") redis-py-cluster官方文当]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Redis集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[echo 0 > /proc/sys/kernel/hung_task_timeout_secs disables this message故障处理]]></title>
    <url>%2Fposts%2F3397780315.html</url>
    <content type="text"><![CDATA[用xshell连接服务器出错:ssh_exchange_identification: Connection closed by remote host在阿里云控制台通过vnc连接服务器后出现如下信息： 问题原因：默认情况下，linux会最多使用40%的可用内存作为文件系统缓存。当超过此阈值后，文件系统会将缓存中的内存全部写入磁盘，导致后续的I/O请求都是同步的。将缓存写入磁盘时，有一个默认120秒的超时时间。出现上面问题的原因是I/O子系统的处理速度不够快，不能在120秒将缓存中的数据全部写入磁盘。I/O系统响应缓慢，导致越来越多的请求堆积，最终系统内存全部被占用，导致系统失去响应。 解决方法根据应用程序情况，对vm.dirty_ratio:当文件系统缓存脏页数量达到系统内存百分之多少时（如10%），系统不得不开始处理缓存脏页（因为此时脏页数量已经比较多，为了避免数据丢失需要将一定脏页刷入外存）；在此过程中很多应用进程可能会因系统转而处理文件I/O而阻塞vm.dirty_background_ratio:当文件系统缓存脏页数量达到系统内存百分之多少时（5%）就会触发pdflush/flush/kdmflush等后台会写进程运行，将一定缓存的脏页异步地刷入外存两个参数进行调优设置 。推荐如下设置： 123sysctl -w vm.dirty_ratio=10sysctl -w vm.dirty_background_ratio=5sysctl -p 如果让系统永久生效 123echo "vm.dirty_background_ratio = 5"&gt;&gt;/etc/sysctl.confecho "vm.dirty_ratio = 10"&gt;&gt;/etc/sysctl.confsysctl -p]]></content>
      <categories>
        <category>linux系统故障</category>
      </categories>
      <tags>
        <tag>hung_task_timeout_secs disables this message</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis管理]]></title>
    <url>%2Fposts%2F2273748276.html</url>
    <content type="text"><![CDATA[基本数据类型 类型 说明 String 字符串 Redis字符串数据类型的相关命令用于管理redis字符串值 Hash 哈希 Redishash是一个string类型的field和value的映射表，hash特别适合由于存储对象。Redis中每个hash可以存储2³²-1键值对（40多亿）。 List 列表 Redis列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素到列表的头部或尾部一个列表最多可以包含2³²-1个元素（4294967295, 每个列表超过40亿个元素）。 Set 集合 Redis的Set是String类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Sorted set 有序集合 Redis有序集合和集合一样也是string类型元素的集合，且不允许重复的成员。 全局key操作 命令 含义 KEYS * 查看KEY，支持通配符 DEL 删除给定的一个或多个key EXISTS 检查是否存在 RENAME 变更key名 SORT 键值排序，有非数字时报错 TYPE 返回键所存储值的类型 DUMP\RESTORE 序列化与反序列化 EXPIRE\PEXPIRE 以秒\毫秒设定生存时间 TTL\PTTL 以秒\毫秒为单位返回生存时间 PERSIST 取消生存时间设置 RANDOMKEY 返回数据库中的任意键 String（字符串） 命令 描述 SET key value 设置指定key的值 GET key 获取指定key的值 GETRANGE key start end 返回key中字符串值的子字符 GETSET key value 将给定key的值设为value，并返回key的旧值（old value） GETBIT key offset 对key所存储的字符串值获取指定偏移量上的位（bit） MGET key1 [key2..] 获取所有（一个或多个）给定key的值 SETBIT key offset value 对key所存储的字符串值设置或清除指定偏移量上的位（bit） SETEX key seconds value 将值value关联到key，并将key的过期时间设置为seconds（以秒为单位） SETNX key value 只有在key不存在时设置key的值 SETRANGE key offset value 用value参数覆写给定key所存储的字符串值，从偏移量offset开始 STRLEN key 返回key所存储的字符串值的长度 MSET key value [key value …] 同时设置一个或多个key-value对 MSETNX key value [key value …] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在 PSETEX key milliseconds value 这个命令和SETEX相似，但它以毫秒为单位设置key的生存时间 INCR key 将key中存储的数字值增一 INCRBY key increment 将key所存储的值加上给定的增量值（increment） INCRBYFLOAT key increment 将 key 所储存的值加上给定的浮点增量值（increment） DECR key 将key中存储的数字值减一 DECRBY key decrementkey 所储存的值减去给定的减量值（decrement） APPEND key value 如果 key 已经存在并且是一个字符串，APPEND 命令将 指定value 追加到改 key 原来的值（value）的末尾 应用场景：常规计数：微博数、粉丝数等。 Hash（字典） 我们可以将Redis中的Hashes类型看成具有String Key和String Value的map容器。该类型非常适合用于存储值对象的信息。如Username、Password和Age等。如果Hash中包含很少的字段，那么该类型的数据也将仅占用很少的磁盘空间。 命令 描述 HDEL key field [field2] 删除一个或多个哈希表字段 HEXISTS key field 查看哈希表key中，指定的字段是否存在 HGET key field 获取存储在哈希表中指定字段的值 HGETALL key 获取在哈希表中指定key的所有字段和值 HINCRBY key field increment 为哈希表key中的指定字段的整数值加上增量increment HINCRBYFLOAT key field increment 为哈希表key中的指定字段的浮点数值加上增量increment HKEYS key 获取所有哈希表中的字段 HLEN key 获取哈希表中字段的数量 HMGET key field1 [field2] 获取所有给定字段的值 HMSET key field1 value1 [field2 value2] 同时将多个field-value（域-值）对设置到哈希表key中 HSET key field value 将哈希表key中的字段field的值设为value HSETNX key field value 只有在字段field不存在时，设置哈希表字段的值 HVALS key 获取哈希表中所有值 HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对 应用场景：存储部分变更的数据，如用户信息等。 List（列表） List类型是按照插入顺序排序的字符串链表。和数据结构中的普通链表一样，我们可以在其头部和尾部添加新的元素。在插入时，如果该键并不存在，Redis将为该键创建一个新的链表。与此相反，如果链表中所有的元素均被移除，那么该键也将会被从数据库中删除。List中可以包含的最大元素数量是4294967295。 命令 描述 BLPOP key1 [key2] timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 BRPOP key1 [key2] timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 BRPOPLPUSH source destination timeout 从列表弹出一个值，将弹出的元素插入到另外一列表中并返回它；如果列表没有元素会阻塞列表直到等到 LINDEX key index 通过索引获取列表中的元素 LINSERT key BEFORE/AFTER pivot value 在列表的元素前/后插入元素 LLen key 获取列表长度 LPOP key 移出并获取列表的第一个元素 LPUSH key value1 [value2] 将一个或多个值插入到列表头部 LPUSHX key value 将一个值插入到已存在的列表头部 LRANGE key start stop 获取列表指定范围内的元素 LREM key count value 移出列表元素 LSET key index value 通过索引设置列表元素的值 LTRIM key start stop 对一个列表进行修剪（trim），就是说，让列表只保留指定区间内的元素，不在指定区间内的元素都将被删除 RPOP key 移出并获取列表最后一个元素 RPOPLPUSH source destination 移出列表的最后一个元素，并将该元素加到另一个列表并返回 RPUSH key value1 [value2] 在列表中添加一个或多个值 RPUSHX key value 为已存在的列表添加值 应用场景：消息队列系统，比如sina微博。在Redis中我们的最新微博ID使用了常驻缓存，这是一直更新的。但是做了限制不能超过5000个ID,因此获取ID的函数会一直询问Redis。只有在start/count参数超出了这个范围的时候，才需要去访问数据库。系统不会像传统方式那样“刷新”缓存，Redis实例中的信息永远是一致的。SQL数据库（或是硬盘上的其他类型数据库）只是在用户需要获取“很远”的数据时才会被触发，而主页或第一个评论页是不会麻烦到硬盘上的数据库。 SET (集合) Set类型看作为没有排序的字符集合。Set可包含的最大元素数量是4294967295。如果多次添加相同元素，Set中将仅保留该元素的一份拷贝。 名令 描述 SADD key member1 [member2] 向集合添加一个或多个成员 SCARD key 获取集合的成员数 SDIFF key1 [key2] 返回给定所有集合的差集 SDIFFSTORE destination key1 [key2] 返回给定所有集合的差集并存储在destination中 SISMEMBER key member 判断member元素是否是集合key的成员 SMEMBERS key 返回集合中的所有成员 SMOVE source destination member 将member元素从source集合移动到destination集合 SPOP key 移除并返回集合中的一个随机元素 SRANDMEMBER key [count] 返回集合中一个或者多个随机数 SREM key member1 [member2] 移除集合中一个或多个成员 SUNION key1 [key2] 返回所有给定集合的并集 SUNIONSTORE destination key1 [key2] 所有给定集合的并集存储在destination集合中 SSCAN key cursor [MATCH pattern] [COUNT count] 迭代集合中的元素 应用场景：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis还为集合提供了求交集、并集、差集等操作，可以非常方便地实现如共同关注、共同喜好、共同好友等功能，对上面的所有集合操作，还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的结合中。 SortedSet （有序集合） Sorted-Set中的每一个成员都会有一个分数（score）与之关联，Redis正是通过分数来为集合中的成员进行从小到大的排序。成员是唯一的，但是分数（score）却是可以重复的。集合是通过哈希表实现的，所以添加、删除、查找的复杂度都是O(1)。集合中最大的成员数为2³²-1（4294967295, 每个集合可存储40多亿个成员）。 命令 描述 ZADD key score1 member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的分数 ZCARD key 获取有序集合的成员数 ZCOUNT key min max 计算在有序集合中指定区间分数的成员数 ZINCRBY key increment member 有序集合中对指定成员的分数加上增量increment ZINTERSTORE destination numkeys key [key …] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合key中 ZLEXCOUNT key min max 在有序集合中计算指定字典区间内成员数量 ZRANGE key start stop [WITHSCORES] 通过索引区间返回有序集合中指定区间内的成员 ZRANGEBYLEX key min max [LIMIT offset count] 通过字典区间返回有序集合的成员 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] 通过分数返回有序集合指定区间内的成员 ZRANK key member 返回有序集合中指定成员的索引 ZREM key member [member …] 移除有序集合中的一个或多个成员 ZREMRANGEBYLEX key min max 移除有序集合中给定的字典区间的所有成员 ZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员 ZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所成员 ZREVRANGE key start stop [WITHSCORES] 返回有序集合中指定区间的成员，通过索引，分数从高到低 ZREVRANGEBYSCORE key max min [WITH SCORES] 返回有序集合中指定分数区间内的成员，分数从高到低排序 ZREVRANK key member 返回有序集合中指定成员的排名，有序集合成员按分数值递减（从大到小）排序 ZSCORE key member 返回有序集合中，成员的分数值 ZUNIONSTORE destination nunkeys key [key …] 计算给定的一个或多个有序集的并集，并存储在新的key中 ZSCAN key cursor [MATCH pattern] [COUNT count] 迭代有序集合中的元素（包括元素成员和分数） 应用场景：排行榜应用，取TOP N操作这个需求与上面需求的不同之处在于，前面操作以时间为权重，这个是以某个条件为权重，比如按顶的次数排序，这时候就需要我们的SortedSet了，将要排序的值设置成sorted set的score,将具体的数据设置成相应的value，每次只需要执行一条ZADD命令即可。 消息模式 Redis发布消息通常有两种模式： 队列模式（queuing） 发布-订阅模式（publish-subscribe）任务队列：顾名思义，就是“传递消息的队列”。与任务对列进行交互的实体有两类，一类是生产者（producer），另一类则是消费者（consumer）。生产者将需要处理的任务放入任务队列中，而消费者则不断地从任务独立中读入任务信息并执行。 任务队列的好处： 松耦合 生产者消费者只需按照约定的任务描述格式，进行编写代码 易于扩展 多消费者模式下，消费者可以分布在多个不同的服务器中，由次降低单台服务器的负载 Redis发布订阅 其实从Pub/Sub的机制来看，它更像是一个广播系统，多个Subscriber可以订阅多个Channel，多个Publisher可以往多个Channel中发布消息。可以简单的理解： Subscriber：收音机，可以收到多个频道，并以队列方式显示Publisher：电台，可以往不同的FM频道中发消息Channel：不同频率的FM频道 发布订阅模型 一个Publisher，多个Subscriber模型可以作为消息队列或者消息管道。主要应用：通知、公告。多个Publisher，一个Subscriber模型可以将Pub/Sub做成独立的HTTP接口，各应用程序作为Publisher向Channel中发送消息，Subscriber端收到消息后执行相应的业务逻辑，比如写数据库，显示等等。主要应用：排行榜、投票、计数。多个Publisher，多个Subscriber模型顾名思义，就是可以向不同的Channel中发送消息，由不同的Subscriber接收。主要应用：群聊、聊天。 实践发布订阅 发布订阅命令 命令 描述 PUBLISH channel msg 将信息message发送到指定的频道channel SUBSCRIBE channel [channel …] 订阅频道，可以同时订阅多个频道 UNSUBSCRIBE [channel …] 取消订阅指定的频道，如果不指定频道，则会取消订阅所有频道 PSUBSCRIBE pattern [pattern …] 订阅一个或个符合给定模式的频道，每个模式以*作为匹配符，比如it*匹配所有以it开头的频道（it.news、it.blog、it.tweets等），new.*匹配所有以news.开头的频道 PUNSUBSCRIBE pattern [pattern…] 退订指定的规则，如果没有参数则会退订所有规则 PUBSUB subcommand [argument [argument …]] 查看订阅与发布系统状态 注意：使用发布订阅模式实现的消息队列，当有客户端订阅channel后只能收到后续发布到该频道的消息，之前发送的不会缓存，必须Provider和Consumer同时在线。 消息队列系统对比 客户端在执行订阅命令只有进入了订阅状态，只能接受SUBSCRIBE、PSUBSCRIBE、UNSUBSCRIBE、PUNSUBSCRIBE四个命令。开启的订阅客户端，无法收到该频道之前的消息，因为Redis不会对发布的消息进行持久化。和很多专业的消息队列系统（例如kafka、rocketMQ）相比，Redis的发布订阅略显粗糙，例如：无法实现消息堆积和回溯。但胜在足够简单，如果当前场景可以容忍这些缺点，也不失为一个不错的选择。 Redis事务管理 redis中的事务跟关系型数据库中的事务是一个相似的概念，但是有不同之处。关系型数据库事务执行失败后面的sql语句不再执行，而redis中的一条命令执行失败，其余的命令照常执行。redis中开启一个事务是使用multi，相当于begin/start transaction，exec提交事务，discard取消队列命令（非回滚操作）。redis、mysql事务对比： Mysql Redis 开启 start/begin transaction multi 语句 普通SQL 普通命令 失败 rollback回滚 discard取消（是队列里面的命令不执行，队列里面的任务根本就没有执行。而不是执行了也可以撤回来） 成功 commit exec Redis事务命令 命令 描述 DISCARD 取消事务，放弃执行事务块内的所有命令 EXEC 执行所有事务块内的命令 MULTI 标记一个事务块的开始 UNWATCH 取消WATCH命令对所有key的监视 WATCH key [key …] 监视一个或多个key,如果在事务执行之前这个或这些被其他命令所改动，那么事务将被打断 事务执行举例 1234567ZADD salary 2000 user1ZADD salary 3000 user2ZRANGE salary 0 -1 WITHSCORESMULTIZINCRBY salary 1000 user1ZINCRBY salary -1000 user2EXEC redis中事务的锁机制 举例：我正在买票 Ticket -1 ，money -100而票只有1张，如果在multi之后，和exec之前，票被别人买了，即ticket变成了0。我该如何观察这种情景，并不再提交： 悲观的想法：世界充满危险，肯定有人和我抢，给ticket上锁，只有我能操作。[悲观锁]乐观的想法：没有那么多人和我抢，只要注意，有没有人更改ticket的值就可以了。[乐观锁] Redis的事务中，启用的是乐观锁，只负责监测key有没有被改动。 Redis服务管理命令 命令 描述 BGREWRITEAOF 异步执行一个AOF文件重写操作 BGSAVE 在后台异步保存当前数据库的数据到磁盘 CLIENT KILL [ip:port] [ID client-id] 关闭客户端连接 CLINET LIST 后去连接到服务器的客户端连接列表 CLINET GETNAME 后去连接名称 CLINET PAUSE timeout 在指定时间内终止运行来自客户端的命令 CLINET SETNAME connection-name 设置当前连接的名称 CLUSTER SLOTS 获取集群节点的映射数组 COMMAND 获取redis命令详情数组 COMMAND COUNT 获取redis命令总数 COMMAND GETKEYS 获取给定命令的所有键 TIME 返回当前服务器时间 COMMAND INFO command-name [command-name…] 获取指定redis命令描述的数组 CONFIG GET parameter 获取指定配置参数的值 CONFIG REWRITE 对启动redis服务器时所指定的redis.conf配置文件进行改写 CONFIG SET parameter value 修改redis配置参数，无需重启 CONFIG RESETSTAT 重置INFO命令中的某些统计数据 DBSIZE 返回当前数据库的key的数量 DEBUG OBJECT key 获取key的调试信息 DEBUG SEGFAULT 让redis服务崩溃 FLUSHALL 删除所有数据库的所有key FLUSHDB 删除当前数据库的所有key INFO [section] 获取redis服务器的各种信息和统计数值 LASTSAVE 返回最近一次redis成功将数据保存到磁盘上的时间，以unix时间戳格式表示 MONITOR 实时打印出redis服务器接受到的命令，调试用 ROLE 返回主从实例所属的角色 SHUTDOWN [NOSAVE] [SAVE] 异步保存数据到硬盘，并关闭服务器 SLAVEOF host port 将当前服务器转变为指定服务器的从属服务器（slave server） SLOWLOG subcommand [argument] 管理redis的慢日志 SYNC 用于复制功能（replication）的内部命令 Redis慢日志查询 Slow log是Redis用来记录查询执行时间的日志系统slow log保存在内存里面，读写速度非常快可以通过修改redis.conf文件或者用CONFIG GET和CONFIG SET 命令对他们动态地进行修改 12345678#redis.conf修改slowlog-log-slower-than 10000 超过多少微秒#命令行修改CONFIG SET slowlog-log-slower-than 10000CONFIG SET sloelog-max-len 1000 保存多少条慢日志CONFIG GET slow*SLOWLOG GETSLOWLOG RESET]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Redis的一些了解]]></title>
    <url>%2Fposts%2F424997909.html</url>
    <content type="text"><![CDATA[介绍 Redis是一个使用ANSIC编写的开源、支持网络、基于内存、可选持久性的键值对（key-value）存储数据库。从2015年6月开始，Redis的开发由Redis Labs赞助，而2013年5月至2015年6月期间，其开发由Pivotal赞助。在2013年5月之前，其开发由VMware赞助。根据月度排行榜网站DB-Engines.com的数据显示，Redis是最流行的键值对存储数据库。 软件获取和帮助 官方网站：https://redis.io官方各版本下载地址：http://download.redis.io/releases/Redis 中文命令参考：http://redisdoc.com中文网站1：http://redis.cn中文网站2：http://www.redis.net.cn Redis特性 高速读写，数据类型丰富 支持持久化，多种内存分配及回收策略 支持弱事务，消息队列、消息订阅 支持高可用，支持分布式分片集群 企业缓存数据库解决方案对比 Memcached 优点：高性能读写、单一数据类型、支持客户端分布式集群、一致性hash多核结构、多线程读写性能高。 缺点：无持久化、节点故障可能出现缓存穿透、分布式需要客户端实现、跨机房数据同步困难、架构扩容复杂度高。 Redis 优点：高性能读写、多数据类型支持、数据持久化、高可用架构、支持自定义虚拟内存、支持分布式分片集群、单线程读写性能极高。 缺点：多线程读写较Memcached慢。 Tair 优点：高性能读写、支持三种存储引擎（ddb、rdb、ldb）、支持高可用、支持分布式分片集群、支撑了几乎所有淘宝业务的缓存。 缺点：单机情况下，读写性能较其他两种产品慢。 Redis安装 一键安装脚本，适用于centos7.x系统 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#!/bin/bash#定义变量version="4.0.11"redis_dir=/usr/local/redis-$version#编译安装yum -y install gccwget http://download.redis.io/releases/redis-$&#123;version&#125;.tar.gz || exit 1tar xf redis-$&#123;version&#125;.tar.gz &amp;&amp; cd redis-$versionmake || make MALLOC=libc mkdir -p /usr/local/redis-$&#123;version&#125;/binmkdir -p /usr/local/redis-$&#123;version&#125;/etccp redis.conf /usr/local/redis-$&#123;version&#125;/etc cd src cp mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server redis-trib.rb /usr/local/redis-$&#123;version&#125;/binln -s /usr/local/redis-$&#123;version&#125; /usr/local/redis#后台启动redissed -i 's/daemonize no/daemonize yes/g' /usr/local/redis/etc/redis.conf#加入环境变量echo 'redis_path=/usr/local/redis/bin' &gt;&gt;/etc/profileecho 'export PATH=$PATH:$redis_path'&gt;&gt;/etc/profile#修改内核参数echo "vm.overcommit_memory = 1"&gt;&gt;/etc/sysctl.confsysctl -p#redis启动脚本cat &gt;/usr/local/redis/bin/redis&lt;&lt;EOF#!/bin/bash## redis Startup script for Redis Server## description: Redis is an open source, advanced key-value store.## processname: redis-serverBIN="/usr/local/redis/bin"CONFIG="/usr/local/redis/etc/redis.conf"PIDFILE="/var/run/redis_6379.pid"### Read configurationprog="redis-server"desc="Redis Server"start() &#123; [ -e \$PIDFILE ] &amp;&amp; PID=\`cat \$PIDFILE\` || PID=0 if [ \$PID -ne 0 ];then echo "\$desc already running...." else echo "Starting \$desc " \$BIN/\$prog \$CONFIG fi&#125;stop() &#123; [ -e \$PIDFILE ] &amp;&amp; PID=\`cat \$PIDFILE\` || PID=0 if [ \$PID -ne 0 ];then echo "Stopping \$desc " kill -QUIT \$PID rm -rf \$PIDFILE else echo "\$desc is not running.... " fi &#125;restart() &#123; stop start&#125;case "\$1" in start) start ;; stop) stop ;; restart) restart ;; *) echo \$"Usage: \$0 &#123;start|stop|restart|condrestart|status&#125;"esacEOFchmod +x /usr/local/redis/bin/redisecho -e "[Unit]\nDescription=redis\nAfter=network.target\n[Service]\nType=forking\nExecStart=/usr/local/redis/bin/redis start\nExecReload=/usr/local/redis/bin/redis restart\nExecStop=/usr/local/redis/bin/redis stop\nPrivateTmp=true\n[Install]\nWantedBy=multi-user.target"&gt;/usr/lib/systemd/system/redis.servicechmod 754 /usr/lib/systemd/system/redis.servicesystemctl enable redisecho 'redis安装完成，请使用"systemctl start redis"启动redis服务...' redis.conf配置说明 1234567891011121314151617181920212223daemonize no/yes #后台启动port 6379 #默认端口timeout 60 #设置客户端连接时的超时时间，单位为秒，当客户端在这段时间内没有发出任何指令，将关闭该连接。默认值为0，表示不关闭tcp-keepalive 300 #单位是秒，表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞，官方建议300s,如果设置为0，则不会周期性的检测appendonly no/yes #AOF日志开关是否打开logfile /var/log/redis.log #日志文件位置loglevel notice #定义日志级别。默认值为notice，可选debug(记录大量日志信息，适用于开发、测试阶段)、verbose(较多日志信息)、notice(适量日志信息，适用于生产环境)、warning(仅有部分重要，关键信息才会被记录)databases 16 #设置数据库的数目。默认的数据库是DB0，可以在每个连接上使用select &lt;dbid&gt;命令选择一个不同的数据库，dbid是一个介于0到databases -1之间的数值。默认值是16，也就是默认Redis有16个数据库dbfilename dump.rdb #RDB持久化数据文件bind 10.0.0.51 ip2 ip3 ip4 #指定IP地址进行监听protected-mode yes/no #禁止protected-mode（保护模式，是否只允许本地访问）requirepass root #增加认证密码 &#123;password&#125;maxclients 1000 #设置客户端最大并发连接数，默认无限制。当客户端连接数达到限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxmemory 1024000000 #设置redis最大占用内存，单位为字节maxmemory-policy noeviction #当内存使用达到最大值时，redis使用的清除策略： volatile-lru 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used ) allkeys-lru 利用LRU算法移除任何key volatile-random 移除设置过过期时间的随机key allkeys-random 移除随机key volatile-ttl 移除即将过期的key(minimal TTL) noeviction 不移除任何key，只是返回一个写错误 ，默认选项maxmemory-samples 10 #LRU和minimal TTL算法都不是精准的算法，但是相对精确的算法（为了节省内存）。可以通过maxmemory-samples设置样本数，redis默认选择5个样本进行检测， 如果增加，会提高LRU或TTL的精准度，redis作者测试的结果是当这个配置为10时已经非常接近全量LRU的精准度了，并且增加maxmemory-samples会导致在主动清理时消耗更多的CPU时间。 Redis数据持久化 redis提供了多种不同级别的持久化方式：一种是RDB，另一种是AOF。 RDB持久化 可以在指定的时间间隔内生成数据集的时间点快照（point-in-time-snapshot）。在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb的二进制文件中。你可以对 Redis 进行设置，让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时，自动保存一次数据集。也可以通过调用 SAVE或者 BGSAVE，手动让 Redis 进行数据集保存操作。比如说，以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时，自动保存一次数据集:save 60 1000这种持久化方式被称为快照 snapshotting。当 Redis 需要保存 dump.rdb 文件时，服务器执行以下操作Redis 调用forks. 同时拥有父进程和子进程。子进程将数据集写入到一个临时 RDB 文件中。当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。优点： RDB是一个非常紧凑（compact）的文件，它保存了Redis在某个时间点上的数据集。这种文件非常适合用于进行备份：比如说，可以在最近的24小时内，每小时备份一次RDB文件，并且在每个月的每一天，也备份一个RDB文件，即使遇到问题，也可以随时将数据集还原到不同的版本。 RDB非常适用于灾难恢复（disaster recovery）：他只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。 RDB可以最大化Redis的性能：父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘I/O操作。 RDB在恢复大数据集时的速度比AOF的恢复速度要快。 缺点： 虽然Redis允许设置不同的保存点（save point）来控制保存RDB文件的频率，但是，因为RDB文件需要保存整个数据集的状态，所以它并不是一个轻松的操作。可能至少5分钟才保存一次RDB文件。在这种情况下，一旦发生故障停机，可能会丢失好几分钟数据。 每次保存RDB的时候，Redis都要fork出一个子进程，并由子进程来进行实际的持久化工作。在数据集比较庞大时，fork可能会非常耗时，造成服务器在某某毫秒内停止处理客户端；如果数据集非常巨大，并且CPU时间非常紧张的话，这种停止时间甚至可能会长达整整一秒。虽然AOF重写也需要进行fork，但无论AOF重写的执行间隔有多长，数据的耐久性都不会有任何损失。 AOF持久化 记录服务器执行的所有写操作命令，并在服务器启动前，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以Redis协议的格式来保存，新命令会被追加到文件的末尾。Redis还可以在后台对AOF文件进行重写（rewrite），使得AOF文件的体积不会超出保存数据集状态所需要的实际大小。Redis还可以同时使用AOF持久化和RDB持久化。在这种情况下，当Redis重启时，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。甚至可以关闭持久化功能，让数据只在服务器运行时存在。只进行追加操作的文件（append-only file，AOF）快照功能并不是非常耐久：如果Redis因为某些原因而造成故障停机，那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。尽管对于某些程序来说，数据的耐久性不是最重要的考虑因素，但是对于那些追求完全耐久能力的程序员来说，快照功能就不太适用了。从1.1版本开始，Redis增加了一种完全耐久的持久化方式：AOF持久化。可以通过修改配置文件来打开AOF功能：appendonly yes每当Redis执行一个改变数据集的命令方式（比如SET），这个命令就会被追加到AOF文件的末尾，当Redis重启时，程序就可以通过重新执行AOF文件中的命令来达到重建数据集的目的。 优点： 使用AOF会让Redis更加耐久：可以使用不同的fsync策略：无fsync，每秒fsync，每次写的时候fsync。使用默认的每秒fsync策略，Redis的性能依然很好（fsync是由后台线程进行处理的，主线程会尽力处理客户端请求），一旦出现故障，最多丢失1秒的数据。 Redis可以在AOF文件体积变得过大时，自动在后台对AOF进行重写：重写后的新AOF文件包含了恢复当前数据集所需要的最小命令集合。整个重写操作是绝对安全的，因为Redis在创建新AOF文件的过程中，会继续将命令追加到现有的AOF文件里面，即使重写过程中发生停机，现有的AOF文件也不会丢失。 一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。 AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。导出（export）AOF文件也非常简单：举个例子，如果不小心执行了FLUSHALL命令，但只要AOF文件未被重写，只要停止服务器，移除AOF文件末尾的FLUSHALL命令，并重启Redis，就可以将数据集恢复到FLUSHALL执行之前的状态。 缺点： 对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。 在一般情况下，每秒fsync的性能依然非常高，而关闭fsync可以让AOF的速度和RDB一样块，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB可以提供更有保证的最大延迟时间（latency）。 AOF在过去曾经发生过这样的bug：因为个别命令的原因，导致AOF文件在重新载入时，无法将数据集恢复成保存时的原样。（举个例子，阻塞命令BRPOPLPUSH就曾引起过这样的bug）测试套件里为这种情况添加了测试：他们会自动生成随机的、复杂的数据集，并通过重新载入这些数据来确保一切正常。虽然这种bug在AOF文件中并不常见，但是对比来说，RDB几乎是不可能出现这种bug的。 AOF日志重写 因为AOF的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加，AOF文件的体积也会变得越来越大。举个例子，如果对一个计数器调用了100次INCR，那么仅仅是为了保存这个计数器的当前值，AOF文件就需要使用100条记录（entry）。然而实际上，只使用了一条SET命令已经足以保存计数器的当前值了，其余99条记录实际上都是多余的。为了处理这种情况，Redis支持一种有趣的特性：可以在不打断服务客户端的情况下，对AOF文件进行重建（rebuild）。执行BGREWRITEAOF命令，Redis将生成一个新的AOF文件，这个文件包含重建当前数据集所需的最少命令。Redis2.2需要手动执行BGREWRITEAOF命令。 AOF有多耐用 可以配置Redis多久才将数据fysnc到磁盘一次。有三种方式：每次有新命令追加到AOF文件时就执行一次fsync：非常慢，也非常安全。每秒fsync一次：足够快（和使用RDB持久化差不多），并且在故障时只会丢失1秒钟的数据。从不fsync:将数据交给操作系统来处理。更快，也更不安全的选择。推荐（并且也是默认）的措施为每秒fsync一次，这种fsync策略可以兼顾速度和安全性。 如果AOF文件损坏了怎么办 服务器可能在程序正在对AOF文件进行写入时停机，如果停机造成了AOF文件出错（corrupt），那么Redis在重启时会拒绝载入这个AOF文件，从而确保数据的一致性不会被破坏。当发生这种情况时，可以用以下方法来修复出错的AOF文件：为现有的AOF文件创建一个备份。使用Redis附带的redis-check-aof程序，对原来的AOF文件进行修复，redis-check-aof –fix使用diff -u对比修复后的AOF文件和原始AOF文件的备份，查看两个文件之间的不同之处。（可选）重启Redis服务器，等待服务器载入修复后的AOF文件，并进行数据恢复。 如何选择使用哪种持久化方式 一般来说，如果想达到足以媲美postgresql的数据安全性，应该同时使用两种持久化功能。如果非常关心数据，但仍然可以承受数分钟以内的数据丢失，可以只使用RDB持久化。很多用户都只使用AOF持久化，但并不推荐这种方式：因为定时生成RDB快照（snapshot）非常便于进行数据库备份，并且RDB恢复数据集的速度也要比AOF恢复的速度快，除此之外，使用RDB还可以避免之前提到的AOF程序的bug。 AOF和RDB之间的相互作用 在版本号大于等于2.4的Redis中，BGSAVE执行的过程中，不可以执行BGREWRITEAOF。反过来说，在BGREWRITEAOF执行过程中，也不可执行BGSAVE。这可以防止两个Redis后台进程同时对磁盘进行大量的I/O操作。如果BGSAVE正在执行，并且用户显示地调用BGREWRITEAOF命令，那么服务器将向用户回复一个OK状态，并告知用户，BGREWRITEAOF已经被预定执行：一旦BGSAVE执行完毕，BGREWRITEAOF就会正式开始。当Redis启东时，如果RDB持久化和AOF持久化都被打开了，那么程序就会优先使用AOF文件来恢复数据集，因为AOF文件所保存的数据通常是最完整的。 持久化配置 RDB持久化配置 1234567891011#RDB持久化基本配置save 900 1 #900秒（15分钟）内有一个更改save 300 10 #300秒（5分钟）内有10个更改save 60 10000 #60秒内有10000次更改#达到以上定义的配置时间时，就将内存数据持久化到磁盘#RDB持久化高级配置stop-writes-on-bgsave-error yes #后台备份进程出错时，主进程是否停止写入？主进程不停止容易造成数据不一致rdbcompression yes #导出的rdb文件是否压缩，如果rdb的大小很大的话，建议这么做rdbchecksum yes #导入rdb恢复数据时，是否检验rdb的完整性 验证版本是否一致dbfilename dump.rdb #导出来的rdb文件名dir /data/redis/rdb #rdb的放置路径 AOF持久化配置 123456789#AOF持久化基本配置appendonly yes/no #是否打开aof日志功能appendfsync always #每1个命令，都立即同步到aofappendfsync everysec #每秒写一次appendfsync no #写入工作交给操作系统，由操作系统判断缓冲区大小，统一写到aof#AOF持久化高级配置no-appendfsync-on-rewrite yes/no #正在导出rdb快照的过程中，是否停止同步AOFauto-aof-rewrite-percentage 100 #aof文件大小比起上次重写时的大小，增长率100%时重写，缺点：业务开始的时候，会重复重写多次。auto-aof-rewrite-min-size 64mbo #aof文件，至少超过64M时重写 RDB到AOF切换 在Redis2.2或以上版本，可以在不重启的情况下，从RDB切换到AOF： 为最新的dump.rdb文件创建一个备份； 将备份放到一个安全的地方； 执行以下两条命令： 12redis-cli config set appendonly yesredis-cli config set save "" 确保写命令会被正确地追加到AOF文件的末尾 执行说明：执行的第一条命令开启了AOF功能：Redis会阻塞直到初始AOF文件创建完成为止，之后Redis会继续处理命令请求，并开始将写入命令追加到AOF文件末尾。执行的第二条命令用于关闭RDB功能。这一步是可选的，也可以同时使用RDB和AOF这两种持久化功能。 备份redis数据 Redis对于数据备份是非常友好的，因为可以在服务器运行的时候对RDB文件进行复制：RDB文件一旦被创建，就不会进行任何修改。当服务器要创建一个新的RDB文件时，它先将文件的内容保存在一个临时文件里面，当临时文件写入完毕时，程序才使用rename(2)原子地用临时文件替换原来的RDB文件。这也就是说，无论何时，复制RDB文件都是绝对安全的。创建一个定期任务（cron job），每小时将一个RDB文件备份到一个文件夹，并且每天将一个RDB文件备份到另一个文件夹。确保快照的备份都带有相应的日期和时间信息，每次执行定期任务脚本时，使用find命令来删除过期的快照：可以保留最近48小时内的快照，还可以保留最近一两个月的每日快照。至少每天一次，将RDB备份到数据中心之外，或者至少备份到运行Redis服务器的物理机器之外。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix添加nginx监控]]></title>
    <url>%2Fposts%2F4255676476.html</url>
    <content type="text"><![CDATA[nginx开启监控模块 修改nginx的配置，在nginx配置的server域加入以下配置，然后重启nginx 1234location /nginx_status &#123; stub_status on; access_log off; &#125; 执行命令: 1curl http://127.0.0.1/nginx_status 可看到输出： 1234Active connections: 1 server accepts handled requests 3144 3144 3144 Reading: 0 Writing: 1 Waiting: 0 编辑nginx监控脚本 在需要监控的nginx服务器上新建文件”/etc/zabbix/scripts/nginx_monitor.sh”(scripts目录需创建)，加入以下內容： 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bashstatus_url="http://127.0.0.1/nginx_status"case $1 in status) countor=$(ps -C nginx --no-heading|wc -l) if [ $&#123;countor&#125; -eq "0" ];then echo "stop" else echo "running" fi ;; active_conn) curl $status_url 2&gt;/dev/null|awk -F ":" 'NR==1&#123;print $2&#125;' ;; accepts) curl $status_url 2&gt;/dev/null|awk 'NR==3&#123;print $1&#125;' ;; handled) curl $status_url 2&gt;/dev/null|awk 'NR==3&#123;print $2&#125;' ;; requests) curl $status_url 2&gt;/dev/null|awk 'NR==3&#123;print $3&#125;' ;; reading) curl $status_url 2&gt;/dev/null|awk 'NR==4&#123;print $2&#125;' ;; writing) curl $status_url 2&gt;/dev/null|awk 'NR==4&#123;print $4&#125;' ;; waiting) curl $status_url 2&gt;/dev/null|awk 'NR==4&#123;print $6&#125;' ;; *) echo "$(basename $0) (status|active_conn|accepts|handled|requests|reading|writing|waiting)"esac 给予脚本执行权限：chmod +x /etc/zabbix/scripts/nginx_monitor.sh 修改zabbix-agent配置 在需要监控的nginx服务器上新建”/etc/zabbix/zabbix_agentd.d/userparameter_nginx.conf”文件，添加如下配置： 1UserParameter=nginx.status[*],/etc/zabbix/scripts/nginx_monitor.sh $1 重启zabbix-agent：systemctl restart zabbix-agent 导入nginx监控模板 nginx监控模板及脚本下载下载模板文件并解压导入成功会在模板中显示“Template Nginx”模板，绑定到相应主机，nginx监控完成！]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>nginx监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix添加mysql监控]]></title>
    <url>%2Fposts%2F1388969176.html</url>
    <content type="text"><![CDATA[编辑mysql监控脚本 在需要监控的mysql服务器上新建文件”/etc/zabbix/zabbix_agentd.d/mysql_monitor.sh” 1vim /etc/zabbix/zabbix_agentd.d/mysql_monitor.sh 加入以下內容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/bin/bashmysqladmin_dir="/usr/local/mysql/bin/mysqladmin_dir" #mysqladmin的路径MYSQL_PWD='mysqlpassword' #mysql的root密碼ARGS=1if [ $# -ne "$ARGS" ];then echo "Please input onearguement:"ficase $1 in Uptime) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; status 2&gt;/dev/null |awk '&#123;print $2&#125;'` echo $result ;; Questions) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; status 2&gt;/dev/null|awk '&#123;print $6&#125;'` echo $result ;; Com_update) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_update"|awk '&#123;print $4&#125;'` echo $result ;; Slow_queries) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Slow_queries"|awk '&#123;print $4&#125;'` echo $result ;; Com_select) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_select"|awk '&#123;print $4&#125;'` echo $result ;; Com_rollback) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_rollback"|awk '&#123;print $4&#125;'` echo $result ;; Com_insert) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_insert"|awk '&#123;print $4&#125;'` echo $result ;; Com_delete) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_delete"|awk '&#123;print $4&#125;'` echo $result ;; Com_commit) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_commit"|awk '&#123;print $4&#125;'` echo $result ;; Bytes_sent) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Bytes_sent"|awk '&#123;print $4&#125;'` echo $result ;; Bytes_received) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Bytes_received"|awk '&#123;print $4&#125;'` echo $result ;; Com_begin) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_begin"|awk '&#123;print $4&#125;'` echo $result ;; *) echo "Usage:$0 (Uptime|Questions|Com_update|Slow_queries|Com_select|Com_rollback|Com_insert|Com_delete|Com_commit|Bytes_sent|Bytes_received|Com_begin)" ;;esac 12chmod 700 /etc/zabbix/zabbix_agentd.d/mysql_monitor.sh #授予mysql监控脚本执行权限chown zabbix:root /etc/zabbix/zabbix_agentd.d/mysql_monitor.sh #更改脚本属主为zabbix 编辑zabbix-agent配置 在需要监控的mysql服务器上修改”/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf”文件 1vim /etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf 添加如下配置： 1UserParameter=mysql.status[*],/etc/zabbix/zabbix_agentd.d/mysql_monitor.sh $1 重启zabbix-agent 1systemctl restart zabbix-agent 在zabbix服务端测试 1zabbix_get -s 192.168.1.46 -k mysql.status[Uptime] #获取到数据说明监控脚本正常 绑定mysql监控模板 zabbix自带了mysql监控模板，在zabbix web界面的相应主机上绑定“Template DB MySQL”模板]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>mysql监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主主互备模式架构]]></title>
    <url>%2Fposts%2F1683246444.html</url>
    <content type="text"><![CDATA[DB1和DB2互为主从，保证两台数据库始终是同步的，同时在DB1和DB2上还需要安装高可用软件Keepalived。正常情况下，web server主机仅从BD1进行数据的读、写操作，DB2只负责从DB1同步数据。而Keepalived维护着一个VIP,此ip用来对外提供连接服务，同时，Keepalived还负责监控DB1和DB2上mysql数据库的运行状态，当DB1主机出现故障或mysql运行异常时，自动将VIP地址和mysql服务切换到DB2上，此时web server主机继续从DB2进行数据的读、写操作。通过Keepalived保持了数据库服务的连续性，整个切换过程非常快，并且对前端web server主机是透明的。这种方式可以实现95.000%的SLA（服务水平协定）。 修改mysql配置文件 修改DB1主机的配置文件，在/etc/my.cnf文件中的”[mysqld]”段加如下内容： 12345server-id = 1log-bin = mysql-binreplicate-wild-ignore-table = mysql.%replicate-wild-ignore-table = test.%replicate-wild-ignore-table = information_schema.% 修改DB2主机的配置文件，在/etc/my.cnf文件中的”[mysqld]”段加如下内容： 123456server-id = 2log-bin = mysql-binrelay-log = mysql-relay-binreplicate-wild-ignore-table = mysql.%replicate-wild-ignore-table = test.%replicate-wild-ignore-table = information_schema.% 重启DB1和DB2的mysql服务 手动同步数据库： 如果DB1上已经有mysql数据，在执行主主互备之前，需要将DB1和DB2上两个mysql数据保持一致 创建复制用户并授权： 在DB1中创建复制用户 123grant replication slave on *.* to 'repl_user'@'192.168.88.12' identified by 'password';flush privileges;show master status; 在DB2的mysql库中将DB1设为自己主服务器 1change master to master_host='192.168.88.11',master_port=3306,master_user='repl_user', master_password='123456',master_log_file='mysql-bin.000028',master_log_pos=4264031; #将master_log_file的值替换为在DB1中执行"show master status"显示的File的值，将master_log_pos的值替换为Position的值 在DB2上启动slave服务 1start slave; 配置从DB2到DB1的mysql主从复制，这个配置过程与上面完全一样 在DB2上创建复制用户 1grant replication slave on *.* to 'repl_user'@'192.168.88.11' identified by 'password'; 在DB1的mysql库中将DB2设为自己的主服务器 1change master to master_host='192.168.88.12',master_port=3306,master_user='repl_user', master_password='123456',master_log_file='mysql-bin.000028',master_log_pos=480; #将master_log_file的值替换为在DB2中执行"show master status"显示的File的值，将master_log_pos的值替换为Position的值 在DB1上启动slave服务 12start slave;show slave status\G #在DB1和DB2执行 配置Keepalived实现mysql双主高可用 在进行高可用配置之前，需要在DB1和DB2服务器上安装Keepalived软件。DB1服务器上/etc/keepalived/keepalived.conf文件内容： 123456789101112131415161718192021222324252627282930313233343536373839global_defs &#123;notification_email &#123;acassen@firewall.locfailover@firewall.locsysadmin@firewall.loc&#125;notification_email_from Alexandre.Cassen@firewall.locsmtp_server 192.168.200.1smtp_connect_timeout 30router_id MySQLHA_DEVEL&#125;vrrp_script check_mysqld &#123;script "/etc/keepalived/mysqlcheck/check_slave.pl 127.0.0.1"#检测mysql复制状态的脚本interval 2weight 21&#125;vrrp_instance HA_1 &#123;state BACKUP #在DB1和DB2上均配置为BACKUPinterface eth0virtual_router_id 80priority 100advert_int 2nopreempt #不抢占模式，只在优先级高的机器上设置，优先级低的机器不可设置authentication &#123;auth_type PASSauth_pass qweasdzxc&#125;track_script &#123;check_mysqld&#125;virtual_ipaddress &#123;192.168.88.10/24 dev eth0 #mysql的对外服务ip,即VIP&#125;&#125; 其中，check_slave.pl文件内容为 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/perl -wuse DBI;use DBD::mysql;# CONFIG VARIABLES$SBM = 120;$db = "aaa";$host = $ARGV[0];$port = 3306;$user = 'root';$pw = '123456';# SQL query$query = "show slave status";$dbh = DBI-&gt;connect("DBI:mysql:$db:$host:$port", $user, $pw, &#123; RaiseError =&gt; 0,PrintError =&gt; 0 &#125;);if (!defined($dbh)) &#123; exit 1;&#125;$sqlQuery = $dbh-&gt;prepare($query);$sqlQuery-&gt;execute;$Slave_IO_Running = "";$Slave_SQL_Running = "";$Seconds_Behind_Master = "";while (my $ref = $sqlQuery-&gt;fetchrow_hashref()) &#123; $Slave_IO_Running = $ref-&gt;&#123;'Slave_IO_Running'&#125;; $Slave_SQL_Running = $ref-&gt;&#123;'Slave_SQL_Running'&#125;; $Seconds_Behind_Master = $ref-&gt;&#123;'Seconds_Behind_Master'&#125;;&#125;$sqlQuery-&gt;finish;$dbh-&gt;disconnect();if ( $Slave_IO_Running eq "No" || $Slave_SQL_Running eq "No" ) &#123; exit 1;&#125; else &#123; if ( $Seconds_Behind_Master &gt; $SBM ) &#123; exit 1; &#125; else &#123; exit 0; &#125;&#125; 安装per连接数据库驱动 1yum -y install perl-DBD-MySQL #安装per连接数据库驱动 这是用perl写的检测mysql复制状态的脚本，只需修改文件中mysql数据库的数据库、端口，用户名密码即可直接使用，但在使用前要保证此脚本有可执行权限。接着将Keepalived.conf文件和check_slave.pl文件复制到DB2服务器上的对应位置，将Keepalived.conf文件中priority值修改为90，由于配置的不是抢占模式，因此，还需要去掉nopreempt选项。在完成所有配置后，分别在DB1和DB2上启动Keepalived服务，在正常情况下VIP地址应该运行在DB1服务器上。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql主主互备</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7通过阿里源安装zabbix]]></title>
    <url>%2Fposts%2F1314989757.html</url>
    <content type="text"><![CDATA[此安装方法适用于centos7.x系统，安装版本为zabbix4.2 安装zabbix环境 12echo -e "[zabbix]\nname=Zabbix Repository\nbaseurl=https://mirrors.aliyun.com/zabbix/zabbix/4.1/rhel/7/x86_64/\ngpgcheck=0\nenabled=1" &gt;&gt;/etc/yum.repos.d/zabbix.repo #添加阿里镜像仓库zabbix的yum源yum install -y zabbix-server-mysql zabbix-web-mysql zabbix-get zabbix-agent php-fpm 可能会报错：Error: Package: zabbix-server-mysql-4.2.0-0.2alpha2.el7.x86_64 (zabbix) Requires: libiksemel.so.3()(64bit)出现此错误则需要安装以下依赖： 12345yum install -y epel-releaseyum install -y iksemel fping libiksemel#如果以上命令不能安装iksemel，可使用如下命令yum install -y gnutlsrpm -ivh http://springdale.math.ias.edu/data/puias/unsupported/7/x86_64//iksemel-1.4-6.sdl7.x86_64.rpm 安装mysql并导入zabbix数据库 12345678rpm -ivh http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm #添加mysql源yum install -y mysql-server #安装后mysql的root密码为空，可自行设置systemctl start mysqld #启动mysqlsystemctl enable mysqld #加入开启自启动mysql -uroot -e "create database zabbix character set utf8 collate utf8_bin;" #创建zabbix数据库mysql -uroot -e "grant all privileges on zabbix.* to zabbix@localhost identified by 'password';" #将password改为自己的密码zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -ppassword zabbix #将password改为自己的密码sed -i 's#\# DBPassword=#DBPassword=password#g' /etc/zabbix/zabbix_server.conf #将password改为自己的密码 更改时区 1sed -i 's#\# php_value date.timezone Europe/Riga#php_value date.timezone Asia/Shanghai#g' /etc/httpd/conf.d/zabbix.conf 启动zabbix 12systemctl restart zabbix-server zabbix-agent httpd php-fpm systemctl enable zabbix-server zabbix-agent httpd php-fpm #加入开机自启动 访问http://your_ip/zabbix接着点击“Next step”和“Finish”,默认用户名:Admin，密码:zabbix 更改中文并解决中文乱码 修改语言为中文zabbix默认的字体会出现中文乱码，在windows系统中的C:\Windows\Fonts目录下选择支持中文的字体（如:’宋体’），上传至“/usr/share/zabbix/fonts”目录下，并将字体名称的大写改为小写，否则不识别，执行如下命令： 1sed -i &apos;s#graphfont#fontname#g&apos; /usr/share/zabbix/include/defines.inc.php #fontname为替换字体的名称，不需要后缀 刷新zabbix页面,中文字体显示正常 为zabbix设置域名和路径 设置域名，编辑/etc/httpd/conf/httpd.conf自定义路径，编辑/etc/httpd/conf.d/zabbix.conf重启httpd服务 1systemctl restart httpd zabbix4.2自动安装脚本 服务端安装脚本 123456789101112131415161718192021222324252627#!/bin/bashecho "开始安装zabbix服务端..."#添加zabbix安装源echo -e "[zabbix]\nname=Zabbix Repository\nbaseurl=https://mirrors.aliyun.com/zabbix/zabbix/4.1/rhel/7/x86_64/\ngpgcheck=0\nenabled=1" &gt;&gt;/etc/yum.repos.d/zabbix.repo#安装依赖yum install -y epel-release &amp;&amp; yum install -y fpingyum install -y gnutls &amp;&amp; rpm -ivh http://springdale.math.ias.edu/data/puias/unsupported/7/x86_64//iksemel-1.4-6.sdl7.x86_64.rpm || exit 1 #安装zabbix相关服务yum install -y zabbix-server-mysql zabbix-web-mysql zabbix-get zabbix-agent php-fpm || exit 1#安装mysql数据库rpm -ivh http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm &amp;&amp; yum install -y mysql-server || exit 1systemctl start mysqld &amp;&amp; systemctl enable mysqld#创建zabbix数据库mysql -uroot -e "create database zabbix character set utf8 collate utf8_bin;" || exit 1#设置zabbix数据库密码，密码由时间戳MD5加密取前15个字符组成zabbixdb_pw=$(date +%s|md5sum|cut -c 1-15)#创建zabbix数据库账号mysql -uroot -e "grant all privileges on zabbix.* to zabbix@localhost identified by \"$&#123;zabbixdb_pw&#125;\";" || exit 1#导入zabbix数据库zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p$&#123;zabbixdb_pw&#125; zabbix || exit 1#设置zabbix_server数据库密码sed -i "s#\# DBPassword=#DBPassword=$&#123;zabbixdb_pw&#125;#g" /etc/zabbix/zabbix_server.conf#设置时区为亚洲上海sed -i 's#\# php_value date.timezone Europe/Riga#php_value date.timezone Asia/Shanghai#g' /etc/httpd/conf.d/zabbix.conf#重启zabbix-server、agent、httpd、php服务并加入开机自启动systemctl restart zabbix-server zabbix-agent httpd php-fpm &amp;&amp; systemctl enable zabbix-server zabbix-agent httpd php-fpmecho -e "zabbix安装完成...\n请访问http://your_ip/zabbix并继续\nzabbix数据库密码：$&#123;zabbixdb_pw&#125; 请保存\nmysql的root密码为空，请自行设置" 客户端安装脚本 123456#!/bin/bashserver_ip="your_server_ip" #your_server_ip更改为自己的zabbix服务器地址echo "开始安装zabbix客户端..."rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/4.1/rhel/7/x86_64/zabbix-agent-4.2.0-0.1alpha1.el7.x86_64.rpmsed -i "s#Server=127.0.0.1#Server=$&#123;server_ip&#125;#g" /etc/zabbix/zabbix_agentd.confsystemctl start zabbix-agent &amp;&amp; systemctl enable zabbix-agent]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab数据备份、还原、迁移]]></title>
    <url>%2Fposts%2F1095624551.html</url>
    <content type="text"><![CDATA[gitlab备份 12gitlab-rake gitlab:backup:create docker exec -i gitlab gitlab-rake gitlab:backup:create #docker环境中 备份文件在/var/opt/gitlab/backups/目录下，文件格式为“时间戳_年_月_日_版本号_gitlab_backup.tar”编辑/etc/gitlab/gitlab.rb文件中的“gitlab_rails[‘backup_path’] = ”参数可修改备份文件目录，需重新加载gitlab配置并重启 gitlab还原 123456#停止相关数据连接服务gitlab-ctl stop unicorn gitlab-ctl stop sidekiq#还原gitlab-rake gitlab:backup:restore BACKUP=1547406063 #还原1547406063_2019_01_13_11.5.4_gitlab_backup.tar文件，“BACKUP=”后跟还原文件的时间戳gitlab-ctl start #启动gitlab服务 注：不能直接在终端执行gitlab-ctl stop停止所有服务，因为gitlab删除和还原操作还需要使用到redis和postgresql连接。 gitlab迁移 将备份的文件拷贝至新的gitlab对应的备份目录下，执行还原的步骤。 新gitlab版本需要和原有版本一致，否则可能迁移失败！复制备份过程可能导致属组和属主发生变化，需要修改所有者为git]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab安装]]></title>
    <url>%2Fposts%2F4024240644.html</url>
    <content type="text"><![CDATA[脚本快速安装 12345curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash #debcurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash #rpmcurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.node.sh | bash #nodecurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.python.sh | bash #pythoncurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.gem.sh | bash #gem(ruby) 访问gitlab地址：http://your_host_ip docker安装 12345678910docker pull registry.cn-zhangjiakou.aliyuncs.com/kapyan/gitlab:11.5.4docker run --detach \ --hostname 192.168.1.208:8000 \ --publish 10000:443 --publish 8000:8000 --publish 20000:22 \ --name gitlab \ --restart always \ --volume /home/gitlab/config:/etc/gitlab \ --volume /home/gitlab/logs:/var/log/gitlab \ --volume /home/gitlab/data:/var/opt/gitlab \ gitlab #运行容器 docker exec -it gitlab /bin/bash #进入容器vim /etc/gitlab/gitlab.rbgitlab-ctl reconfigure #重新加载gitlab配置gitlab-ctl restart #重启gitlab访问gitlab地址：http://your_host_ip:8000官方安装包]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx安装]]></title>
    <url>%2Fposts%2F385762059.html</url>
    <content type="text"><![CDATA[通过存储库安装nginx CentOS 6.x系统： 123echo -e "[nginx]\nname=nginx repo\nbaseurl=http://nginx.org/packages/centos/6/$(uname -m)/\ngpgcheck=0\nenabled=1"&gt;&gt;/etc/yum.repos.d/nginx.repoyum install -y nginxchkconfig nginx on #设置开机自启动 CentOS 7.x系统： 123echo -e "[nginx]\nname=nginx repo\nbaseurl=http://nginx.org/packages/centos/7/$(uname -m)/\ngpgcheck=0\nenabled=1"&gt;&gt;/etc/yum.repos.d/nginx.repoyum install -y nginxsystemctl enable nginx #设置开机自启动 ubuntu系统： 1234sudo echo -e "deb http://nginx.org/packages/ubuntu/ codename nginx\ndeb-src http://nginx.org/packages/ubuntu/ codename nginx"&gt;&gt;/etc/apt/sources.listsudo apt-get updatesudo apt-get install -y nginxsystemctl enable nginx #设置开机自启动 源码编译安装nginx nginx各版本源码包下载以nginx-1.14.2为例：Centos系统： 123456789useradd -M -s /sbin/nologin www #创建nginx运行用户yum -y install gcc pcre pcre-devel openssl openssl-devel zlib-devel gd gd-devel perl perl-ExtUtils-Embed #安装依赖wget http://nginx.org/download/nginx-1.14.2.tar.gz #下载nginx-1.14.2tar xf nginx-1.14.2.tar.gz #解压nginx压缩包cd nginx-1.14.2./configure --prefix=/usr/local/nginx-1.14.2 --user=www --group=www --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gzip_static_module --with-http_perl_module --with-mail --with-mail_ssl_module --with-http_stub_status_module #设置编译参数make &amp;&amp; make install #编译安装ln -s /usr/local/nginx-1.14.2 /usr/local/nginx #给nginx添加软连接ln -s /usr/local/nginx/sbin/nginx /usr/local/bin/nginx Ubuntu系统： 123456789useradd -M -s /sbin/nologin www #创建nginx运行用户apt-get install -y gcc libpcre3 libpcre3-dev zlib1g-dev libssl-dev libperl-dev build-essential openssl #安装依赖wget http://nginx.org/download/nginx-1.14.2.tar.gz #下载nginx-1.14.2tar xf nginx-1.14.2.tar.gz #解压nginx压缩包cd nginx-1.14.2./configure --prefix=/usr/local/nginx-1.14.2 --user=www --group=www --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gzip_static_module --with-http_perl_module --with-mail --with-mail_ssl_module --with-http_stub_status_module #设置编译参数make &amp;&amp; make install #编译安装ln -s /usr/local/nginx-1.14.2 /usr/local/nginx #给nginx添加软连接ln -s /usr/local/nginx/sbin/nginx /usr/local/bin/nginx nginx官方启动脚本☞点击显/隐内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15# description: NGINX is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /var/run/nginx.pid# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ "$NETWORKING" = "no" ] &amp;&amp; exit 0nginx="/usr/sbin/nginx"prog=$(basename $nginx)NGINX_CONF_FILE="/etc/nginx/nginx.conf"[ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginxlockfile=/var/lock/subsys/nginxmake_dirs() &#123; # make required directories user=`$nginx -V 2&gt;&amp;1 | grep "configure arguments:.*--user=" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -` if [ -n "$user" ]; then if [ -z "`grep $user /etc/passwd`" ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d "=" -f 2` if [ ! -d "$value" ]; then # echo "creating" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done fi&#125;start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $"Starting $prog: " daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $"Stopping $prog: " killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; configtest || return $? stop sleep 1 start&#125;reload() &#123; configtest || return $? echo -n $"Reloading $prog: " killproc $nginx -HUP RETVAL=$? echo&#125;force_reload() &#123; restart&#125;configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125;rh_status() &#123; status $prog&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;case "$1" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;" exit 2esac 官方启动脚本示例 nginx编译参数详解 nginx编译参数☞点击显/隐内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134./configure --help --prefix=path #指定nginx安装路径，默认是/usr/local/nginx --sbin-path=path #指定二进制可执行文件路径，默认是prefix/sbin/nginx --modules-path=path #指定modules路径，默认是prefix/modules --conf-path=path #指定nginx配置文件路径，默认是prefix/conf/nginx.conf --error-log-path=path #指定错误日志文件路径，默认是prefix/logs/error.log --pid-path=path #设置nginx的pid文件路径，默认是prefix/logs/nginx.pid --lock-path=path #设置nginx的lock文件路径，默认是prefix/logs/nginx.lock，在nginx启动是创建，保证只有一个nginx服务运行 --user=name #设置nginx运行的用户，默认是nobody --group=name #设置nginx运行的组 --build=name #设置nginx的编译的名字，建议忽略该选项 --builddir=path #设置nginx的编译目录，建议忽略该选项 --with-select_module --without-select_module #配置服务器的是否使用select轮询接口（该接口低效且有限制），如果系统不支持如kqueue, epoll, 或/dev/poll等机制，则会构建该模块，保持默认即可 --with-poll_module --without-poll_module #poll接口比select接口更加高效，但是同样有一定的socket数量的限制，推荐使用默认 --with-threads #允许使用线程池，默认开启 --with-file-aio #在FreeBSD和Linux系统中开启异步文件I/O，默认开启 --with-http_ssl_module #开启https协议支持，默认不构建，要求安装openssl openssl-devel依赖 --with-http_v2_module #开启http/2协议支持，默认不构建 --with-http_realip_module #该模块可将客户端地址更改为在指定的头字段中发送的地址，默认不构建 --with-http_addition_module #该模块在响应之前和之后添加文本，默认不构建 --with-http_xslt_module # --with-http_xslt_module=dynamic #允许构建使用一个或多个XSLT样式表转换XML响应，默认不构建，需要安装libxml2和libxslt库 --with-http_image_filter_module --with-http_image_filter_module=dynamic #图像过滤器模块，可以转换JPEG、GIF、PNG和WebP格式的图像，默认不构建模块，该模块依赖libgd库，建议使用最新版本的库 --with-http_geoip_module --with-http_geoip_module=dynamic #使用预编译的MaxMind数据库创建具有取决于客户端IP地址的值得变量，该模块依赖MaxMind GeoIP 库，默认不构建 --with-http_sub_module #该模块通过一个指定的字符串替换为另一个字符串来修改响应，默认不构建 --with-http_dav_module #通过WebDAV协议进行文件管理自动化，默认不构建 --with-http_flv_module #为Flash Video(flv)文件提供伪流服务器端支持，默认不构建 --with-http_mp4_module #为MP4文件提供伪流服务器端支持，默认不构建 --with-http_gunzip_module #用于不支持gzip编码方法的客户端，默认不构建 --with-http_gzip_static_module #允许使用.gz文件扩展名发送预压缩文件，默认不构建 --with-http_auth_request_module #基于子请求的结果实现客户端授权，默认不构建 --with-http_random_index_module #处理以斜杠（“/”）结尾的请求，并选择目录中的随机文件作为索引文件，默认不构建 --with-http_secure_link_module #用于检查请求链路的真实性，保护资源免受未经授权的访问，并限制链路生存期，默认不构建 --with-http_degradation_module #开启ngx_http_degradation_module，默认不构建 --with-http_slice_module #此模块可将请求拆分为子请求，每个子请求都返回一定范围的响应，默认不构建 --with-http_stub_status_module #此模块提供对基本状态信息的访问，默认不构建 --without-http_charset_module #该模块将指定的字符集添加到“Content-Type”响应头字段，还可以将数据从一个字符集转换为另一个字符集，此参数将取消该模块 --without-http_gzip_module #禁用文件压缩模块 --without-http_ssi_module #禁用该模块，该模块在通过它的响应中处理SSI(服务器端包含)命令 --without-http_userid_module #禁用该模块，该模块设置适合客户端识别的cookie --without-http_access_module #禁用该模块，该模块允许限制对某些客户端地址的访问 --without-http_auth_basic_module #禁用该模块，该模块允许通过使用“HTTP基本身份验证”协议验证用户名和密码来限制对资源的访问 --without-http_mirror_module #禁用该模块，该模块通过创建后台镜像子请求来实现原始请求的镜像 --without-http_autoindex_module #禁用该模块，该模块处理以斜杠（“/”）结尾的请求，并在ngx_http_index_module模块找不到索引文件的情况下生成目录列表 --without-http_geo_module #禁用该模块，该模块使用取决于客户端IP地址的值创建变量 --without-http_map_module #禁用该模块，该模块创建的变量值取决于其他变量的值 --without-http_split_clients_module #禁用该模块，该模块适用于A/B测试的变量，也称为拆分测试 --without-http_referer_module #禁用该模块，该模块用于阻止对“referer”头字段中具有无效值的请求访问站点 --without-http_rewrite_module #禁用该模块，该模块用于请求重定向，依赖PCRE库 --without-http_proxy_module #禁用该模块，该模块用于http代理服务 --without-http_fastcgi_module #禁用将请求传给FastCGI服务器的模块 --without-http_uwsgi_module #禁用将请求传给uwsgi服务器的模块 --without-http_scgi_module #禁用将请求传给SCGI服务器的模块 --without-http_grpc_module #禁用将请求传给GRPC服务器的模块 --without-http_memcached_module #禁止该模块，该模块从memcached服务器获取响应 --without-http_limit_conn_module #禁止该模块，该模块用于限制每个定义密钥的连接数，例如来自单个ip地址的连接数 --without-http_limit_req_module #禁止该模块，该模块用于限制每个定义密钥的请求处理数速率，例如来自单个ip地址的请求处理速率 --without-http_empty_gif_module #禁止该模块，该模块用于发出单像素透明的GIF --without-http_browser_module #禁用该模块，该模块创建的变量的值取决于User-Agent请求标头字段的值 --without-http_upstream_hash_module #禁用该模块，该模块用于负载均衡的hash算法 --without-http_upstream_ip_hash_module #禁用该模块，该模块用于负载均衡的ip_hash算法 --without-http_upstream_keepalive_module #禁用该模块，该模块提供上游服务器的连接缓存 --without-http_upstream_zone_module #禁用该模块，该模块可以将上游组的运行时状态存储在共享内存区域中 --with-http_perl_module --with-http_perl_module=dynamic #用于在perl中实现位置和变量处理程序，并将perl调用插入到SSI中，依赖perl5.6.1或更高版本，默认不构建 --with-perl_modules_path=path #设置perl_modules模块保存目录 --with-perl=path #设置perl所在路径 --http-log-path=path #设置访问日志路径，默认是 prefix/logs/access.log --http-client-body-temp-path=path #设置存储客户端请求主体的临时文件目录，默认是prefix/ client_body_temp --http-proxy-temp-path=path #设置存储临时文件和从代理服务器接收的数据目录，默认是prefix/proxy_temp. --http-fastcgi-temp-path=path #设置存储从FastCGI服务器接收的数据的临时文件目录，默认prefix/fastcgi_temp --http-uwsgi-temp-path=path #设置存储从uwsgi服务器接收的数据的临时文件目录，默认prefix/uwsgi_temp --http-scgi-temp-path=path ##设置存储从scgi服务器接收的数据的临时文件目录，默认prefix/scgi_temp. --without-http #禁用http服务 --without-http-cache #禁用http缓存 --with-mail --with-mail=dynamic #启用POP3/IMAP4/SMTP邮件代理服务器，默认不构建 --with-mail_ssl_module #为邮件代理服务器提供SSL/TLS协议支持，依赖OpenSSL库，默认不构建 --without-mail_pop3_module #禁止POP3邮件代理服务 --without-mail_imap_module #禁止IMAP邮件代理服务 --without-mail_smtp_module #禁止SMTP邮件代理服务 --with-stream --with-stream=dynamic #允许构建流模块以进行通用的TCP/UDP代理和负载均衡，默认不构建 --with-stream_ssl_module #为流模块提供SSL/TLS协议支持，依赖OpenSSL库，默认不构建 --with-stream_realip_module #该模块将客户端地址更改为proxy协议头中发送的地址，默认不构建 --with-stream_geoip_module --with-stream_geoip_module=dynamic #该模块根据客户端IP地址和预编译的MaxMind数据库创建变量，依赖MaxMind GeoIP库，默认不构建 --with-stream_ssl_preread_module #该模块允许从ClientHello消息中提取信息而不终止SSL/TLS，默认不构建 --without-stream_limit_conn_module #禁止该模块，该模块用于限制每个定义密钥的连接数，例如来自单个ip地址的连接数 --without-stream_access_module #禁止该模块，该模块用于限制对某些客户端地址的访问 --without-stream_geo_module # --without-stream_map_module --without-stream_split_clients_module --without-stream_return_module #禁止该模块，该模块允许向客户端发送指定值，然后关闭连接 --without-stream_upstream_hash_module --without-stream_upstream_least_conn_module --without-stream_upstream_zone_module --with-google_perftools_module #该模块支持使用Google Performance Tools分析nginx工作进程，适用于nginx开发人员，依赖gperftools库默认不构建 --with-cpp_test_module # --add-module=path #加入第三方模块，path为 第三方模块路径 --add-dynamic-module=path #动态加载第三方模块 --with-compat #启动动态模块兼容性 --with-cc=path #指定C编译器路径 --with-cpp=path #指定C预处理器路径 --with-cc-opt=parameters #设置将添加到CFLAGS变量的其他参数，在FreeBSD下使用系统PCRE库时，应指定--with-cc-opt="-I /usr/local/include" --with-ld-opt=parameters #设置将在链接期间使用的其他参数，在FreeBSD下使用系统PCRE库时，应指定--with-ld-opt="-L /usr/local/lib" --with-cpu-opt=cpu #设置cpu类型，如: pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 --without-pcre #禁止使用PCRE库 --with-pcre #强制使用PCRE库，PCRE库用于支持url重写和正则模块 --with-pcre=path #指定PCRE库的源码路径，nginx会自动编译 --with-pcre-opt=parameters #为PCRE设置其他参数 --with-pcre-jit #使用“即时编译”支持（1.1.12，pcre_jit指令）构建PCRE --with-zlib=path #指定zlib库的源码路径，nginx会自动编译，用于文件压缩 --with-zlib-opt=parameters #为zlib设置其他参数 --with-zlib-asm=cpu #允许使用针对其中一个指定CPU优化的zlib，例如：pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 --with-libatomic #强制使用libatomic库 --with-libatomic=path #指定libatomic库的源码路径，nginx会自动编译 --with-openssl=path #指定openssl库的源码路径，nginx会自动编译 --with-openssl-opt=parameters #为openssl设置其他参数 --with-debug #启用调试日志 nginx配置详解 nginx配置详解☞点击显/隐内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#定义Nginx运行的用户和用户组user www www; #nginx进程数，建议设置为等于CPU总核心数。worker_processes 8;error_log /var/log/nginx/error.log error; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]pid /var/run/nginx.pid; #进程文件#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events&#123;#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。use epoll;#单个进程最大连接数（最大连接数=连接数*进程数）worker_connections 65535;&#125;#设定http服务器http&#123;include mime.types; #文件扩展名与文件类型映射表default_type application/octet-stream; #默认文件类型charset utf-8; #默认编码server_names_hash_bucket_size 128; #服务器名字的hash表大小client_header_buffer_size 32k; #上传文件大小限制large_client_header_buffers 4 64k; #设定请求缓存client_max_body_size 8m; #设定客户端请求缓存sendfile on; # 开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。tcp_nopush on; #防止网络阻塞tcp_nodelay on; #防止网络阻塞keepalive_timeout 120; #长连接超时时间，单位是秒#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#gzip模块设置gzip on; #开启gzip压缩输出gzip_min_length 1k; #最小压缩文件大小gzip_buffers 4 16k; #压缩缓冲区gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）gzip_comp_level 2; #压缩等级gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。gzip_vary on;limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用upstream blog.ha97.com &#123;#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。server 192.168.80.121:80 weight=3;server 192.168.80.122:80 weight=2;server 192.168.80.123:80 weight=3;&#125;#虚拟主机的配置server&#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.aaa.com wwww.bbb.com; index index.html index.htm index.php; root html; #站点根目录 location ~ .*\.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*\.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /var/log/nginx/access.log access; #对 "/" 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数， proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic "NginxStatus"; auth_basic_user_file conf/htpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125;&#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab个人的简单使用]]></title>
    <url>%2Fposts%2F3451632616.html</url>
    <content type="text"><![CDATA[个人设置 头像、语言设置 修改密码 免密设置 添加公钥后可在操作git仓库时免去输入用户名、密码的步骤。公钥获取：windows系统：打开C:\用户\username\\.ssh\id_rsa.pub文件，将内容复制到填写公钥的位置，其中username为当前用户名，一般是administratorlinux系统：输入cat ~/.ssh/id_rsa.pub命令，将内容复制到填写公钥的位置。如果没有id_rsa.pub文件，则需要创建秘钥，创建方法如下：windows系统：按“win+R”键，输入“cmd”并回车打开cmd窗口，输入“ssh-keygen”，按三次回车键，创建完成linux系统：在终端里输入“ssh-keygen”，按三次回车键，创建完成 创建项目 获取项目地址、下载项目 项目权限设置、添加项目成员]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[geoserver+postgresql搭建]]></title>
    <url>%2Fposts%2F2386358445.html</url>
    <content type="text"><![CDATA[geoserver简介: &ensp;&ensp;&ensp;&ensp;Geoserver是一个功能齐全,遵循OGC开放标准的开源WFS-T和WMS服务器。利用Geoserver可以把数据作为maps/images来发布(利用WMS来实现)也可以直接发布实际的数据(利用WFS来实现),同时也提供了修改,删除和新增的功能(利用WFS-T)。它是开源的 ,允许用户查看和编辑地理数据。GeoServer 是符合OGC 规范的一个全功能的WFS-T 和WMS server。 geoserver+postgresql环境搭建： 实验环境 系统及版本：Ubuntu16.0.4 jdk版本：1.8.0 tomcat版本：8.5 geoserver版本：2.14.1 postgresql版本：9.6 postgis版本：2.5 开始搭建： 1. 安装jdk1.8 1sudo apt-get install -y openjdk-8-jdk 2. 安装tomcat8.5 12sudo wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz #下载Tomcattar xf apache-tomcat-8.5.37.tar.gz -C /usr/local/ &amp;&amp; mv /usr/local/apache-tomcat-8.5.37 /usr/local/tomcat #解压Tomcat至/usr/local/tomcat目录 3. 安装geoserver 12sudo wget https://nchc.dl.sourceforge.net/project/geoserver/GeoServer/2.14.1/geoserver-2.14.1-war.zip #下载geoserver2.14.1sudo unzip geoserver-2.14.1-war.zip &amp;&amp; sudo unzip -d /usr/local/tomcat/webapps/geoserver geoserver.war #解压geoserver压缩包至/usr/local/tomcat/webapps/geoserver目录 注：提示”unzip: command not found”，请使用sudo apt-get install -y zip 安装zip 1/usr/local/tomcat/bin/startup.sh #启动tomcat tomcat启动成功后，在浏览器打开http://host_ip:8080/geoserver 访问geoserver服务将host_ip替换为server的ip地址，默认用户名：admin 密码：geoserver 4. 安装postgresql-9.6和postgis-2.5 123456sudo echo 'deb http://apt.postgresql.org/pub/repos/apt/ xenial-pgdg main'&gt;&gt;/etc/apt/sources.list.d/pgdg.list #添加postgresql安装源sudo wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - #导入存储库签名秘钥sudo apt-get update #更新包列表sudo apt-get install -y postgresql-9.6 #安装postgresql9.6sudo apt-get install -y postgresql-9.6-postgis-2.5 #安装postgresql9.6对应的postgis扩展sudo service postgresql start #启动postgresql服务 至此geoserver+postgresql搭建完成！参考资料：postgresql官方安装文档 通过docker安装 docker镜像地址：registry.cn-zhangjiakou.aliyuncs.com/kapyan/geoserver:2.14.1 说明： 容器已集成geoserver的JDBC Image Mosaic、Vector Tiles扩展 GEOWEBCACHE_CACHE_DIR目录在/var/app/tomcat/webapps/ROOT/geo_web_cache_dir目录 postgresql远程连接已开启，用户名：wanshan 密码：wanshan@2018 可用中文字体：楷体、宋体、新宋体 安装： 12docker pull registry.cn-zhangjiakou.aliyuncs.com/kapyan/geoserver:2.14.1docker run -it -d -p 80:8080 -p 5432:5432 --restart always --name geoserver -v /home/geoserver/data:/var/app/tomcat/webapps/ROOT/data/mydata -v /home/geoserver/geo_web_cache_dir:/var/app/tomcat/webapps/ROOT/geo_web_cache_dir geoserver FAQ 添加nginx反向代理 在nginx添加以下host文件配置，并重启 12345678910111213141516server &#123; server_name domain_name; #你的域名 listen 80; location / &#123; add_header 'Access-Control-Allow-Origin' *; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Headers' 'Authorization,Content-Type,Accept,Origin,User-Agent,DNT,Cache-Control,X-Mx-ReqToken,X-Requested-With'; add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS'; #配置跨域允许，防止程序调用geoserver被跨域拦截 proxy_pass http://localhost:8080; proxy_set_header Host $host:$server_port; &#125;&#125; geoserver添加JDBC Image Mosaic扩展 下载相应版本的JDBC Image Mosaic扩展并解压至geoserver所在目录的WEB-INF/lib/目录下geoserver2.14.1及扩展下载地址 12wget https://jaist.dl.sourceforge.net/project/geoserver/GeoServer/2.14.1/extensions/geoserver-2.14.1-imagemosaic-jdbc-plugin.zip #下载JDBC Image Mosaic扩展unzip -d /usr/local/tomcat/webapps/geoserver/WEB-INF/lib/ geoserver-2.14.1-imagemosaic-jdbc-plugin.zip #解压至geoserver所在目录的WEB-INF/lib/目录下 geoserver添加Vector Tiles扩展 下载相应版本的Vector Tiles扩展并解压至geoserver所在目录的WEB-INF/lib/目录下 12wget https://jaist.dl.sourceforge.net/project/geoserver/GeoServer/2.14.1/extensions/geoserver-2.14.1-vectortiles-plugin.zip #下载Vector Tiles扩展unzip -d /usr/local/tomcat/webapps/geoserver/WEB-INF/lib/ geoserver-2.14.1-vectortiles-plugin.zip #解压至geoserver所在目录的WEB-INF/lib/目录下 编辑geoserver所在目录的/WEB-INF/web.xml文件，在第4行下添加如下内容： 12345&lt;!--切片缓存目录--&gt;&lt;context-param&gt; &lt;param-name&gt;GEOWEBCACHE_CACHE_DIR&lt;/param-name&gt; &lt;param-value&gt;/usr/local/tomcat/webapps/geoserver/geo_web_cache_dir&lt;/param-value&gt;&lt;/context-param&gt; 然后重启tomcat 注：“/usr/local/tomcat/webapps/geoserver/geo_web_cache_dir”替换为自定义目录 geoserver开启jsonp 编辑geoserver所在目录的/WEB-INF/web.xml文件，去掉以下注释： 123443 &lt;!--&lt;context-param&gt;44 &lt;param-name&gt;ENABLE_JSONP&lt;/param-name&gt;45 &lt;param-value&gt;true&lt;/param-value&gt;46 &lt;/context-param&gt;--&gt; 改为 123443 &lt;context-param&gt;44 &lt;param-name&gt;ENABLE_JSONP&lt;/param-name&gt;45 &lt;param-value&gt;true&lt;/param-value&gt;46 &lt;/context-param&gt; postgresql开启远程连接 1.修改/etc/postgresql/9.6/main/postgresql.conf第59行： #listen_addresses = &apos;localhost&apos; 为 listen_addresses = &apos;*&apos; 2.在/etc/postgresql/9.6/main/pg_hba.conf的 # IPv4 local connections: host all all 127.0.0.1/32 md5 后添加一行： host all all 0.0.0.0/0 md5 注：0.0.0.0/0代码允许所有网段访问，也可指定特定网段，如192.168.1.0/24 postgresql创建超级用户 1234su postgres #切换至postgres用户psql #进入postgresqlCREATE ROLE test superuser PASSWORD '123456' login; #创建名为test，密码为123456的超级用户\du #查看所有用户 为数据库添加postgis空间数据库扩展 12345678su postgres #切换至postgres用户psql -d yourdatabase -c "CREATE EXTENSION postgis;"psql -d yourdatabase -c "CREATE EXTENSION postgis_topology;"psql -d yourdatabase -c "CREATE EXTENSION postgis_sfcgal;"psql -d yourdatabase -c "CREATE EXTENSION fuzzystrmatch;"psql -d yourdatabase -c "CREATE EXTENSION address_standardizer;"psql -d yourdatabase -c "CREATE EXTENSION address_standardizer_data_us;"psql -d yourdatabase -c "CREATE EXTENSION postgis_tiger_geocoder;" GDAL PostGIS Raster driver未找到 从postgis2.1.3开始，默认禁用out-of-db rasters和所有raster驱动，启用他们需要在系统中设置环境变量 12echo "POSTGIS_GDAL_ENABLED_DRIVERS=ENABLE_ALL"&gt;&gt; /etc/postgresql/9.6/main/environment #添加环境变量service postgresql restart #重启postgresql 参考资料：postgis官方安装文档 中文字段乱码问题 如果预览视图显示中文为“□□□□”，是因为系统中没有相应的字体，需要安装字体，可以在windows系统的C:\Windows\fonts目录下找到需要的字体，并上传至/usr/share/fonts/custom目录下（没有则新建custom目录），并在/usr/share/fonts/custom目录执行以下命令 123456sudo apt-get install -y font-manager #安装字体管理工具sudo mkfontscalesudo mkfontdirsudo fc-cache -fv sudo fc-list #查看已安装字体注：高版本系统可能没有mkfontscale命令，将字体所在路径加入/etc/fonts/fonts.conf文件的"&lt;dir&gt;your_fonts_path&lt;/dir&gt;"即可 如果xml的中文显示为’???’，是因为系统的默认编码可能不支持中文，如“POSIX” 1234sudo locale #查看当前系统编码sudo locale -a #查看系统支持的所有编码export LANG="en_US.UTF-8" #修改系统编码（临时修改，重启失效）echo 'export LANG="en_US.UTF-8"' &gt;&gt; /etc/profile #修改系统编码（永久修改） 请求跨域问题 cors-filter-2.6.jar下载java-property-utils-1.13.jar下载将cors-filter-2.6.jar和java-property-utils-1.13.jar放入geoserver的WEB-INF/lib目录在geoserver的WEB-INF/web.xml文件的filter级标签末尾添加以下代码： 12345678910111213141516171819202122232425262728&lt;filter&gt; &lt;filter-name&gt;CORS&lt;/filter-name&gt; &lt;filter-class&gt;com.thetransactioncompany.cors.CORSFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;cors.allowOrigin&lt;/param-name&gt; &lt;param-value&gt;*&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.supportedMethods&lt;/param-name&gt; &lt;param-value&gt;GET, POST, HEAD, PUT, DELETE&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.supportedHeaders&lt;/param-name&gt; &lt;param-value&gt;Accept, Origin, X-Requested-With, Content-Type, Last-Modified&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.exposedHeaders&lt;/param-name&gt; &lt;param-value&gt;Set-Cookie&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.supportsCredentials&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CORS&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;]]></content>
      <categories>
        <category>geoserver</category>
      </categories>
      <tags>
        <tag>geoserver</tag>
        <tag>postgresql</tag>
      </tags>
  </entry>
</search>
