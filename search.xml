<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[echo 0 > /proc/sys/kernel/hung_task_timeout_secs disables this message故障处理]]></title>
    <url>%2Fposts%2F3397780315.html</url>
    <content type="text"><![CDATA[用xshell连接服务器出错:ssh_exchange_identification: Connection closed by remote host在阿里云控制台通过vnc连接服务器后出现如下信息： 问题原因：默认情况下，linux会最多使用40%的可用内存作为文件系统缓存。当超过此阈值后，文件系统会将缓存中的内存全部写入磁盘，导致后续的I/O请求都是同步的。将缓存写入磁盘时，有一个默认120秒的超时时间。出现上面问题的原因是I/O子系统的处理速度不够快，不能在120秒将缓存中的数据全部写入磁盘。I/O系统响应缓慢，导致越来越多的请求堆积，最终系统内存全部被占用，导致系统失去响应。 解决方法根据应用程序情况，对vm.dirty_ratio:当文件系统缓存脏页数量达到系统内存百分之多少时（如10%），系统不得不开始处理缓存脏页（因为此时脏页数量已经比较多，为了避免数据丢失需要将一定脏页刷入外存）；在此过程中很多应用进程可能会因系统转而处理文件I/O而阻塞vm.dirty_background_ratio:当文件系统缓存脏页数量达到系统内存百分之多少时（5%）就会触发pdflush/flush/kdmflush等后台会写进程运行，将一定缓存的脏页异步地刷入外存两个参数进行调优设置 。推荐如下设置：123sysctl -w vm.dirty_ratio=10sysctl -w vm.dirty_background_ratio=5sysctl -p 如果让系统永久生效123echo "vm.dirty_background_ratio = 5"&gt;&gt;/etc/sysctl.confecho "vm.dirty_ratio = 10"&gt;&gt;/etc/sysctl.confsysctl -p]]></content>
      <categories>
        <category>linux系统故障</category>
      </categories>
      <tags>
        <tag>hung_task_timeout_secs disables this message</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis管理]]></title>
    <url>%2Fposts%2F2273748276.html</url>
    <content type="text"><![CDATA[基本数据类型 类型 说明 String 字符串 Redis字符串数据类型的相关命令用于管理redis字符串值 Hash 哈希 Redishash是一个string类型的field和value的映射表，hash特别适合由于存储对象。Redis中每个hash可以存储2³²-1键值对（40多亿）。 List 列表 Redis列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素到列表的头部或尾部一个列表最多可以包含2³²-1个元素（4294967295, 每个列表超过40亿个元素）。 Set 集合 Redis的Set是String类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Sorted set 有序集合 Redis有序集合和集合一样也是string类型元素的集合，且不允许重复的成员。 全局key操作 命令 含义 KEYS * 查看KEY，支持通配符 DEL 删除给定的一个或多个key EXISTS 检查是否存在 RENAME 变更key名 SORT 键值排序，有非数字时报错 TYPE 返回键所存储值的类型 DUMP\RESTORE 序列化与反序列化 EXPIRE\PEXPIRE 以秒\毫秒设定生存时间 TTL\PTTL 以秒\毫秒为单位返回生存时间 PERSIST 取消生存时间设置 RANDOMKEY 返回数据库中的任意键 String（字符串） 命令 描述 SET key value 设置指定key的值 GET key 获取指定key的值 GETRANGE key start end 返回key中字符串值的子字符 GETSET key value 将给定key的值设为value，并返回key的旧值（old value） GETBIT key offset 对key所存储的字符串值获取指定偏移量上的位（bit） MGET key1 [key2..] 获取所有（一个或多个）给定key的值 SETBIT key offset value 对key所存储的字符串值设置或清除指定偏移量上的位（bit） SETEX key seconds value 将值value关联到key，并将key的过期时间设置为seconds（以秒为单位） SETNX key value 只有在key不存在时设置key的值 SETRANGE key offset value 用value参数覆写给定key所存储的字符串值，从偏移量offset开始 STRLEN key 返回key所存储的字符串值的长度 MSET key value [key value …] 同时设置一个或多个key-value对 MSETNX key value [key value …] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在 PSETEX key milliseconds value 这个命令和SETEX相似，但它以毫秒为单位设置key的生存时间 INCR key 将key中存储的数字值增一 INCRBY key increment 将key所存储的值加上给定的增量值（increment） INCRBYFLOAT key increment 将 key 所储存的值加上给定的浮点增量值（increment） DECR key 将key中存储的数字值减一 DECRBY key decrementkey 所储存的值减去给定的减量值（decrement） APPEND key value 如果 key 已经存在并且是一个字符串，APPEND 命令将 指定value 追加到改 key 原来的值（value）的末尾 应用场景：常规计数：微博数、粉丝数等。 Hash（字典）我们可以将Redis中的Hashes类型看成具有String Key和String Value的map容器。该类型非常适合用于存储值对象的信息。如Username、Password和Age等。如果Hash中包含很少的字段，那么该类型的数据也将仅占用很少的磁盘空间。 命令 描述 HDEL key field [field2] 删除一个或多个哈希表字段 HEXISTS key field 查看哈希表key中，指定的字段是否存在 HGET key field 获取存储在哈希表中指定字段的值 HGETALL key 获取在哈希表中指定key的所有字段和值 HINCRBY key field increment 为哈希表key中的指定字段的整数值加上增量increment HINCRBYFLOAT key field increment 为哈希表key中的指定字段的浮点数值加上增量increment HKEYS key 获取所有哈希表中的字段 HLEN key 获取哈希表中字段的数量 HMGET key field1 [field2] 获取所有给定字段的值 HMSET key field1 value1 [field2 value2] 同时将多个field-value（域-值）对设置到哈希表key中 HSET key field value 将哈希表key中的字段field的值设为value HSETNX key field value 只有在字段field不存在时，设置哈希表字段的值 HVALS key 获取哈希表中所有值 HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对 应用场景：存储部分变更的数据，如用户信息等。 List（列表）List类型是按照插入顺序排序的字符串链表。和数据结构中的普通链表一样，我们可以在其头部和尾部添加新的元素。在插入时，如果该键并不存在，Redis将为该键创建一个新的链表。与此相反，如果链表中所有的元素均被移除，那么该键也将会被从数据库中删除。List中可以包含的最大元素数量是4294967295。 命令 描述 BLPOP key1 [key2] timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 BRPOP key1 [key2] timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 BRPOPLPUSH source destination timeout 从列表弹出一个值，将弹出的元素插入到另外一列表中并返回它；如果列表没有元素会阻塞列表直到等到 LINDEX key index 通过索引获取列表中的元素 LINSERT key BEFORE/AFTER pivot value 在列表的元素前/后插入元素 LLen key 获取列表长度 LPOP key 移出并获取列表的第一个元素 LPUSH key value1 [value2] 将一个或多个值插入到列表头部 LPUSHX key value 将一个值插入到已存在的列表头部 LRANGE key start stop 获取列表指定范围内的元素 LREM key count value 移出列表元素 LSET key index value 通过索引设置列表元素的值 LTRIM key start stop 对一个列表进行修剪（trim），就是说，让列表只保留指定区间内的元素，不在指定区间内的元素都将被删除 RPOP key 移出并获取列表最后一个元素 RPOPLPUSH source destination 移出列表的最后一个元素，并将该元素加到另一个列表并返回 RPUSH key value1 [value2] 在列表中添加一个或多个值 RPUSHX key value 为已存在的列表添加值 应用场景：消息队列系统，比如sina微博。在Redis中我们的最新微博ID使用了常驻缓存，这是一直更新的。但是做了限制不能超过5000个ID,因此获取ID的函数会一直询问Redis。只有在start/count参数超出了这个范围的时候，才需要去访问数据库。系统不会像传统方式那样“刷新”缓存，Redis实例中的信息永远是一致的。SQL数据库（或是硬盘上的其他类型数据库）只是在用户需要获取“很远”的数据时才会被触发，而主页或第一个评论页是不会麻烦到硬盘上的数据库。 SET (集合)Set类型看作为没有排序的字符集合。Set可包含的最大元素数量是4294967295。如果多次添加相同元素，Set中将仅保留该元素的一份拷贝。 名令 描述 SADD key member1 [member2] 向集合添加一个或多个成员 SCARD key 获取集合的成员数 SDIFF key1 [key2] 返回给定所有集合的差集 SDIFFSTORE destination key1 [key2] 返回给定所有集合的差集并存储在destination中 SISMEMBER key member 判断member元素是否是集合key的成员 SMEMBERS key 返回集合中的所有成员 SMOVE source destination member 将member元素从source集合移动到destination集合 SPOP key 移除并返回集合中的一个随机元素 SRANDMEMBER key [count] 返回集合中一个或者多个随机数 SREM key member1 [member2] 移除集合中一个或多个成员 SUNION key1 [key2] 返回所有给定集合的并集 SUNIONSTORE destination key1 [key2] 所有给定集合的并集存储在destination集合中 SSCAN key cursor [MATCH pattern] [COUNT count] 迭代集合中的元素 应用场景：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis还为集合提供了求交集、并集、差集等操作，可以非常方便地实现如共同关注、共同喜好、共同好友等功能，对上面的所有集合操作，还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的结合中。 SortedSet （有序集合）Sorted-Set中的每一个成员都会有一个分数（score）与之关联，Redis正是通过分数来为集合中的成员进行从小到大的排序。成员是唯一的，但是分数（score）却是可以重复的。集合是通过哈希表实现的，所以添加、删除、查找的复杂度都是O(1)。集合中最大的成员数为2³²-1（4294967295, 每个集合可存储40多亿个成员）。 命令 描述 ZADD key score1 member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的分数 ZCARD key 获取有序集合的成员数 ZCOUNT key min max 计算在有序集合中指定区间分数的成员数 ZINCRBY key increment member 有序集合中对指定成员的分数加上增量increment ZINTERSTORE destination numkeys key [key …] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合key中 ZLEXCOUNT key min max 在有序集合中计算指定字典区间内成员数量 ZRANGE key start stop [WITHSCORES] 通过索引区间返回有序集合中指定区间内的成员 ZRANGEBYLEX key min max [LIMIT offset count] 通过字典区间返回有序集合的成员 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] 通过分数返回有序集合指定区间内的成员 ZRANK key member 返回有序集合中指定成员的索引 ZREM key member [member …] 移除有序集合中的一个或多个成员 ZREMRANGEBYLEX key min max 移除有序集合中给定的字典区间的所有成员 ZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员 ZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所成员 ZREVRANGE key start stop [WITHSCORES] 返回有序集合中指定区间的成员，通过索引，分数从高到低 ZREVRANGEBYSCORE key max min [WITH SCORES] 返回有序集合中指定分数区间内的成员，分数从高到低排序 ZREVRANK key member 返回有序集合中指定成员的排名，有序集合成员按分数值递减（从大到小）排序 ZSCORE key member 返回有序集合中，成员的分数值 ZUNIONSTORE destination nunkeys key [key …] 计算给定的一个或多个有序集的并集，并存储在新的key中 ZSCAN key cursor [MATCH pattern] [COUNT count] 迭代有序集合中的元素（包括元素成员和分数） 应用场景：排行榜应用，取TOP N操作这个需求与上面需求的不同之处在于，前面操作以时间为权重，这个是以某个条件为权重，比如按顶的次数排序，这时候就需要我们的SortedSet了，将要排序的值设置成sorted set的score,将具体的数据设置成相应的value，每次只需要执行一条ZADD命令即可。 消息模式Redis发布消息通常有两种模式： 队列模式（queuing） 发布-订阅模式（publish-subscribe）任务队列：顾名思义，就是“传递消息的队列”。与任务对列进行交互的实体有两类，一类是生产者（producer），另一类则是消费者（consumer）。生产者将需要处理的任务放入任务队列中，而消费者则不断地从任务独立中读入任务信息并执行。 任务队列的好处： 松耦合 生产者消费者只需按照约定的任务描述格式，进行编写代码 易于扩展 多消费者模式下，消费者可以分布在多个不同的服务器中，由次降低单台服务器的负载 Redis发布订阅其实从Pub/Sub的机制来看，它更像是一个广播系统，多个Subscriber可以订阅多个Channel，多个Publisher可以往多个Channel中发布消息。可以简单的理解： Subscriber：收音机，可以收到多个频道，并以队列方式显示Publisher：电台，可以往不同的FM频道中发消息Channel：不同频率的FM频道 发布订阅模型一个Publisher，多个Subscriber模型可以作为消息队列或者消息管道。主要应用：通知、公告。多个Publisher，一个Subscriber模型可以将Pub/Sub做成独立的HTTP接口，各应用程序作为Publisher向Channel中发送消息，Subscriber端收到消息后执行相应的业务逻辑，比如写数据库，显示等等。主要应用：排行榜、投票、计数。多个Publisher，多个Subscriber模型顾名思义，就是可以向不同的Channel中发送消息，由不同的Subscriber接收。主要应用：群聊、聊天。 实践发布订阅发布订阅命令 命令 描述 PUBLISH channel msg 将信息message发送到指定的频道channel SUBSCRIBE channel [channel …] 订阅频道，可以同时订阅多个频道 UNSUBSCRIBE [channel …] 取消订阅指定的频道，如果不指定频道，则会取消订阅所有频道 PSUBSCRIBE pattern [pattern …] 订阅一个或个符合给定模式的频道，每个模式以*作为匹配符，比如it*匹配所有以it开头的频道（it.news、it.blog、it.tweets等），new.*匹配所有以news.开头的频道 PUNSUBSCRIBE pattern [pattern…] 退订指定的规则，如果没有参数则会退订所有规则 PUBSUB subcommand [argument [argument …]] 查看订阅与发布系统状态 注意：使用发布订阅模式实现的消息队列，当有客户端订阅channel后只能收到后续发布到该频道的消息，之前发送的不会缓存，必须Provider和Consumer同时在线。 消息队列系统对比客户端在执行订阅命令只有进入了订阅状态，只能接受SUBSCRIBE、PSUBSCRIBE、UNSUBSCRIBE、PUNSUBSCRIBE四个命令。开启的订阅客户端，无法收到该频道之前的消息，因为Redis不会对发布的消息进行持久化。和很多专业的消息队列系统（例如kafka、rocketMQ）相比，Redis的发布订阅略显粗糙，例如：无法实现消息堆积和回溯。但胜在足够简单，如果当前场景可以容忍这些缺点，也不失为一个不错的选择。 Redis事务管理redis中的事务跟关系型数据库中的事务是一个相似的概念，但是有不同之处。关系型数据库事务执行失败后面的sql语句不再执行，而redis中的一条命令执行失败，其余的命令照常执行。redis中开启一个事务是使用multi，相当于begin/start transaction，exec提交事务，discard取消队列命令（非回滚操作）。redis、mysql事务对比： Mysql Redis 开启 start/begin transaction multi 语句 普通SQL 普通命令 失败 rollback回滚 discard取消（是队列里面的命令不执行，队列里面的任务根本就没有执行。而不是执行了也可以撤回来） 成功 commit exec Redis事务命令 命令 描述 DISCARD 取消事务，放弃执行事务块内的所有命令 EXEC 执行所有事务块内的命令 MULTI 标记一个事务块的开始 UNWATCH 取消WATCH命令对所有key的监视 WATCH key [key …] 监视一个或多个key,如果在事务执行之前这个或这些被其他命令所改动，那么事务将被打断 事务执行举例1234567ZADD salary 2000 user1ZADD salary 3000 user2ZRANGE salary 0 -1 WITHSCORESMULTIZINCRBY salary 1000 user1ZINCRBY salary -1000 user2EXEC redis中事务的锁机制举例：我正在买票 Ticket -1 ，money -100而票只有1张，如果在multi之后，和exec之前，票被别人买了，即ticket变成了0。我该如何观察这种情景，并不再提交： 悲观的想法：世界充满危险，肯定有人和我抢，给ticket上锁，只有我能操作。[悲观锁]乐观的想法：没有那么多人和我抢，只要注意，有没有人更改ticket的值就可以了。[乐观锁] Redis的事务中，启用的是乐观锁，只负责监测key有没有被改动。 Redis服务管理命令 命令 描述 BGREWRITEAOF 异步执行一个AOF文件重写操作 BGSAVE 在后台异步保存当前数据库的数据到磁盘 CLIENT KILL [ip:port] [ID client-id] 关闭客户端连接 CLINET LIST 后去连接到服务器的客户端连接列表 CLINET GETNAME 后去连接名称 CLINET PAUSE timeout 在指定时间内终止运行来自客户端的命令 CLINET SETNAME connection-name 设置当前连接的名称 CLUSTER SLOTS 获取集群节点的映射数组 COMMAND 获取redis命令详情数组 COMMAND COUNT 获取redis命令总数 COMMAND GETKEYS 获取给定命令的所有键 TIME 返回当前服务器时间 COMMAND INFO command-name [command-name…] 获取指定redis命令描述的数组 CONFIG GET parameter 获取指定配置参数的值 CONFIG REWRITE 对启动redis服务器时所指定的redis.conf配置文件进行改写 CONFIG SET parameter value 修改redis配置参数，无需重启 CONFIG RESETSTAT 重置INFO命令中的某些统计数据 DBSIZE 返回当前数据库的key的数量 DEBUG OBJECT key 获取key的调试信息 DEBUG SEGFAULT 让redis服务崩溃 FLUSHALL 删除所有数据库的所有key FLUSHDB 删除当前数据库的所有key INFO [section] 获取redis服务器的各种信息和统计数值 LASTSAVE 返回最近一次redis成功将数据保存到磁盘上的时间，以unix时间戳格式表示 MONITOR 实时打印出redis服务器接受到的命令，调试用 ROLE 返回主从实例所属的角色 SHUTDOWN [NOSAVE] [SAVE] 异步保存数据到硬盘，并关闭服务器 SLAVEOF host port 将当前服务器转变为指定服务器的从属服务器（slave server） SLOWLOG subcommand [argument] 管理redis的慢日志 SYNC 用于复制功能（replication）的内部命令 Redis慢日志查询Slow log是Redis用来记录查询执行时间的日志系统slow log保存在内存里面，读写速度非常快可以通过修改redis.conf文件或者用CONFIG GET和CONFIG SET 命令对他们动态地进行修改12345678#redis.conf修改slowlog-log-slower-than 10000 超过多少微秒#命令行修改CONFIG SET slowlog-log-slower-than 10000CONFIG SET sloelog-max-len 1000 保存多少条慢日志CONFIG GET slow*SLOWLOG GETSLOWLOG RESET]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Redis的一些了解]]></title>
    <url>%2Fposts%2F424997909.html</url>
    <content type="text"><![CDATA[介绍 Redis是一个使用ANSIC编写的开源、支持网络、基于内存、可选持久性的键值对（key-value）存储数据库。从2015年6月开始，Redis的开发由Redis Labs赞助，而2013年5月至2015年6月期间，其开发由Pivotal赞助。在2013年5月之前，其开发由VMware赞助。根据月度排行榜网站DB-Engines.com的数据显示，Redis是最流行的键值对存储数据库。 软件获取和帮助官方网站：https://redis.io官方各版本下载地址：http://download.redis.io/releases/Redis 中文命令参考：http://redisdoc.com中文网站1：http://redis.cn中文网站2：http://www.redis.net.cn Redis特性 高速读写，数据类型丰富 支持持久化，多种内存分配及回收策略 支持弱事务，消息队列、消息订阅 支持高可用，支持分布式分片集群 企业缓存数据库解决方案对比Memcached 优点：高性能读写、单一数据类型、支持客户端分布式集群、一致性hash多核结构、多线程读写性能高。 缺点：无持久化、节点故障可能出现缓存穿透、分布式需要客户端实现、跨机房数据同步困难、架构扩容复杂度高。 Redis 优点：高性能读写、多数据类型支持、数据持久化、高可用架构、支持自定义虚拟内存、支持分布式分片集群、单线程读写性能极高。 缺点：多线程读写较Memcached慢。 Tair 优点：高性能读写、支持三种存储引擎（ddb、rdb、ldb）、支持高可用、支持分布式分片集群、支撑了几乎所有淘宝业务的缓存。 缺点：单机情况下，读写性能较其他两种产品慢。 Redis安装一键安装脚本，适用于centos7.x系统1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#!/bin/bash#定义变量version="4.0.11"redis_dir=/usr/local/redis-$version#编译安装yum -y install gccwget http://download.redis.io/releases/redis-$&#123;version&#125;.tar.gz || exit 1tar xf redis-$&#123;version&#125;.tar.gz &amp;&amp; cd redis-$versionmake || make MALLOC=libc mkdir -p /usr/local/redis-$&#123;version&#125;/binmkdir -p /usr/local/redis-$&#123;version&#125;/etccp redis.conf /usr/local/redis-$&#123;version&#125;/etc cd src cp mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server redis-trib.rb /usr/local/redis-$&#123;version&#125;/binln -s /usr/local/redis-$&#123;version&#125; /usr/local/redis#后台启动redissed -i 's/daemonize no/daemonize yes/g' /usr/local/redis/etc/redis.conf#加入环境变量echo 'redis_path=/usr/local/redis/bin' &gt;&gt;/etc/profileecho 'export PATH=$PATH:$redis_path'&gt;&gt;/etc/profile#修改内核参数echo "vm.overcommit_memory = 1"&gt;&gt;/etc/sysctl.confsysctl -p#redis启动脚本cat &gt;/usr/local/redis/bin/redis&lt;&lt;EOF#!/bin/bash## redis Startup script for Redis Server## description: Redis is an open source, advanced key-value store.## processname: redis-serverBIN="/usr/local/redis/bin"CONFIG="/usr/local/redis/etc/redis.conf"PIDFILE="/var/run/redis_6379.pid"### Read configurationprog="redis-server"desc="Redis Server"start() &#123; [ -e \$PIDFILE ] &amp;&amp; PID=\`cat \$PIDFILE\` || PID=0 if [ \$PID -ne 0 ];then echo "\$desc already running...." else echo "Starting \$desc " \$BIN/\$prog \$CONFIG fi&#125;stop() &#123; [ -e \$PIDFILE ] &amp;&amp; PID=\`cat \$PIDFILE\` || PID=0 if [ \$PID -ne 0 ];then echo "Stopping \$desc " kill -QUIT \$PID rm -rf \$PIDFILE else echo "\$desc is not running.... " fi &#125;restart() &#123; stop start&#125;case "\$1" in start) start ;; stop) stop ;; restart) restart ;; *) echo \$"Usage: \$0 &#123;start|stop|restart|condrestart|status&#125;"esacEOFchmod +x /usr/local/redis/bin/redisecho -e "[Unit]\nDescription=redis\nAfter=network.target\n[Service]\nType=forking\nExecStart=/usr/local/redis/bin/redis start\nExecReload=/usr/local/redis/bin/redis restart\nExecStop=/usr/local/redis/bin/redis stop\nPrivateTmp=true\n[Install]\nWantedBy=multi-user.target"&gt;/usr/lib/systemd/system/redis.servicechmod 754 /usr/lib/systemd/system/redis.servicesystemctl enable redisecho 'redis安装完成，请使用"systemctl start redis"启动redis服务...' redis.conf配置说明1234567891011121314151617181920212223daemonize no/yes #后台启动port 6379 #默认端口timeout 60 #设置客户端连接时的超时时间，单位为秒，当客户端在这段时间内没有发出任何指令，将关闭该连接。默认值为0，表示不关闭tcp-keepalive 300 #单位是秒，表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞，官方建议300s,如果设置为0，则不会周期性的检测appendonly no/yes #AOF日志开关是否打开logfile /var/log/redis.log #日志文件位置loglevel notice #定义日志级别。默认值为notice，可选debug(记录大量日志信息，适用于开发、测试阶段)、verbose(较多日志信息)、notice(适量日志信息，适用于生产环境)、warning(仅有部分重要，关键信息才会被记录)databases 16 #设置数据库的数目。默认的数据库是DB0，可以在每个连接上使用select &lt;dbid&gt;命令选择一个不同的数据库，dbid是一个介于0到databases -1之间的数值。默认值是16，也就是默认Redis有16个数据库dbfilename dump.rdb #RDB持久化数据文件bind 10.0.0.51 ip2 ip3 ip4 #指定IP地址进行监听protected-mode yes/no #禁止protected-mode（保护模式，是否只允许本地访问）requirepass root #增加认证密码 &#123;password&#125;maxclients 1000 #设置客户端最大并发连接数，默认无限制。当客户端连接数达到限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxmemory 1024000000 #设置redis最大占用内存，单位为字节maxmemory-policy noeviction #当内存使用达到最大值时，redis使用的清除策略： volatile-lru 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used ) allkeys-lru 利用LRU算法移除任何key volatile-random 移除设置过过期时间的随机key allkeys-random 移除随机key volatile-ttl 移除即将过期的key(minimal TTL) noeviction 不移除任何key，只是返回一个写错误 ，默认选项maxmemory-samples 10 #LRU和minimal TTL算法都不是精准的算法，但是相对精确的算法（为了节省内存）。可以通过maxmemory-samples设置样本数，redis默认选择5个样本进行检测， 如果增加，会提高LRU或TTL的精准度，redis作者测试的结果是当这个配置为10时已经非常接近全量LRU的精准度了，并且增加maxmemory-samples会导致在主动清理时消耗更多的CPU时间。 Redis数据持久化redis提供了多种不同级别的持久化方式：一种是RDB，另一种是AOF。 RDB持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time-snapshot）。在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb的二进制文件中。你可以对 Redis 进行设置，让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时，自动保存一次数据集。也可以通过调用 SAVE或者 BGSAVE，手动让 Redis 进行数据集保存操作。比如说，以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时，自动保存一次数据集:save 60 1000这种持久化方式被称为快照 snapshotting。当 Redis 需要保存 dump.rdb 文件时，服务器执行以下操作Redis 调用forks. 同时拥有父进程和子进程。子进程将数据集写入到一个临时 RDB 文件中。当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。优点： RDB是一个非常紧凑（compact）的文件，它保存了Redis在某个时间点上的数据集。这种文件非常适合用于进行备份：比如说，可以在最近的24小时内，每小时备份一次RDB文件，并且在每个月的每一天，也备份一个RDB文件，即使遇到问题，也可以随时将数据集还原到不同的版本。 RDB非常适用于灾难恢复（disaster recovery）：他只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。 RDB可以最大化Redis的性能：父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘I/O操作。 RDB在恢复大数据集时的速度比AOF的恢复速度要快。 缺点： 虽然Redis允许设置不同的保存点（save point）来控制保存RDB文件的频率，但是，因为RDB文件需要保存整个数据集的状态，所以它并不是一个轻松的操作。可能至少5分钟才保存一次RDB文件。在这种情况下，一旦发生故障停机，可能会丢失好几分钟数据。 每次保存RDB的时候，Redis都要fork出一个子进程，并由子进程来进行实际的持久化工作。在数据集比较庞大时，fork可能会非常耗时，造成服务器在某某毫秒内停止处理客户端；如果数据集非常巨大，并且CPU时间非常紧张的话，这种停止时间甚至可能会长达整整一秒。虽然AOF重写也需要进行fork，但无论AOF重写的执行间隔有多长，数据的耐久性都不会有任何损失。 AOF持久化记录服务器执行的所有写操作命令，并在服务器启动前，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以Redis协议的格式来保存，新命令会被追加到文件的末尾。Redis还可以在后台对AOF文件进行重写（rewrite），使得AOF文件的体积不会超出保存数据集状态所需要的实际大小。Redis还可以同时使用AOF持久化和RDB持久化。在这种情况下，当Redis重启时，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。甚至可以关闭持久化功能，让数据只在服务器运行时存在。只进行追加操作的文件（append-only file，AOF）快照功能并不是非常耐久：如果Redis因为某些原因而造成故障停机，那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。尽管对于某些程序来说，数据的耐久性不是最重要的考虑因素，但是对于那些追求完全耐久能力的程序员来说，快照功能就不太适用了。从1.1版本开始，Redis增加了一种完全耐久的持久化方式：AOF持久化。可以通过修改配置文件来打开AOF功能：appendonly yes每当Redis执行一个改变数据集的命令方式（比如SET），这个命令就会被追加到AOF文件的末尾，当Redis重启时，程序就可以通过重新执行AOF文件中的命令来达到重建数据集的目的。 优点： 使用AOF会让Redis更加耐久：可以使用不同的fsync策略：无fsync，每秒fsync，每次写的时候fsync。使用默认的每秒fsync策略，Redis的性能依然很好（fsync是由后台线程进行处理的，主线程会尽力处理客户端请求），一旦出现故障，最多丢失1秒的数据。 Redis可以在AOF文件体积变得过大时，自动在后台对AOF进行重写：重写后的新AOF文件包含了恢复当前数据集所需要的最小命令集合。整个重写操作是绝对安全的，因为Redis在创建新AOF文件的过程中，会继续将命令追加到现有的AOF文件里面，即使重写过程中发生停机，现有的AOF文件也不会丢失。 一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。 AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。导出（export）AOF文件也非常简单：举个例子，如果不小心执行了FLUSHALL命令，但只要AOF文件未被重写，只要停止服务器，移除AOF文件末尾的FLUSHALL命令，并重启Redis，就可以将数据集恢复到FLUSHALL执行之前的状态。 缺点： 对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。 在一般情况下，每秒fsync的性能依然非常高，而关闭fsync可以让AOF的速度和RDB一样块，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB可以提供更有保证的最大延迟时间（latency）。 AOF在过去曾经发生过这样的bug：因为个别命令的原因，导致AOF文件在重新载入时，无法将数据集恢复成保存时的原样。（举个例子，阻塞命令BRPOPLPUSH就曾引起过这样的bug）测试套件里为这种情况添加了测试：他们会自动生成随机的、复杂的数据集，并通过重新载入这些数据来确保一切正常。虽然这种bug在AOF文件中并不常见，但是对比来说，RDB几乎是不可能出现这种bug的。 AOF日志重写因为AOF的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加，AOF文件的体积也会变得越来越大。举个例子，如果对一个计数器调用了100次INCR，那么仅仅是为了保存这个计数器的当前值，AOF文件就需要使用100条记录（entry）。然而实际上，只使用了一条SET命令已经足以保存计数器的当前值了，其余99条记录实际上都是多余的。为了处理这种情况，Redis支持一种有趣的特性：可以在不打断服务客户端的情况下，对AOF文件进行重建（rebuild）。执行BGREWRITEAOF命令，Redis将生成一个新的AOF文件，这个文件包含重建当前数据集所需的最少命令。Redis2.2需要手动执行BGREWRITEAOF命令。 AOF有多耐用可以配置Redis多久才将数据fysnc到磁盘一次。有三种方式：每次有新命令追加到AOF文件时就执行一次fsync：非常慢，也非常安全。每秒fsync一次：足够快（和使用RDB持久化差不多），并且在故障时只会丢失1秒钟的数据。从不fsync:将数据交给操作系统来处理。更快，也更不安全的选择。推荐（并且也是默认）的措施为每秒fsync一次，这种fsync策略可以兼顾速度和安全性。 如果AOF文件损坏了怎么办服务器可能在程序正在对AOF文件进行写入时停机，如果停机造成了AOF文件出错（corrupt），那么Redis在重启时会拒绝载入这个AOF文件，从而确保数据的一致性不会被破坏。当发生这种情况时，可以用以下方法来修复出错的AOF文件：为现有的AOF文件创建一个备份。使用Redis附带的redis-check-aof程序，对原来的AOF文件进行修复，redis-check-aof –fix使用diff -u对比修复后的AOF文件和原始AOF文件的备份，查看两个文件之间的不同之处。（可选）重启Redis服务器，等待服务器载入修复后的AOF文件，并进行数据恢复。 如何选择使用哪种持久化方式一般来说，如果想达到足以媲美postgresql的数据安全性，应该同时使用两种持久化功能。如果非常关心数据，但仍然可以承受数分钟以内的数据丢失，可以只使用RDB持久化。很多用户都只使用AOF持久化，但并不推荐这种方式：因为定时生成RDB快照（snapshot）非常便于进行数据库备份，并且RDB恢复数据集的速度也要比AOF恢复的速度快，除此之外，使用RDB还可以避免之前提到的AOF程序的bug。 AOF和RDB之间的相互作用在版本号大于等于2.4的Redis中，BGSAVE执行的过程中，不可以执行BGREWRITEAOF。反过来说，在BGREWRITEAOF执行过程中，也不可执行BGSAVE。这可以防止两个Redis后台进程同时对磁盘进行大量的I/O操作。如果BGSAVE正在执行，并且用户显示地调用BGREWRITEAOF命令，那么服务器将向用户回复一个OK状态，并告知用户，BGREWRITEAOF已经被预定执行：一旦BGSAVE执行完毕，BGREWRITEAOF就会正式开始。当Redis启东时，如果RDB持久化和AOF持久化都被打开了，那么程序就会优先使用AOF文件来恢复数据集，因为AOF文件所保存的数据通常是最完整的。 持久化配置RDB持久化配置1234567891011#RDB持久化基本配置save 900 1 #900秒（15分钟）内有一个更改save 300 10 #300秒（5分钟）内有10个更改save 60 10000 #60秒内有10000次更改#达到以上定义的配置时间时，就将内存数据持久化到磁盘#RDB持久化高级配置stop-writes-on-bgsave-error yes #后台备份进程出错时，主进程是否停止写入？主进程不停止容易造成数据不一致rdbcompression yes #导出的rdb文件是否压缩，如果rdb的大小很大的话，建议这么做rdbchecksum yes #导入rdb恢复数据时，是否检验rdb的完整性 验证版本是否一致dbfilename dump.rdb #导出来的rdb文件名dir /data/redis/rdb #rdb的放置路径 AOF持久化配置123456789#AOF持久化基本配置appendonly yes/no #是否打开aof日志功能appendfsync always #每1个命令，都立即同步到aofappendfsync everysec #每秒写一次appendfsync no #写入工作交给操作系统，由操作系统判断缓冲区大小，统一写到aof#AOF持久化高级配置no-appendfsync-on-rewrite yes/no #正在导出rdb快照的过程中，是否停止同步AOFauto-aof-rewrite-percentage 100 #aof文件大小比起上次重写时的大小，增长率100%时重写，缺点：业务开始的时候，会重复重写多次。auto-aof-rewrite-min-size 64mbo #aof文件，至少超过64M时重写 RDB到AOF切换在Redis2.2或以上版本，可以在不重启的情况下，从RDB切换到AOF： 为最新的dump.rdb文件创建一个备份； 将备份放到一个安全的地方； 执行以下两条命令： 12redis-cli config set appendonly yesredis-cli config set save "" 确保写命令会被正确地追加到AOF文件的末尾 执行说明：执行的第一条命令开启了AOF功能：Redis会阻塞直到初始AOF文件创建完成为止，之后Redis会继续处理命令请求，并开始将写入命令追加到AOF文件末尾。执行的第二条命令用于关闭RDB功能。这一步是可选的，也可以同时使用RDB和AOF这两种持久化功能。 备份redis数据Redis对于数据备份是非常友好的，因为可以在服务器运行的时候对RDB文件进行复制：RDB文件一旦被创建，就不会进行任何修改。当服务器要创建一个新的RDB文件时，它先将文件的内容保存在一个临时文件里面，当临时文件写入完毕时，程序才使用rename(2)原子地用临时文件替换原来的RDB文件。这也就是说，无论何时，复制RDB文件都是绝对安全的。创建一个定期任务（cron job），每小时将一个RDB文件备份到一个文件夹，并且每天将一个RDB文件备份到另一个文件夹。确保快照的备份都带有相应的日期和时间信息，每次执行定期任务脚本时，使用find命令来删除过期的快照：可以保留最近48小时内的快照，还可以保留最近一两个月的每日快照。至少每天一次，将RDB备份到数据中心之外，或者至少备份到运行Redis服务器的物理机器之外。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix添加nginx监控]]></title>
    <url>%2Fposts%2F4255676476.html</url>
    <content type="text"><![CDATA[nginx开启监控模块修改nginx的配置，在nginx配置的server域加入以下配置，然后重启nginx1234location /nginx_status &#123; stub_status on; access_log off; &#125; 执行命令:1curl http://127.0.0.1/nginx_status 可看到输出：1234Active connections: 1 server accepts handled requests 3144 3144 3144 Reading: 0 Writing: 1 Waiting: 0 编辑nginx监控脚本在需要监控的nginx服务器上新建文件”/etc/zabbix/scripts/nginx_monitor.sh”(scripts目录需创建)，加入以下內容：1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bashstatus_url="http://127.0.0.1/nginx_status"case $1 in status) countor=$(ps -C nginx --no-heading|wc -l) if [ $&#123;countor&#125; -eq "0" ];then echo "stop" else echo "running" fi ;; active_conn) curl $status_url 2&gt;/dev/null|awk -F ":" 'NR==1&#123;print $2&#125;' ;; accepts) curl $status_url 2&gt;/dev/null|awk 'NR==3&#123;print $1&#125;' ;; handled) curl $status_url 2&gt;/dev/null|awk 'NR==3&#123;print $2&#125;' ;; requests) curl $status_url 2&gt;/dev/null|awk 'NR==3&#123;print $3&#125;' ;; reading) curl $status_url 2&gt;/dev/null|awk 'NR==4&#123;print $2&#125;' ;; writing) curl $status_url 2&gt;/dev/null|awk 'NR==4&#123;print $4&#125;' ;; waiting) curl $status_url 2&gt;/dev/null|awk 'NR==4&#123;print $6&#125;' ;; *) echo "$(basename $0) (status|active_conn|accepts|handled|requests|reading|writing|waiting)"esac 给予脚本执行权限：chmod +x /etc/zabbix/scripts/nginx_monitor.sh 修改zabbix-agent配置在需要监控的nginx服务器上新建”/etc/zabbix/zabbix_agentd.d/userparameter_nginx.conf”文件，添加如下配置：1UserParameter=nginx.status[*],/etc/zabbix/scripts/nginx_monitor.sh $1 重启zabbix-agent：systemctl restart zabbix-agent 导入nginx监控模板nginx监控模板及脚本下载下载模板文件并解压导入成功会在模板中显示“Template Nginx”模板，绑定到相应主机，nginx监控完成！]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>nginx监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix添加mysql监控]]></title>
    <url>%2Fposts%2F1388969176.html</url>
    <content type="text"><![CDATA[编辑mysql监控脚本在需要监控的mysql服务器上新建文件”/etc/zabbix/zabbix_agentd.d/mysql_monitor.sh”1vim /etc/zabbix/zabbix_agentd.d/mysql_monitor.sh 加入以下內容：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/bin/bashmysqladmin_dir="/usr/local/mysql/bin/mysqladmin_dir" #mysqladmin的路径MYSQL_PWD='mysqlpassword' #mysql的root密碼ARGS=1if [ $# -ne "$ARGS" ];then echo "Please input onearguement:"ficase $1 in Uptime) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; status 2&gt;/dev/null |awk '&#123;print $2&#125;'` echo $result ;; Questions) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; status 2&gt;/dev/null|awk '&#123;print $6&#125;'` echo $result ;; Com_update) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_update"|awk '&#123;print $4&#125;'` echo $result ;; Slow_queries) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Slow_queries"|awk '&#123;print $4&#125;'` echo $result ;; Com_select) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_select"|awk '&#123;print $4&#125;'` echo $result ;; Com_rollback) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_rollback"|awk '&#123;print $4&#125;'` echo $result ;; Com_insert) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_insert"|awk '&#123;print $4&#125;'` echo $result ;; Com_delete) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_delete"|awk '&#123;print $4&#125;'` echo $result ;; Com_commit) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_commit"|awk '&#123;print $4&#125;'` echo $result ;; Bytes_sent) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Bytes_sent"|awk '&#123;print $4&#125;'` echo $result ;; Bytes_received) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Bytes_received"|awk '&#123;print $4&#125;'` echo $result ;; Com_begin) result=`$mysqladmin_dir -uroot -p$&#123;MYSQL_PWD&#125; extended-status 2&gt;/dev/null|grep -w "Com_begin"|awk '&#123;print $4&#125;'` echo $result ;; *) echo "Usage:$0 (Uptime|Questions|Com_update|Slow_queries|Com_select|Com_rollback|Com_insert|Com_delete|Com_commit|Bytes_sent|Bytes_received|Com_begin)" ;;esac 12chmod 700 /etc/zabbix/zabbix_agentd.d/mysql_monitor.sh #授予mysql监控脚本执行权限chown zabbix:root /etc/zabbix/zabbix_agentd.d/mysql_monitor.sh #更改脚本属主为zabbix 编辑zabbix-agent配置在需要监控的mysql服务器上修改”/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf”文件 1vim /etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf 添加如下配置：1UserParameter=mysql.status[*],/etc/zabbix/zabbix_agentd.d/mysql_monitor.sh $1 重启zabbix-agent1systemctl restart zabbix-agent 在zabbix服务端测试1zabbix_get -s 192.168.1.46 -k mysql.status[Uptime] #获取到数据说明监控脚本正常 绑定mysql监控模板zabbix自带了mysql监控模板，在zabbix web界面的相应主机上绑定“Template DB MySQL”模板]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>mysql监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主主互备模式架构]]></title>
    <url>%2Fposts%2F1683246444.html</url>
    <content type="text"><![CDATA[DB1和DB2互为主从，保证两台数据库始终是同步的，同时在DB1和DB2上还需要安装高可用软件Keepalived。正常情况下，web server主机仅从BD1进行数据的读、写操作，DB2只负责从DB1同步数据。而Keepalived维护着一个VIP,此ip用来对外提供连接服务，同时，Keepalived还负责监控DB1和DB2上mysql数据库的运行状态，当DB1主机出现故障或mysql运行异常时，自动将VIP地址和mysql服务切换到DB2上，此时web server主机继续从DB2进行数据的读、写操作。通过Keepalived保持了数据库服务的连续性，整个切换过程非常快，并且对前端web server主机是透明的。这种方式可以实现95.000%的SLA（服务水平协定）。 修改mysql配置文件 修改DB1主机的配置文件，在/etc/my.cnf文件中的”[mysqld]”段加如下内容：12345server-id = 1log-bin = mysql-binreplicate-wild-ignore-table = mysql.%replicate-wild-ignore-table = test.%replicate-wild-ignore-table = information_schema.% 修改DB2主机的配置文件，在/etc/my.cnf文件中的”[mysqld]”段加如下内容：123456server-id = 2log-bin = mysql-binrelay-log = mysql-relay-binreplicate-wild-ignore-table = mysql.%replicate-wild-ignore-table = test.%replicate-wild-ignore-table = information_schema.% 重启DB1和DB2的mysql服务 手动同步数据库：如果DB1上已经有mysql数据，在执行主主互备之前，需要将DB1和DB2上两个mysql数据保持一致 创建复制用户并授权：在DB1中创建复制用户123grant replication slave on *.* to 'repl_user'@'192.168.88.12' identified by 'password';flush privileges;show master status; 在DB2的mysql库中将DB1设为自己主服务器1change master to master_host='192.168.88.11',master_port=3306,master_user='repl_user', master_password='123456',master_log_file='mysql-bin.000028',master_log_pos=4264031; #将master_log_file的值替换为在DB1中执行"show master status"显示的File的值，将master_log_pos的值替换为Position的值 在DB2上启动slave服务1start slave; 配置从DB2到DB1的mysql主从复制，这个配置过程与上面完全一样 在DB2上创建复制用户1grant replication slave on *.* to 'repl_user'@'192.168.88.11' identified by 'password'; 在DB1的mysql库中将DB2设为自己的主服务器1change master to master_host='192.168.88.12',master_port=3306,master_user='repl_user', master_password='123456',master_log_file='mysql-bin.000028',master_log_pos=480; #将master_log_file的值替换为在DB2中执行"show master status"显示的File的值，将master_log_pos的值替换为Position的值 在DB1上启动slave服务12start slave;show slave status\G #在DB1和DB2执行 配置Keepalived实现mysql双主高可用在进行高可用配置之前，需要在DB1和DB2服务器上安装Keepalived软件。DB1服务器上/etc/keepalived/keepalived.conf文件内容：123456789101112131415161718192021222324252627282930313233343536373839global_defs &#123;notification_email &#123;acassen@firewall.locfailover@firewall.locsysadmin@firewall.loc&#125;notification_email_from Alexandre.Cassen@firewall.locsmtp_server 192.168.200.1smtp_connect_timeout 30router_id MySQLHA_DEVEL&#125;vrrp_script check_mysqld &#123;script "/etc/keepalived/mysqlcheck/check_slave.pl 127.0.0.1"#检测mysql复制状态的脚本interval 2weight 21&#125;vrrp_instance HA_1 &#123;state BACKUP #在DB1和DB2上均配置为BACKUPinterface eth0virtual_router_id 80priority 100advert_int 2nopreempt #不抢占模式，只在优先级高的机器上设置，优先级低的机器不可设置authentication &#123;auth_type PASSauth_pass qweasdzxc&#125;track_script &#123;check_mysqld&#125;virtual_ipaddress &#123;192.168.88.10/24 dev eth0 #mysql的对外服务ip,即VIP&#125;&#125; 其中，check_slave.pl文件内容为123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/perl -wuse DBI;use DBD::mysql;# CONFIG VARIABLES$SBM = 120;$db = "aaa";$host = $ARGV[0];$port = 3306;$user = 'root';$pw = '123456';# SQL query$query = "show slave status";$dbh = DBI-&gt;connect("DBI:mysql:$db:$host:$port", $user, $pw, &#123; RaiseError =&gt; 0,PrintError =&gt; 0 &#125;);if (!defined($dbh)) &#123; exit 1;&#125;$sqlQuery = $dbh-&gt;prepare($query);$sqlQuery-&gt;execute;$Slave_IO_Running = "";$Slave_SQL_Running = "";$Seconds_Behind_Master = "";while (my $ref = $sqlQuery-&gt;fetchrow_hashref()) &#123; $Slave_IO_Running = $ref-&gt;&#123;'Slave_IO_Running'&#125;; $Slave_SQL_Running = $ref-&gt;&#123;'Slave_SQL_Running'&#125;; $Seconds_Behind_Master = $ref-&gt;&#123;'Seconds_Behind_Master'&#125;;&#125;$sqlQuery-&gt;finish;$dbh-&gt;disconnect();if ( $Slave_IO_Running eq "No" || $Slave_SQL_Running eq "No" ) &#123; exit 1;&#125; else &#123; if ( $Seconds_Behind_Master &gt; $SBM ) &#123; exit 1; &#125; else &#123; exit 0; &#125;&#125; 安装per连接数据库驱动1yum -y install perl-DBD-MySQL #安装per连接数据库驱动 这是用perl写的检测mysql复制状态的脚本，只需修改文件中mysql数据库的数据库、端口，用户名密码即可直接使用，但在使用前要保证此脚本有可执行权限。接着将Keepalived.conf文件和check_slave.pl文件复制到DB2服务器上的对应位置，将Keepalived.conf文件中priority值修改为90，由于配置的不是抢占模式，因此，还需要去掉nopreempt选项。在完成所有配置后，分别在DB1和DB2上启动Keepalived服务，在正常情况下VIP地址应该运行在DB1服务器上。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql主主互备</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7通过阿里源安装zabbix]]></title>
    <url>%2Fposts%2F1314989757.html</url>
    <content type="text"><![CDATA[此安装方法适用于centos7.x系统，安装版本为zabbix4.2 安装zabbix环境12echo -e "[zabbix]\nname=Zabbix Repository\nbaseurl=https://mirrors.aliyun.com/zabbix/zabbix/4.1/rhel/7/x86_64/\ngpgcheck=0\nenabled=1" &gt;&gt;/etc/yum.repos.d/zabbix.repo #添加阿里镜像仓库zabbix的yum源yum install -y zabbix-server-mysql zabbix-web-mysql zabbix-get zabbix-agent php-fpm 可能会报错：Error: Package: zabbix-server-mysql-4.2.0-0.2alpha2.el7.x86_64 (zabbix) Requires: libiksemel.so.3()(64bit)出现此错误则需要安装以下依赖：12345yum install -y epel-releaseyum install -y iksemel fping libiksemel#如果以上命令不能安装iksemel，可使用如下命令yum install -y gnutlsrpm -ivh http://springdale.math.ias.edu/data/puias/unsupported/7/x86_64//iksemel-1.4-6.sdl7.x86_64.rpm 安装mysql并导入zabbix数据库12345678rpm -ivh http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm #添加mysql源yum install -y mysql-server #安装后mysql的root密码为空，可自行设置systemctl start mysqld #启动mysqlsystemctl enable mysqld #加入开启自启动mysql -uroot -e "create database zabbix character set utf8 collate utf8_bin;" #创建zabbix数据库mysql -uroot -e "grant all privileges on zabbix.* to zabbix@localhost identified by 'password';" #将password改为自己的密码zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -ppassword zabbix #将password改为自己的密码sed -i 's#\# DBPassword=#DBPassword=password#g' /etc/zabbix/zabbix_server.conf #将password改为自己的密码 更改时区1sed -i 's#\# php_value date.timezone Europe/Riga#php_value date.timezone Asia/Shanghai#g' /etc/httpd/conf.d/zabbix.conf 启动zabbix12systemctl restart zabbix-server zabbix-agent httpd php-fpm systemctl enable zabbix-server zabbix-agent httpd php-fpm #加入开机自启动 访问http://your_ip/zabbix接着点击“Next step”和“Finish”,默认用户名:Admin，密码:zabbix 更改中文并解决中文乱码修改语言为中文zabbix默认的字体会出现中文乱码，在windows系统中的C:\Windows\Fonts目录下选择支持中文的字体（如:’宋体’），上传至“/usr/share/zabbix/fonts”目录下，并将字体名称的大写改为小写，否则不识别，执行如下命令：1sed -i &apos;s#graphfont#fontname#g&apos; /usr/share/zabbix/include/defines.inc.php #fontname为替换字体的名称，不需要后缀 刷新zabbix页面,中文字体显示正常 为zabbix设置域名和路径设置域名，编辑/etc/httpd/conf/httpd.conf自定义路径，编辑/etc/httpd/conf.d/zabbix.conf重启httpd服务1systemctl restart httpd zabbix4.2自动安装脚本服务端安装脚本123456789101112131415161718192021222324252627#!/bin/bashecho "开始安装zabbix服务端..."#添加zabbix安装源echo -e "[zabbix]\nname=Zabbix Repository\nbaseurl=https://mirrors.aliyun.com/zabbix/zabbix/4.1/rhel/7/x86_64/\ngpgcheck=0\nenabled=1" &gt;&gt;/etc/yum.repos.d/zabbix.repo#安装依赖yum install -y epel-release &amp;&amp; yum install -y fpingyum install -y gnutls &amp;&amp; rpm -ivh http://springdale.math.ias.edu/data/puias/unsupported/7/x86_64//iksemel-1.4-6.sdl7.x86_64.rpm || exit 1 #安装zabbix相关服务yum install -y zabbix-server-mysql zabbix-web-mysql zabbix-get zabbix-agent php-fpm || exit 1#安装mysql数据库rpm -ivh http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm &amp;&amp; yum install -y mysql-server || exit 1systemctl start mysqld &amp;&amp; systemctl enable mysqld#创建zabbix数据库mysql -uroot -e "create database zabbix character set utf8 collate utf8_bin;" || exit 1#设置zabbix数据库密码，密码由时间戳MD5加密取前15个字符组成zabbixdb_pw=$(date +%s|md5sum|cut -c 1-15)#创建zabbix数据库账号mysql -uroot -e "grant all privileges on zabbix.* to zabbix@localhost identified by \"$&#123;zabbixdb_pw&#125;\";" || exit 1#导入zabbix数据库zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p$&#123;zabbixdb_pw&#125; zabbix || exit 1#设置zabbix_server数据库密码sed -i "s#\# DBPassword=#DBPassword=$&#123;zabbixdb_pw&#125;#g" /etc/zabbix/zabbix_server.conf#设置时区为亚洲上海sed -i 's#\# php_value date.timezone Europe/Riga#php_value date.timezone Asia/Shanghai#g' /etc/httpd/conf.d/zabbix.conf#重启zabbix-server、agent、httpd、php服务并加入开机自启动systemctl restart zabbix-server zabbix-agent httpd php-fpm &amp;&amp; systemctl enable zabbix-server zabbix-agent httpd php-fpmecho -e "zabbix安装完成...\n请访问http://your_ip/zabbix并继续\nzabbix数据库密码：$&#123;zabbixdb_pw&#125; 请保存\nmysql的root密码为空，请自行设置" 客户端安装脚本123456#!/bin/bashserver_ip="your_server_ip" #your_server_ip更改为自己的zabbix服务器地址echo "开始安装zabbix客户端..."rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/4.1/rhel/7/x86_64/zabbix-agent-4.2.0-0.1alpha1.el7.x86_64.rpmsed -i "s#Server=127.0.0.1#Server=$&#123;server_ip&#125;#g" /etc/zabbix/zabbix_agentd.confsystemctl start zabbix-agent &amp;&amp; systemctl enable zabbix-agent]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab数据备份、还原、迁移]]></title>
    <url>%2Fposts%2F1095624551.html</url>
    <content type="text"><![CDATA[gitlab备份12gitlab-rake gitlab:backup:create docker exec -i gitlab gitlab-rake gitlab:backup:create #docker环境中 备份文件在/var/opt/gitlab/backups/目录下，文件格式为“时间戳_年_月_日_版本号_gitlab_backup.tar”编辑/etc/gitlab/gitlab.rb文件中的“gitlab_rails[‘backup_path’] = ”参数可修改备份文件目录，需重新加载gitlab配置并重启 gitlab还原123456#停止相关数据连接服务gitlab-ctl stop unicorn gitlab-ctl stop sidekiq#还原gitlab-rake gitlab:backup:restore BACKUP=1547406063 #还原1547406063_2019_01_13_11.5.4_gitlab_backup.tar文件，“BACKUP=”后跟还原文件的时间戳gitlab-ctl start #启动gitlab服务 注：不能直接在终端执行gitlab-ctl stop停止所有服务，因为gitlab删除和还原操作还需要使用到redis和postgresql连接。 gitlab迁移将备份的文件拷贝至新的gitlab对应的备份目录下，执行还原的步骤。 新gitlab版本需要和原有版本一致，否则可能迁移失败！复制备份过程可能导致属组和属主发生变化，需要修改所有者为git]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab安装]]></title>
    <url>%2Fposts%2F4024240644.html</url>
    <content type="text"><![CDATA[脚本快速安装12345curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash #debcurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash #rpmcurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.node.sh | bash #nodecurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.python.sh | bash #pythoncurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.gem.sh | bash #gem(ruby) 访问gitlab地址：http://your_host_ip docker安装12345678910docker pull registry.cn-zhangjiakou.aliyuncs.com/kapyan/gitlab:11.5.4docker run --detach \ --hostname 192.168.1.208:8000 \ --publish 10000:443 --publish 8000:8000 --publish 20000:22 \ --name gitlab \ --restart always \ --volume /home/gitlab/config:/etc/gitlab \ --volume /home/gitlab/logs:/var/log/gitlab \ --volume /home/gitlab/data:/var/opt/gitlab \ gitlab #运行容器 docker exec -it gitlab /bin/bash #进入容器vim /etc/gitlab/gitlab.rbgitlab-ctl reconfigure #重新加载gitlab配置gitlab-ctl restart #重启gitlab访问gitlab地址：http://your_host_ip:8000官方安装包]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx安装]]></title>
    <url>%2Fposts%2F385762059.html</url>
    <content type="text"><![CDATA[通过存储库安装nginxCentOS 6.x系统：123echo -e "[nginx]\nname=nginx repo\nbaseurl=http://nginx.org/packages/centos/6/$(uname -m)/\ngpgcheck=0\nenabled=1"&gt;&gt;/etc/yum.repos.d/nginx.repoyum install -y nginxchkconfig nginx on #设置开机自启动 CentOS 7.x系统：123echo -e "[nginx]\nname=nginx repo\nbaseurl=http://nginx.org/packages/centos/7/$(uname -m)/\ngpgcheck=0\nenabled=1"&gt;&gt;/etc/yum.repos.d/nginx.repoyum install -y nginxsystemctl enable nginx #设置开机自启动 ubuntu系统：1234sudo echo -e "deb http://nginx.org/packages/ubuntu/ codename nginx\ndeb-src http://nginx.org/packages/ubuntu/ codename nginx"&gt;&gt;/etc/apt/sources.listsudo apt-get updatesudo apt-get install -y nginxsystemctl enable nginx #设置开机自启动 源码编译安装nginxnginx各版本源码包下载以nginx-1.14.2为例：Centos系统：123456789useradd -M -s /sbin/nologin www #创建nginx运行用户yum -y install gcc pcre pcre-devel openssl openssl-devel zlib-devel gd gd-devel perl perl-ExtUtils-Embed #安装依赖wget http://nginx.org/download/nginx-1.14.2.tar.gz #下载nginx-1.14.2tar xf nginx-1.14.2.tar.gz #解压nginx压缩包cd nginx-1.14.2./configure --prefix=/usr/local/nginx-1.14.2 --user=www --group=www --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gzip_static_module --with-http_perl_module --with-mail --with-mail_ssl_module --with-http_stub_status_module #设置编译参数make &amp;&amp; make install #编译安装ln -s /usr/local/nginx-1.14.2 /usr/local/nginx #给nginx添加软连接ln -s /usr/local/nginx/sbin/nginx /usr/local/bin/nginx Ubuntu系统：123456789useradd -M -s /sbin/nologin www #创建nginx运行用户apt-get install -y gcc libpcre3 libpcre3-dev zlib1g-dev libssl-dev libperl-dev build-essential openssl #安装依赖wget http://nginx.org/download/nginx-1.14.2.tar.gz #下载nginx-1.14.2tar xf nginx-1.14.2.tar.gz #解压nginx压缩包cd nginx-1.14.2./configure --prefix=/usr/local/nginx-1.14.2 --user=www --group=www --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gzip_static_module --with-http_perl_module --with-mail --with-mail_ssl_module --with-http_stub_status_module #设置编译参数make &amp;&amp; make install #编译安装ln -s /usr/local/nginx-1.14.2 /usr/local/nginx #给nginx添加软连接ln -s /usr/local/nginx/sbin/nginx /usr/local/bin/nginx nginx官方启动脚本☞点击显/隐内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15# description: NGINX is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /var/run/nginx.pid# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ "$NETWORKING" = "no" ] &amp;&amp; exit 0nginx="/usr/sbin/nginx"prog=$(basename $nginx)NGINX_CONF_FILE="/etc/nginx/nginx.conf"[ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginxlockfile=/var/lock/subsys/nginxmake_dirs() &#123; # make required directories user=`$nginx -V 2&gt;&amp;1 | grep "configure arguments:.*--user=" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -` if [ -n "$user" ]; then if [ -z "`grep $user /etc/passwd`" ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d "=" -f 2` if [ ! -d "$value" ]; then # echo "creating" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done fi&#125;start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $"Starting $prog: " daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $"Stopping $prog: " killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; configtest || return $? stop sleep 1 start&#125;reload() &#123; configtest || return $? echo -n $"Reloading $prog: " killproc $nginx -HUP RETVAL=$? echo&#125;force_reload() &#123; restart&#125;configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125;rh_status() &#123; status $prog&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;case "$1" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;" exit 2esac 官方启动脚本示例 nginx编译参数详解nginx编译参数☞点击显/隐内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134./configure --help --prefix=path #指定nginx安装路径，默认是/usr/local/nginx --sbin-path=path #指定二进制可执行文件路径，默认是prefix/sbin/nginx --modules-path=path #指定modules路径，默认是prefix/modules --conf-path=path #指定nginx配置文件路径，默认是prefix/conf/nginx.conf --error-log-path=path #指定错误日志文件路径，默认是prefix/logs/error.log --pid-path=path #设置nginx的pid文件路径，默认是prefix/logs/nginx.pid --lock-path=path #设置nginx的lock文件路径，默认是prefix/logs/nginx.lock，在nginx启动是创建，保证只有一个nginx服务运行 --user=name #设置nginx运行的用户，默认是nobody --group=name #设置nginx运行的组 --build=name #设置nginx的编译的名字，建议忽略该选项 --builddir=path #设置nginx的编译目录，建议忽略该选项 --with-select_module --without-select_module #配置服务器的是否使用select轮询接口（该接口低效且有限制），如果系统不支持如kqueue, epoll, 或/dev/poll等机制，则会构建该模块，保持默认即可 --with-poll_module --without-poll_module #poll接口比select接口更加高效，但是同样有一定的socket数量的限制，推荐使用默认 --with-threads #允许使用线程池，默认开启 --with-file-aio #在FreeBSD和Linux系统中开启异步文件I/O，默认开启 --with-http_ssl_module #开启https协议支持，默认不构建，要求安装openssl openssl-devel依赖 --with-http_v2_module #开启http/2协议支持，默认不构建 --with-http_realip_module #该模块可将客户端地址更改为在指定的头字段中发送的地址，默认不构建 --with-http_addition_module #该模块在响应之前和之后添加文本，默认不构建 --with-http_xslt_module # --with-http_xslt_module=dynamic #允许构建使用一个或多个XSLT样式表转换XML响应，默认不构建，需要安装libxml2和libxslt库 --with-http_image_filter_module --with-http_image_filter_module=dynamic #图像过滤器模块，可以转换JPEG、GIF、PNG和WebP格式的图像，默认不构建模块，该模块依赖libgd库，建议使用最新版本的库 --with-http_geoip_module --with-http_geoip_module=dynamic #使用预编译的MaxMind数据库创建具有取决于客户端IP地址的值得变量，该模块依赖MaxMind GeoIP 库，默认不构建 --with-http_sub_module #该模块通过一个指定的字符串替换为另一个字符串来修改响应，默认不构建 --with-http_dav_module #通过WebDAV协议进行文件管理自动化，默认不构建 --with-http_flv_module #为Flash Video(flv)文件提供伪流服务器端支持，默认不构建 --with-http_mp4_module #为MP4文件提供伪流服务器端支持，默认不构建 --with-http_gunzip_module #用于不支持gzip编码方法的客户端，默认不构建 --with-http_gzip_static_module #允许使用.gz文件扩展名发送预压缩文件，默认不构建 --with-http_auth_request_module #基于子请求的结果实现客户端授权，默认不构建 --with-http_random_index_module #处理以斜杠（“/”）结尾的请求，并选择目录中的随机文件作为索引文件，默认不构建 --with-http_secure_link_module #用于检查请求链路的真实性，保护资源免受未经授权的访问，并限制链路生存期，默认不构建 --with-http_degradation_module #开启ngx_http_degradation_module，默认不构建 --with-http_slice_module #此模块可将请求拆分为子请求，每个子请求都返回一定范围的响应，默认不构建 --with-http_stub_status_module #此模块提供对基本状态信息的访问，默认不构建 --without-http_charset_module #该模块将指定的字符集添加到“Content-Type”响应头字段，还可以将数据从一个字符集转换为另一个字符集，此参数将取消该模块 --without-http_gzip_module #禁用文件压缩模块 --without-http_ssi_module #禁用该模块，该模块在通过它的响应中处理SSI(服务器端包含)命令 --without-http_userid_module #禁用该模块，该模块设置适合客户端识别的cookie --without-http_access_module #禁用该模块，该模块允许限制对某些客户端地址的访问 --without-http_auth_basic_module #禁用该模块，该模块允许通过使用“HTTP基本身份验证”协议验证用户名和密码来限制对资源的访问 --without-http_mirror_module #禁用该模块，该模块通过创建后台镜像子请求来实现原始请求的镜像 --without-http_autoindex_module #禁用该模块，该模块处理以斜杠（“/”）结尾的请求，并在ngx_http_index_module模块找不到索引文件的情况下生成目录列表 --without-http_geo_module #禁用该模块，该模块使用取决于客户端IP地址的值创建变量 --without-http_map_module #禁用该模块，该模块创建的变量值取决于其他变量的值 --without-http_split_clients_module #禁用该模块，该模块适用于A/B测试的变量，也称为拆分测试 --without-http_referer_module #禁用该模块，该模块用于阻止对“referer”头字段中具有无效值的请求访问站点 --without-http_rewrite_module #禁用该模块，该模块用于请求重定向，依赖PCRE库 --without-http_proxy_module #禁用该模块，该模块用于http代理服务 --without-http_fastcgi_module #禁用将请求传给FastCGI服务器的模块 --without-http_uwsgi_module #禁用将请求传给uwsgi服务器的模块 --without-http_scgi_module #禁用将请求传给SCGI服务器的模块 --without-http_grpc_module #禁用将请求传给GRPC服务器的模块 --without-http_memcached_module #禁止该模块，该模块从memcached服务器获取响应 --without-http_limit_conn_module #禁止该模块，该模块用于限制每个定义密钥的连接数，例如来自单个ip地址的连接数 --without-http_limit_req_module #禁止该模块，该模块用于限制每个定义密钥的请求处理数速率，例如来自单个ip地址的请求处理速率 --without-http_empty_gif_module #禁止该模块，该模块用于发出单像素透明的GIF --without-http_browser_module #禁用该模块，该模块创建的变量的值取决于User-Agent请求标头字段的值 --without-http_upstream_hash_module #禁用该模块，该模块用于负载均衡的hash算法 --without-http_upstream_ip_hash_module #禁用该模块，该模块用于负载均衡的ip_hash算法 --without-http_upstream_keepalive_module #禁用该模块，该模块提供上游服务器的连接缓存 --without-http_upstream_zone_module #禁用该模块，该模块可以将上游组的运行时状态存储在共享内存区域中 --with-http_perl_module --with-http_perl_module=dynamic #用于在perl中实现位置和变量处理程序，并将perl调用插入到SSI中，依赖perl5.6.1或更高版本，默认不构建 --with-perl_modules_path=path #设置perl_modules模块保存目录 --with-perl=path #设置perl所在路径 --http-log-path=path #设置访问日志路径，默认是 prefix/logs/access.log --http-client-body-temp-path=path #设置存储客户端请求主体的临时文件目录，默认是prefix/ client_body_temp --http-proxy-temp-path=path #设置存储临时文件和从代理服务器接收的数据目录，默认是prefix/proxy_temp. --http-fastcgi-temp-path=path #设置存储从FastCGI服务器接收的数据的临时文件目录，默认prefix/fastcgi_temp --http-uwsgi-temp-path=path #设置存储从uwsgi服务器接收的数据的临时文件目录，默认prefix/uwsgi_temp --http-scgi-temp-path=path ##设置存储从scgi服务器接收的数据的临时文件目录，默认prefix/scgi_temp. --without-http #禁用http服务 --without-http-cache #禁用http缓存 --with-mail --with-mail=dynamic #启用POP3/IMAP4/SMTP邮件代理服务器，默认不构建 --with-mail_ssl_module #为邮件代理服务器提供SSL/TLS协议支持，依赖OpenSSL库，默认不构建 --without-mail_pop3_module #禁止POP3邮件代理服务 --without-mail_imap_module #禁止IMAP邮件代理服务 --without-mail_smtp_module #禁止SMTP邮件代理服务 --with-stream --with-stream=dynamic #允许构建流模块以进行通用的TCP/UDP代理和负载均衡，默认不构建 --with-stream_ssl_module #为流模块提供SSL/TLS协议支持，依赖OpenSSL库，默认不构建 --with-stream_realip_module #该模块将客户端地址更改为proxy协议头中发送的地址，默认不构建 --with-stream_geoip_module --with-stream_geoip_module=dynamic #该模块根据客户端IP地址和预编译的MaxMind数据库创建变量，依赖MaxMind GeoIP库，默认不构建 --with-stream_ssl_preread_module #该模块允许从ClientHello消息中提取信息而不终止SSL/TLS，默认不构建 --without-stream_limit_conn_module #禁止该模块，该模块用于限制每个定义密钥的连接数，例如来自单个ip地址的连接数 --without-stream_access_module #禁止该模块，该模块用于限制对某些客户端地址的访问 --without-stream_geo_module # --without-stream_map_module --without-stream_split_clients_module --without-stream_return_module #禁止该模块，该模块允许向客户端发送指定值，然后关闭连接 --without-stream_upstream_hash_module --without-stream_upstream_least_conn_module --without-stream_upstream_zone_module --with-google_perftools_module #该模块支持使用Google Performance Tools分析nginx工作进程，适用于nginx开发人员，依赖gperftools库默认不构建 --with-cpp_test_module # --add-module=path #加入第三方模块，path为 第三方模块路径 --add-dynamic-module=path #动态加载第三方模块 --with-compat #启动动态模块兼容性 --with-cc=path #指定C编译器路径 --with-cpp=path #指定C预处理器路径 --with-cc-opt=parameters #设置将添加到CFLAGS变量的其他参数，在FreeBSD下使用系统PCRE库时，应指定--with-cc-opt="-I /usr/local/include" --with-ld-opt=parameters #设置将在链接期间使用的其他参数，在FreeBSD下使用系统PCRE库时，应指定--with-ld-opt="-L /usr/local/lib" --with-cpu-opt=cpu #设置cpu类型，如: pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 --without-pcre #禁止使用PCRE库 --with-pcre #强制使用PCRE库，PCRE库用于支持url重写和正则模块 --with-pcre=path #指定PCRE库的源码路径，nginx会自动编译 --with-pcre-opt=parameters #为PCRE设置其他参数 --with-pcre-jit #使用“即时编译”支持（1.1.12，pcre_jit指令）构建PCRE --with-zlib=path #指定zlib库的源码路径，nginx会自动编译，用于文件压缩 --with-zlib-opt=parameters #为zlib设置其他参数 --with-zlib-asm=cpu #允许使用针对其中一个指定CPU优化的zlib，例如：pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 --with-libatomic #强制使用libatomic库 --with-libatomic=path #指定libatomic库的源码路径，nginx会自动编译 --with-openssl=path #指定openssl库的源码路径，nginx会自动编译 --with-openssl-opt=parameters #为openssl设置其他参数 --with-debug #启用调试日志 nginx配置详解nginx配置详解☞点击显/隐内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#定义Nginx运行的用户和用户组user www www; #nginx进程数，建议设置为等于CPU总核心数。worker_processes 8;error_log /var/log/nginx/error.log error; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]pid /var/run/nginx.pid; #进程文件#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events&#123;#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。use epoll;#单个进程最大连接数（最大连接数=连接数*进程数）worker_connections 65535;&#125;#设定http服务器http&#123;include mime.types; #文件扩展名与文件类型映射表default_type application/octet-stream; #默认文件类型charset utf-8; #默认编码server_names_hash_bucket_size 128; #服务器名字的hash表大小client_header_buffer_size 32k; #上传文件大小限制large_client_header_buffers 4 64k; #设定请求缓存client_max_body_size 8m; #设定客户端请求缓存sendfile on; # 开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。tcp_nopush on; #防止网络阻塞tcp_nodelay on; #防止网络阻塞keepalive_timeout 120; #长连接超时时间，单位是秒#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#gzip模块设置gzip on; #开启gzip压缩输出gzip_min_length 1k; #最小压缩文件大小gzip_buffers 4 16k; #压缩缓冲区gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）gzip_comp_level 2; #压缩等级gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。gzip_vary on;limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用upstream blog.ha97.com &#123;#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。server 192.168.80.121:80 weight=3;server 192.168.80.122:80 weight=2;server 192.168.80.123:80 weight=3;&#125;#虚拟主机的配置server&#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.aaa.com wwww.bbb.com; index index.html index.htm index.php; root html; #站点根目录 location ~ .*\.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*\.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /var/log/nginx/access.log access; #对 "/" 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数， proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic "NginxStatus"; auth_basic_user_file conf/htpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125;&#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab个人的简单使用]]></title>
    <url>%2Fposts%2F3451632616.html</url>
    <content type="text"><![CDATA[个人设置 头像、语言设置 修改密码 免密设置添加公钥后可在操作git仓库时免去输入用户名、密码的步骤。公钥获取：windows系统：打开C:\用户\username\\.ssh\id_rsa.pub文件，将内容复制到填写公钥的位置，其中username为当前用户名，一般是administratorlinux系统：输入cat ~/.ssh/id_rsa.pub命令，将内容复制到填写公钥的位置。如果没有id_rsa.pub文件，则需要创建秘钥，创建方法如下：windows系统：按“win+R”键，输入“cmd”并回车打开cmd窗口，输入“ssh-keygen”，按三次回车键，创建完成linux系统：在终端里输入“ssh-keygen”，按三次回车键，创建完成 创建项目 获取项目地址、下载项目 项目权限设置、添加项目成员]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[geoserver+postgresql搭建]]></title>
    <url>%2Fposts%2F2386358445.html</url>
    <content type="text"><![CDATA[geoserver简介:&ensp;&ensp;&ensp;&ensp;Geoserver是一个功能齐全,遵循OGC开放标准的开源WFS-T和WMS服务器。利用Geoserver可以把数据作为maps/images来发布(利用WMS来实现)也可以直接发布实际的数据(利用WFS来实现),同时也提供了修改,删除和新增的功能(利用WFS-T)。它是开源的 ,允许用户查看和编辑地理数据。GeoServer 是符合OGC 规范的一个全功能的WFS-T 和WMS server。 geoserver+postgresql环境搭建：实验环境 系统及版本：Ubuntu16.0.4 jdk版本：1.8.0 tomcat版本：8.5 geoserver版本：2.14.1 postgresql版本：9.6 postgis版本：2.5 开始搭建：1. 安装jdk1.81sudo apt-get install -y openjdk-8-jdk 2. 安装tomcat8.512sudo wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz #下载Tomcattar xf apache-tomcat-8.5.37.tar.gz -C /usr/local/ &amp;&amp; mv /usr/local/apache-tomcat-8.5.37 /usr/local/tomcat #解压Tomcat至/usr/local/tomcat目录 3. 安装geoserver12sudo wget https://nchc.dl.sourceforge.net/project/geoserver/GeoServer/2.14.1/geoserver-2.14.1-war.zip #下载geoserver2.14.1sudo unzip geoserver-2.14.1-war.zip &amp;&amp; sudo unzip -d /usr/local/tomcat/webapps/geoserver geoserver.war #解压geoserver压缩包至/usr/local/tomcat/webapps/geoserver目录 注：提示”unzip: command not found”，请使用sudo apt-get install -y zip 安装zip1/usr/local/tomcat/bin/startup.sh #启动tomcat tomcat启动成功后，在浏览器打开http://host_ip:8080/geoserver 访问geoserver服务将host_ip替换为server的ip地址，默认用户名：admin 密码：geoserver 4. 安装postgresql-9.6和postgis-2.5123456sudo echo 'deb http://apt.postgresql.org/pub/repos/apt/ xenial-pgdg main'&gt;&gt;/etc/apt/sources.list.d/pgdg.list #添加postgresql安装源sudo wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - #导入存储库签名秘钥sudo apt-get update #更新包列表sudo apt-get install -y postgresql-9.6 #安装postgresql9.6sudo apt-get install -y postgresql-9.6-postgis-2.5 #安装postgresql9.6对应的postgis扩展sudo service postgresql start #启动postgresql服务 至此geoserver+postgresql搭建完成！参考资料：postgresql官方安装文档 通过docker安装docker镜像地址：registry.cn-zhangjiakou.aliyuncs.com/kapyan/geoserver:2.14.1 说明： 容器已集成geoserver的JDBC Image Mosaic、Vector Tiles扩展 GEOWEBCACHE_CACHE_DIR目录在/var/app/tomcat/webapps/ROOT/geo_web_cache_dir目录 postgresql远程连接已开启，用户名：wanshan 密码：wanshan@2018 可用中文字体：楷体、宋体、新宋体 安装：12docker pull registry.cn-zhangjiakou.aliyuncs.com/kapyan/geoserver:2.14.1docker run -it -d -p 80:8080 -p 5432:5432 --restart always --name geoserver -v /home/geoserver/data:/var/app/tomcat/webapps/ROOT/data/mydata -v /home/geoserver/geo_web_cache_dir:/var/app/tomcat/webapps/ROOT/geo_web_cache_dir geoserver FAQ添加nginx反向代理在nginx添加以下host文件配置，并重启12345678910111213141516server &#123; server_name domain_name; #你的域名 listen 80; location / &#123; add_header 'Access-Control-Allow-Origin' *; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Headers' 'Authorization,Content-Type,Accept,Origin,User-Agent,DNT,Cache-Control,X-Mx-ReqToken,X-Requested-With'; add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS'; #配置跨域允许，防止程序调用geoserver被跨域拦截 proxy_pass http://localhost:8080; proxy_set_header Host $host:$server_port; &#125;&#125; geoserver添加JDBC Image Mosaic扩展下载相应版本的JDBC Image Mosaic扩展并解压至geoserver所在目录的WEB-INF/lib/目录下geoserver2.14.1及扩展下载地址12wget https://jaist.dl.sourceforge.net/project/geoserver/GeoServer/2.14.1/extensions/geoserver-2.14.1-imagemosaic-jdbc-plugin.zip #下载JDBC Image Mosaic扩展unzip -d /usr/local/tomcat/webapps/geoserver/WEB-INF/lib/ geoserver-2.14.1-imagemosaic-jdbc-plugin.zip #解压至geoserver所在目录的WEB-INF/lib/目录下 geoserver添加Vector Tiles扩展下载相应版本的Vector Tiles扩展并解压至geoserver所在目录的WEB-INF/lib/目录下12wget https://jaist.dl.sourceforge.net/project/geoserver/GeoServer/2.14.1/extensions/geoserver-2.14.1-vectortiles-plugin.zip #下载Vector Tiles扩展unzip -d /usr/local/tomcat/webapps/geoserver/WEB-INF/lib/ geoserver-2.14.1-vectortiles-plugin.zip #解压至geoserver所在目录的WEB-INF/lib/目录下 编辑geoserver所在目录的/WEB-INF/web.xml文件，在第4行下添加如下内容：12345&lt;!--切片缓存目录--&gt;&lt;context-param&gt; &lt;param-name&gt;GEOWEBCACHE_CACHE_DIR&lt;/param-name&gt; &lt;param-value&gt;/usr/local/tomcat/webapps/geoserver/geo_web_cache_dir&lt;/param-value&gt;&lt;/context-param&gt; 然后重启tomcat 注：“/usr/local/tomcat/webapps/geoserver/geo_web_cache_dir”替换为自定义目录 geoserver开启jsonp编辑geoserver所在目录的/WEB-INF/web.xml文件，去掉以下注释：123443 &lt;!--&lt;context-param&gt;44 &lt;param-name&gt;ENABLE_JSONP&lt;/param-name&gt;45 &lt;param-value&gt;true&lt;/param-value&gt;46 &lt;/context-param&gt;--&gt; 改为123443 &lt;context-param&gt;44 &lt;param-name&gt;ENABLE_JSONP&lt;/param-name&gt;45 &lt;param-value&gt;true&lt;/param-value&gt;46 &lt;/context-param&gt; postgresql开启远程连接1.修改/etc/postgresql/9.6/main/postgresql.conf第59行： #listen_addresses = &apos;localhost&apos; 为 listen_addresses = &apos;*&apos; 2.在/etc/postgresql/9.6/main/pg_hba.conf的 # IPv4 local connections: host all all 127.0.0.1/32 md5 后添加一行： host all all 0.0.0.0/0 md5 注：0.0.0.0/0代码允许所有网段访问，也可指定特定网段，如192.168.1.0/24 postgresql创建超级用户1234su postgres #切换至postgres用户psql #进入postgresqlCREATE ROLE test superuser PASSWORD '123456' login; #创建名为test，密码为123456的超级用户\du #查看所有用户 为数据库添加postgis空间数据库扩展12345678su postgres #切换至postgres用户psql -d yourdatabase -c "CREATE EXTENSION postgis;"psql -d yourdatabase -c "CREATE EXTENSION postgis_topology;"psql -d yourdatabase -c "CREATE EXTENSION postgis_sfcgal;"psql -d yourdatabase -c "CREATE EXTENSION fuzzystrmatch;"psql -d yourdatabase -c "CREATE EXTENSION address_standardizer;"psql -d yourdatabase -c "CREATE EXTENSION address_standardizer_data_us;"psql -d yourdatabase -c "CREATE EXTENSION postgis_tiger_geocoder;" GDAL PostGIS Raster driver未找到从postgis2.1.3开始，默认禁用out-of-db rasters和所有raster驱动，启用他们需要在系统中设置环境变量12echo "POSTGIS_GDAL_ENABLED_DRIVERS=ENABLE_ALL"&gt;&gt; /etc/postgresql/9.6/main/environment #添加环境变量service postgresql restart #重启postgresql 参考资料：postgis官方安装文档 中文字段乱码问题 如果预览视图显示中文为“□□□□”，是因为系统中没有相应的字体，需要安装字体，可以在windows系统的C:\Windows\fonts目录下找到需要的字体，并上传至/usr/share/fonts/custom目录下（没有则新建custom目录），并在/usr/share/fonts/custom目录执行以下命令123456sudo apt-get install -y font-manager #安装字体管理工具sudo mkfontscalesudo mkfontdirsudo fc-cache -fv sudo fc-list #查看已安装字体注：高版本系统可能没有mkfontscale命令，将字体所在路径加入/etc/fonts/fonts.conf文件的"&lt;dir&gt;your_fonts_path&lt;/dir&gt;"即可 如果xml的中文显示为’???’，是因为系统的默认编码可能不支持中文，如“POSIX”1234sudo locale #查看当前系统编码sudo locale -a #查看系统支持的所有编码export LANG="en_US.UTF-8" #修改系统编码（临时修改，重启失效）echo 'export LANG="en_US.UTF-8"' &gt;&gt; /etc/profile #修改系统编码（永久修改）]]></content>
      <categories>
        <category>geoserver</category>
      </categories>
      <tags>
        <tag>geoserver</tag>
        <tag>postgresql</tag>
      </tags>
  </entry>
</search>
